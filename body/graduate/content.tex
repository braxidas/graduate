\chapter{绪论}


\section{研究背景与意义}

随着云计算技术的深入普及，云原生（Cloud Native）架构已成为构建现代企业级应用的主流标准。根据云原生计算基金会（CNCF）发布的 2024 年年度报告显示，全球云原生开发者的数量已达到 1560 万，超过 89\% 的企业正在生产环境中使用或尝试云原生技术\cite{CNCF2024}。这一技术范式的核心变革，在于利用容器（Container）替代了传统的虚拟机（VM）作为最小计算单元，并利用 Kubernetes 等编排系统实现了资源的自动化调度\cite{Burns2016BorgOA}。这种转变不仅让软件的开发与交付变得更加敏捷，也彻底重塑了底层基础设施的网络架构。

\begin{figure}[htbp]
  \centering
  % 1. 移除 resizebox，改用 scale=0.95 缩放坐标，保持文字大小不变且清晰
  \begin{tikzpicture}[
      scale=0.95, 
      >=Stealth,
      % 2. 全局字体：移除 \sffamily，使用标准罗马字体，字号设为 \small
      font=\small,
      % --- 样式定义 ---
      basic box/.style={
          draw=gray!50,
          rectangle,
          rounded corners=3pt,
          minimum width=3.2cm,
          minimum height=1.4cm,
          align=center,
          fill=white,
          drop shadow={opacity=0.1, shadow xshift=1pt, shadow yshift=-1pt},
          inner sep=4pt,
          line width=0.8pt % 线条加粗一点，更有质感
      },
      % 外部攻击者
      hacker box/.style={basic box, draw=red!40, fill=red!5},
      % 边界防护
      fw box/.style={basic box, minimum width=1.0cm, minimum height=4.5cm, draw=blue!40, fill=blue!5},
      % 内部业务服务
      svc box/.style={basic box, draw=orange!40, fill=orange!5},
      % 攻击路径连线
      attack line/.style={->, draw=red!70, line width=1.2pt, rounded corners=4pt}
  ]

    % 1. 外部网络层 (坐标保持)
    \node[hacker box] (hacker) at (-5, 0) {\textbf{外部攻击者} \\ \footnotesize (External Attacker)};

    % 2. 边界防火墙
    \node[fw box] (fw) at (-1.5, 0) {\rotatebox{90}{\textbf{边界防火墙 (FW)}}};

    % 3. 内部微服务集群
    \node[svc box, dashed] (web) at (3, 1.5) {Web 服务 A \\ (\textbf{已入侵})};
    \node[svc box] (order) at (3, -1.5) {订单服务 B};
    \node[svc box] (db) at (7.5, 0) {数据库服务 C};

    % 绘制内部网络分组框
    \draw[gray!35, dashed, rounded corners=8pt, line width=0.8pt] (1.0, -2.6) rectangle (9.5, 2.6);
    \node[font=\footnotesize\bfseries, text=gray!80] at (5.25, 2.8) {内部受信网络 (东西向流量缺乏隔离)};

    % 4. 连线逻辑 (字体升级：tiny -> scriptsize)
    % 突破边界
    \draw[attack line] (hacker.east) -- node[above, font=\scriptsize, text=red] {南北向渗透} (fw.west);
    \draw[attack line] (fw.east) -- (web.west);

    % 内部横向移动
    \draw[attack line] (web.south) -- (order.north) node[midway, left, font=\scriptsize, text=red] {横向移动};
    
    % 订单服务到数据库
    \draw[attack line] (order.east) -| (db.south) node[pos=0.5, below, font=\scriptsize, text=red] {获取敏感数据};
    
    % Web服务到数据库
    \draw[attack line] (web.east) -| (db.north) node[pos=0.25, above, font=\scriptsize, text=red] {跨服务渗透};

    % % 5. 底部结论说明 (增加 text width 防止单行过长)
    % \node[draw=red!40, fill=white, rounded corners=2pt, inner sep=6pt] at (5.25, -3.8) {
    %     \textbf{传统防御困境：} 攻击者突破外围后，可利用“默认可信”机制在微服务间横向移动 
    % };

  \end{tikzpicture}
  \caption{传统边界防御体系在云原生环境下的失效机理示意图}
  \label{fig:traditional_defense_failure}
\end{figure}

然而，云原生环境带来的极致弹性与动态性，也让传统的网络安全防御体系面临失效的风险。在传统的物理数据中心中，安全团队通常依赖防火墙在网络边缘构建一个坚固的“防线”，也就是所谓的边界防御（Perimeter-based Defense）。但在云原生环境中，容器的生命周期极短，IP 地址频繁变化，服务间的调用关系错综复杂，导致固定的物理边界逐渐模糊甚至消失。Gartner 的研究指出，随着云环境复杂度的增加，绝大多数（预计到 2025 年将达 99\%）的云安全事故将源于客户的配置错误，而非云平台本身的漏洞\cite{Gartner2023}。一旦攻击者突破了外围防线,参考\ref{fig:traditional_defense_failure}，由于内部网络往往缺乏有效的隔离，他们便可以利用“默认可信”的机制在微服务之间进行肆无忌惮的横向移动（Lateral Movement）。


为了应对这种“内网默认可信”带来的安全隐患，Google 等业界先驱提出了“零信任（Zero Trust）”的安全理念，主张“永不信任，始终验证”，即无论请求来自网络内部还是外部，都必须经过严格的身份认证与授权\cite{Ward2014BeyondCorpAN}。在此背景下，微隔离（Micro-segmentation）技术应运而生。与传统防火墙不同，微隔离将防护的颗粒度细化到了每一个工作负载（Workload）甚至每一个容器，试图通过精细化的流量控制策略，阻断攻击者的横向渗透路径\cite{Rose2019ZeroTA}。

虽然微隔离技术的理念已经非常成熟，但在实际的云原生工程落地中，运维人员仍面临着巨大的挑战，主要体现在以下三个方面：

\begin{enumerate}
    \item 策略维护难：在 Kubernetes 集群中，容器的生灭往往以分钟甚至秒为单位，IP 地址的剧烈变动使得基于 IP 的传统黑白名单瞬间失效。运维人员很难手动维护一套能够实时跟随业务变化的动态策略\cite{Li2019ServiceMC}。
    \item 管理复杂度高：微服务架构将单体应用拆分为成百上千个独立服务，服务间的调用链路呈指数级增长。面对如此庞大的分布式网络，依靠人工梳理业务逻辑并配置数万条隔离规则，不仅效率极低，而且极易出现配置冲突或遗漏。
    \item 流量可视性差：现有的安全工具大多只能监控到网络层（L3/L4）的连接状态，缺乏对应用层（L7）业务语义的理解。这意味着安全团队很难区分正常的业务调用与利用合法端口进行的恶意攻击，难以制定出既安全又不影响业务的精准策略\cite{2021AttributebasedAC}。
\end{enumerate}

综上所述，传统的、依赖人工配置的静态安全手段已无法适应云原生环境的高动态特征。因此，如何深入理解业务逻辑，自动化地生成准确、实时且具备可解释性的微隔离策略，已成为当前云原生安全领域急需解决的关键问题。



\section{国内外研究现状}

为了应对微服务环境下的服务实例生命周期大幅缩短，IP 地址不再固定，服务间的依赖关系呈现出随业务逻辑动态变化的网状拓扑特征 \cite{Jamshidi2018MicroservicesTJ}等挑战，围绕如何自动化生成适应云原生环境的微隔离策略，现有的技术方案主要根据数据源的不同分为三类：基于流量分析的策略生成技术、基于角色的策略生成技术以及基于静态分析的策略生成技术。接下来，本文将逐一介绍这些技术。

\subsection{基于流量分析的策略生成技术}

基于流量分析的策略生成技术是目前工业界应用最为广泛的方案，其核心思想是“以观测代替预设”。该技术不依赖源代码或人工配置，而是通过持续监控生产环境中的实际通信行为，逆向推导服务依赖关系，进而生成白名单策略。

从技术实现来看，主要通过 Sidecar 代理或 eBPF（Extended Berkeley Packet Filter）技术进行采集。Isovalent 公司的技术白皮书指出，基于 eBPF 的无侵入式观测能够以极低的性能损耗，在内核层直接捕获全集群的网络拓扑 \cite{Isovalent2023}。尽管该方法具备部署便捷的优势，但针对构建严密安全防线的这一需求看，单纯依赖流量分析存在三个本质缺陷：

\begin{enumerate}
    \item 观测覆盖率不足与长尾效应：流量分析本质上是一种基于时间窗口的采样。它只能记录观测期间发生的“显式行为”，无法覆盖“隐式合法行为”。Zhou 等人\cite{Zhou2018FaultAA}在 IEEE Transactions on Software Engineering 上的实证研究表明，微服务故障传播路径往往涉及低频调用的边缘服务，这些长尾路径在正常监控中很难显现 。Chen 等人\cite{Chen2008AutomatingNA}的经典研究也证实，即使经过长达数周的采样，仍会有大量合法的边缘业务逻辑（如灾备切换、审计任务）因未被触发而未被记录 。若仅依据不完整的流量样本生成白名单，一旦这些低频业务在未来被触发，就会被误判阻断，导致生产事故。

    \item 策略生成的滞后性与冷启动问题：基于学习的机制存在天然的“冷启动”窗口。在服务刚上线或版本更新初期，系统必须积累足够的数据才能计算出收敛的行为基线。He 等人\cite{He2023AdversarialML}指出，机器学习模型在面对数据分布快速变化时表现出显著的滞后性 。此外，云原生工作负载具有高度瞬态性。Sysdig 的监测数据显示，超过 70\% 的容器生命周期不足 5 分钟 \cite{Sysdig2024}。对于这些短生命周期的对象，往往是探针还未收集到足够的流量样本，容器就已经销毁，导致无法生成有效的防护策略。

    \item 脏数据引发的策略“毒化”风险：流量分析方案通常假设“观测到的流量均为良性”。然而，Gnutti 等人\cite{Gnutti2022}的研究指出，在存量系统中，攻击者可能利用伪造的正常流量模式来混淆检测模型 。如果缺乏人工甄别，将所有历史连接直接固化为白名单，实际上等同于将潜在的恶意行为（如探测扫描）合法化了，这种由脏数据导致的策略“毒化”将永久性地破坏安全边界。
\end{enumerate}

针对上述局限性，近年来开始出现结合大语言模型（LLM）进行策略优化的尝试。例如，KubeGuard\cite{KubeGuard2025} 提出利用 LLM 分析运行时日志来辅助生成最小权限配置。同时，KubeAegis 框架\cite{KubeAegis2024}也尝试通过统一策略管理来解决流量观测到的策略规则碎片化问题。然而这些尝试仍然不能从根本上解决上述缺陷。




\subsection{基于角色的策略生成技术}

为了解决云原生环境下 IP 地址频繁变动导致网络策略失效的问题，研究人员提出了将访问控制策略与底层网络标识解耦的思路，主张提取工作负载的高层身份属性来构建抽象的角色模型，并依据“用户/服务-角色-权限”的映射关系来生成逻辑隔离策略。

在理论层面，Sandhu 等人\cite{Sandhu1996RoleBasedAC}提出的 RBAC96 模型奠定了这一领域的基石，通过引入“角色”作为中间层，极大地简化了大规模系统中的权限管理复杂度。在 Kubernetes 等现代编排平台中，这种机制通常表现为利用 ServiceAccount 作为策略锚点。这种方法实现了防护逻辑的语义化，使得安全策略能够跟随容器的生命周期自动迁移，而无需像防火墙那样频繁更新 IP 规则。

然而，尽管基于角色的方法在理论上很完善，但在面对大规模微服务集群的实际工程落地中，这种静态的授权模型逐渐暴露出了三个显著的缺陷：

\begin{enumerate}
    \item 角色爆炸与管理熵增：微服务架构的核心原则是职责单一，这意味着随着业务的发展，服务的数量会呈线性甚至指数级增长。Ferraiolo 等人\cite{Ferraiolo2001}指出，当系统规模扩大时，如果严格遵循“最小特权原则”为每一个微服务实例定制专属角色，将导致角色数量急剧膨胀，即所谓的“角色爆炸（Role Explosion）”现象 。在云原生环境下，这一问题尤为严重。Rostami 等人\cite{Rostami2023}指出，Kubernetes 的 RBAC 系统包含极其复杂的动词（Verbs）和资源（Resources）组合，这种组合的复杂性使得在大型集群中维护成千上万个“服务-角色”映射关系变得极难管理 。

    \item 过度授权带来的权限泄露风险：为了规避角色爆炸带来的管理难题，工程实践中往往会出现“走捷径”的现象。Kuhn 等人\cite{Kuhn2010AddingAT}指出，通过“角色复用”来减少配置量虽然降低了管理成本，但不可避免地扩大了攻击面 。这一点在近年来的安全报告中得到了验证。Red Hat 发布的 2024 年 Kubernetes 安全报告\cite{RedHat2024}显示，超过 46\% 的组织曾因权限配置错误（Misconfiguration）导致安全事故 。最新的自动化检测研究 EPScan \cite{EPScan2025}也证实，在生产环境中，大量的微服务拥有它们实际业务逻辑并不需要的“僵尸权限”，这意味着一旦单一容器被攻陷，攻击者就可以继承该角色所有的多余权限进行横向移动 。

    \item 静态授权无法适应动态风险：传统的 RBAC 模型本质上是一种静态授权机制。策略决策完全依赖于预先定义的静态绑定关系，缺乏对运行时上下文（Context-Awareness）的感知能力。NIST 的研究员 Hu 等人指出，静态角色难以将动态属性（如当前的负载压力、访问时间窗口、客户端地理位置或实时的威胁情报等级）纳入决策逻辑 \cite{Hu2014GuideTA}。在零信任架构中，访问请求的合法性往往取决于瞬时的系统状态，基于静态角色的策略在应对突发威胁时，往往显得过于僵化。
\end{enumerate}

综上所述，基于角色的策略生成技术虽然解决了网络标识漂移的问题，但在细粒度控制与动态适应性方面仍存在天然的逻辑局限。




\subsection{基于静态分析的策略生成技术}

基于静态分析的策略生成技术体现了“安全左移（Security Shift Left）”的防御思想。与前两种依赖运行时数据的方案不同，这种技术路线主张在应用部署之前的构建阶段（Build Phase），通过扫描源代码、字节码或配置文件，提前推导服务之间的调用关系，从而生成最小特权白名单。

在学术界，这一方向的研究主要集中在如何通过代码分析来提取微服务的拓扑结构。Li 等人\cite{li_automatic_2021}提出的 AutoArmor 系统是该领域的代表性工作，它通过对微服务源代码进行静态切片分析，自动提取服务间的 API 调用链并生成访问控制策略 。类似地，Ghavamnia 等人\cite{Ghavamnia2020ConfineAS}提出的 Confine 系统，则专注于通过静态分析容器内的二进制文件来削减系统调用（System Calls）的攻击面，证明了静态方法在收敛权限方面的有效性 。

这种方法的显著优势在于其覆盖率高且具备确定性。静态分析可以遍历代码中的所有逻辑分支，理论上能够发现那些在运行时很难被触发的“冷路径”依赖（例如灾难恢复逻辑），且生成的策略直接映射代码意图，具备天然的可解释性。然而，在云原生微服务的实际工程应用中，纯静态分析面临着三个难以逾越的“语义盲区”：

\begin{enumerate}
    \item 动态语言特性的解析难题：现代微服务应用广泛使用反射（Reflection）、动态代理和依赖注入等动态特性。Cerny 等人\cite{Cerny2024MicroserviceAware}指出，现有的静态分析工具在处理微服务架构时存在显著的“上下文缺失”问题，特别是当调用目标由配置文件或数据库动态决定时，静态工具很难推断出准确的调用图 。最新的 arXiv 研究 \cite{Valles2025Semantic}进一步提出“语义依赖”的概念，指出微服务间大量存在的隐式逻辑依赖无法仅通过语法分析来捕获，这导致纯静态生成的策略往往是不完整的 。

    \item 基础设施层的不可视：在云原生架构中，许多关键的网络行为并非由业务代码直接控制，而是由底层基础设施接管。例如，在 Istio 等服务网格环境中，Sidecar 代理会自动注入到 Pod 中并接管流量。这种运行时的架构变化无法在静态的源代码或 Dockerfile 中被预先捕获。Tigera 的技术报告\cite{Tigera2024}指出，静态分析无法感知由 Kubernetes 控制平面或 Sidecar 引入的额外网络路径，这意味着仅凭业务代码生成的策略，可能会因为遗漏基础设施组件的通信需求而导致服务启动失败 。

    \item 多语言异构环境的适配成本：微服务架构的一个重要特性是技术栈的异构性。Pereira-Vale 等人\cite{PereiraVale2023Mapping}中分析了 50 种现有的安全方案，发现绝大多数静态分析工具缺乏能够跨越语言边界追踪调用链的通用解决方案 。这种工具链的碎片化，使得在多语言混合的微服务系统中构建全局一致的依赖拓扑变得极具挑战性。
\end{enumerate}

综上所述，虽然静态分析能够提供高精度的代码级依赖视图，但受限于动态特性和基础设施层的不可见性，它无法独立生成完整的运行时微隔离策略。这也为本文提出“动静态协同分析”的思路提供了有力的事实依据。



\section{研究内容与意义}

\subsection{当前云原生零信任微隔离领域面临的主要挑战}

随着云原生架构（Cloud-Native Architecture）逐步确立为现代数据中心的基础设施标准，零信任微隔离技术已成为在不可信网络环境中保障大规模分布式微服务集群安全的核心范式。然而，尽管该技术在理论层面已趋于成熟，但在实际的工程化落地过程中，仍面临着严峻的挑战。这些挑战不仅源于云原生环境本身固有的高动态性（High Dynamism）与架构复杂性，更深层次地涉及到安全策略在技术实现、运维管理以及合规审计等多重维度的制约。

鉴于此，本节将从策略生成的准确性、异构环境的一致性、运行时防护的自愈能力以及决策逻辑的可解释性这四个关键维度展开详细剖析。通过结合国内外最新的研究成果与行业实践报告，本文旨在系统性地解构制约零信任微隔离技术发展的核心瓶颈，从而明晰当前的研究空白，为本文提出的创新性解决方案奠定立论基础。



\subsubsection{策略生成的准确性}
在云原生环境中，微服务的高频部署与容器的短生命周期特性，对零信任策略的准确性与响应速度提出了极高的要求。然而，现有的技术路线普遍陷入了“静态覆盖不足”与“动态噪声干扰”的两难境地，很难在准确性与时效性之间找到平衡点。

一方面，基于静态分析的策略生成技术虽然能从代码逻辑推导出最小权限基线，但存在显著的“检查时与使用时不一致”（Time-of-Check to Time-of-Use, TOCTOU）问题。在 Kubernetes 集群中，工作负载的动态行为——例如 Pod 的故障迁移、Sidecar 代理的热加载——往往发生在部署之后。这意味着静态预设的规则很容易与运行时真实的拓扑产生时空错位，导致短暂的权限漏洞窗口 \cite{CISA2024}。相关的行业调查显示，超过 35\% 的安全团队在实施微隔离时，因为无法动态适应应用变更而遭遇了严重的性能瓶颈与业务阻断，最终迫使运维人员不得不放宽策略粒度，牺牲安全性来换取可用性 \cite{AccuKnox2024}。

另一方面，基于流量学习的动态生成方法虽然具备实时性，但极易受环境噪声干扰而产生“过拟合”或“欠拟合”现象。Palo Alto Networks 的研究指出，在东西向流量高度复杂的微服务网格中，单纯依赖流量基线很难有效区分合法的异常波动与恶意的横向移动。在零日攻击场景下，这种方法的有效阻断率仅徘徊在 15\% 到 30\% 之间，且存在较高的误报风险 \cite{PaloAlto2024}。

此外，在多云分布式架构下，跨域策略数据的同步往往存在显著的“收敛延迟”。CISA 在其零信任成熟度模型中强调，传统策略引擎在面对云原生“瞬生灭变”的特征时，策略下发的滞后性已成为制约防御效能的主要瓶颈 \cite{CISA2024}。尽管近年来有学者尝试利用机器学习算法来优化流量聚类，但这类黑盒模型在面对对抗样本时泛化能力有限，且缺乏可解释性，很难作为关键基础设施的唯一决策依据 \cite{He2023AdversarialML}。

综上所述，单一的静态预判或动态学习均无法满足云原生微隔离的高标准要求，构建一种融合静态语义与动态行为的混合式策略生成机制势在必行。

\subsubsection{异构环境的一致性}

云原生架构的演进呈现出显著的多云混合（Multi-Cloud Hybrid）趋势，微服务往往跨越私有云（Kubernetes）、公有云托管平台（如 AWS EKS, Azure AKS）以及边缘计算节点（Edge Nodes）进行分布式部署。这种基础设施的异构性导致零信任微隔离策略在跨域迁移时面临严重的一致性挑战。

首先，底层控制平面的碎片化导致了严重的“厂商锁定”与策略孤岛。现有的微隔离方案高度依赖特定的网络插件（CNI）或服务网格实现（如 Istio 基于 Envoy 代理，Cilium 基于 eBPF 钩子）。不同技术栈之间的策略模型存在巨大的语义鸿沟，缺乏统一的标准描述语言\cite{CNCF2023}。例如，在多云架构中，将业务从私有 IDC 迁移至公有云时，往往需要将数千条 iptables 规则手动重构为云厂商特定的 Security Group 规则。这种重复劳动不仅导致运维成本指数级增长，更违背了云原生“声明式（Declarative）”与“一次编写，到处运行”的设计初衷\cite{Axiomatics2022}。

其次，“棕地（Brownfield）”集成是企业数字化转型中不可回避的痛点。现实系统中往往共存着现代化的微服务容器与遗留的单体应用（Legacy Monoliths）。这些遗留系统缺乏 Sidecar 注入能力或对现代零信任协议（如 SPIFFE/SPIRE）的支持，导致微隔离策略在实施时出现兼容性断层\cite{CSA2017}。

此外，在 5G 核心网（5G Core）与 Serverless 无服务器计算等新兴场景下，策略的执行效率与粒度平衡面临严峻考验。3GPP 在其安全架构标准中明确指出，服务化架构（SBA）中的高吞吐量信令交互要求安全策略必须具备极低的时延，然而各设备厂商对标准的不同解读与自定义实现（Proprietary Implementation），导致跨厂商设备的微隔离互操作性极差\cite{3GPP_TS33501}。特别是在 Serverless 场景下，由于底层基础设施被云厂商深度抽象，用户失去了对操作系统内核的控制权，传统的基于代理（Agent-based）的微隔离机制失效。研究表明，在无服务器环境中移植策略往往需要针对特定运行时进行繁琐的手动调整，极易引入“配置漂移（Drift）”风险，导致防护效能显著下降\cite{Li2021SecuringSC}。

权威调研报告指出，这种跨环境的策略碎片化已成为多云安全治理的最大障碍，构建一个跨平台、标准化的策略抽象层已成为行业迫切需求\cite{PaloAlto2023}。



\subsubsection{运行时防护的自愈能力}

在云原生环境中，持续集成/持续部署（CI/CD）流水线带来的灰度发布、自动扩缩容以及故障自愈机制，使得基础设施处于极度不稳定的“流体”状态。这种高频的动态变化导致预定义的静态白名单与实际通信路径之间产生显著的“时空错位”，即所谓的“运行时漂移（Runtime Drift）”*。

首先，微服务实例的“瞬态性（Ephemerality）”加剧了策略的“腐化（Decay）”速率，Datadog 的大规模测量研究也证实，Kubernetes 集群中超过三分之一的 Pod（如 Job 或 CronJob 类型）在 1 分钟内即完成销毁\cite{Datadog2024}。然而，现有的策略执行点（PEP）往往依赖于静态的 IP 地址绑定或非实时的标签同步。当新实例上线或发生故障迁移时，基于 iptables 或 IPVS 的底层规则更新往往存在分钟级的延迟，导致新实例在启动初期缺乏管控，或旧规则残留形成“幽灵策略（Ghost Policies）”，极易被攻击者利用进行持久化驻留\cite{CrowdStrike2024}。

其次，缺乏针对“概念漂移（Concept Drift）”的闭环矫正机制是当前技术的重大缺陷。在多租户与多集群场景下，业务流量模式并非一成不变，而是随着业务逻辑迭代发生动态偏移。现有的监控体系多侧重于系统指标（Metrics）而非安全语义，导致漂移检测存在严重的滞后性（Lag）。NIST 在其微服务安全标准（SP 800-204B）中指出，若缺乏对应用层语义（L7）的持续再验证，任何静态授权模型都会随着时间推移而退化为过权状态（Over-privileged）\cite{2021AttributebasedAC}。Gartner 的市场指南进一步量化了这一风险：超过 60\% 的微隔离失效并非源于初始策略的逻辑错误，而是源于策略未能跟随工作负载的变更而及时演进，最终导致运维团队被迫将防护模式回退至“监控模式”\cite{Gartner2023}。

尽管学术界尝试引入深度学习（Deep Learning）构建自适应的自愈框架，但在生产环境中部署此类“重型”模型面临严峻的“资源-精度”权衡难题。一方面，高频的流量推理抢占了业务容器宝贵的计算资源（CPU/Memory），违背了云原生轻量化的原则；另一方面，研究表明\cite{Andresini2021INSOMNIATC}，基于统计学的异常检测模型在面对非平稳分布的流量时，极易混淆正常的突发流量（Flash Crowd）与恶意攻击，高误报率（False Positive）使得自动化阻断功能在实际工程中难以落地。



\subsubsection{决策逻辑的可解释性}


在零信任微隔离的落地实践中，自动化策略生成算法往往面临着“计算高效”与“逻辑透明”的零和博弈。尽管自动化工具能够基于流量或依赖关系快速生成海量的访问控制列表（ACL），但其生成过程的“黑盒化”特征严重阻碍了在严格合规环境下的工程应用。

首先，监管法规对自动化运维系统的“可审计性（Auditability）”提出了硬性约束。我国《网络安全等级保护基本要求》（GB/T 22239-2019）明确规定，安全管理中心必须具备对安全策略配置依据的追溯与核查能力\cite{GBT22239}。欧盟《通用数据保护条例》（GDPR）亦强调了对“自动化决策（Automated Decision-Making）”的解释权。然而，现有的策略生成引擎大多仅输出最终的阻断/放行规则，缺乏对“归因链条（Attribution Chain）”的完整记录——即无法回答“某条规则是基于哪个业务意图、哪段通信历史或哪项合规基线而生成”的因果问题\cite{NIST800207}。

其次，“语义鸿沟（Semantic Gap）”与“规则爆炸”导致了认知负荷的极限挑战。大规模微服务集群往往产生数以万计的底层网络规则（L3/L4），这些规则以 IP、端口或标签为载体，彻底丢失了上层的业务语义（L7）。ACM Computing Surveys 的最新综述指出，随着微服务数量的增长，底层规则之间的“逻辑冲突（Logical Conflicts）”（如影子规则、冗余规则）呈指数级上升，且难以通过人工手段识别\cite{Yarygina2018OvercomingSC}。

此外，在多策略源并存的复杂场景下，算法内部的“冲突消解机制（Conflict Resolution）”往往是不透明的。NIST 在其属性访问控制（ABAC）标准中指出，当静态基线与动态流量推导出的规则发生逻辑互斥时，自动化系统通常基于预设的优先级（如“拒绝优先”）进行静默处理，而未向管理员暴露决策依据，导致实际生效的安全边界与预期设计严重偏离\cite{NIST800162}。

因此，构建一种具备全链路溯源能力、能够将底层规则映射回高层业务意图的“白盒化”策略生成框架，是解决信任危机的关键。



\section{解决方案及其意义}

针对上述云原生微隔离领域在策略准确性、环境一致性以及可解释性方面面临的严峻挑战，本文提出了一种基于动静态协同分析与大模型语义增强的零信任微隔离策略生成框架。该框架旨在打破传统网络层（L3/L4）与业务应用层（L7）之间的语义壁垒，构建具备全生命周期感知与自适应能力的防护体系。

本文的核心解决方案包含以下两个层面的技术创新：

\subsection{动静态深度融合的策略生成机制}

为了解决单一分析视角存在的“盲区”，本文设计了静态代码分析（Static Analysis）与动态运行时感知（Dynamic Monitoring）的双向校验机制，以实现策略生成的全覆盖与高精度。

在静态侧，系统引入了程序语言分析领域的经典工具 Soot 框架。Vallée-Rai 等人在 1999 年提出的 Soot 框架能够对 Java 字节码进行全程序分析（Whole-Program Analysis），构建高精度的类粒度调用图（Call Graph）\cite{Soot1999}。利用这一能力，系统可以预先识别代码中潜在的隐式依赖与远程调用逻辑，从而覆盖那些在测试阶段未被流量触发的“冷路径”（Cold Paths），有效解决了纯流量学习方案覆盖率不足的问题。

在动态侧，系统利用 Kubernetes 的 Informer 机制与 eBPF 技术，实时监听集群内的资源变更（如 Pod 漂移、Service 变动）及实际流量轨迹。Isovalent 的研究表明，通过内核层的 eBPF 探针可以无侵入地获取服务间的真实拓扑 \cite{Isovalent2023}。本文通过将静态分析提取的调用链路与动态采集的运行时拓扑进行图同构映射（Graph Isomorphism Mapping），既剔除掉了静态代码中未被加载的死代码（Dead Code），又补全了静态分析无法感知的动态反射调用，从而实现了策略生成的“高召回”与“低误报”。

\subsection{大模型驱动的语义对齐与合规解释}

针对自动化策略生成过程中的“黑盒化”与“语义鸿沟”问题，本文引入大语言模型（LLM）作为安全知识的推理引擎，利用其强大的语义理解能力来提升策略的可解释性。

首先，系统集成了 DeepWiki 仓库级依赖挖掘技术。Du 等人在 ACL 2025 上发表的研究指出，DeepWiki 能够跨越文件边界，精准提取代码库中的深层依赖关系 \cite{Du2025DependEvalBL}。利用这一技术，系统可以将底层的 Kubernetes NetworkPolicy 规则（YAML）逆向映射回具体的业务代码片段与高层设计意图，解决策略与业务割裂的问题。

其次，系统采用了思维链（Chain-of-Thought, CoT）推理技术。Wei 等人在 NeurIPS 上证明，通过引导大模型生成中间推理步骤，可以显著提升其处理复杂逻辑任务的准确性 \cite{wei2022chain}。本文利用 CoT 技术构建了双向解释机制：一方面，将自然语言描述的安全需求自动转化为形式化的 ACL 规则；另一方面，为每一条生成的阻断策略提供符合自然语言逻辑的“归因证据”，例如指出某条规则是基于哪个业务模块的数据库访问需求而生成的。Chen 等人的研究表明，这种基于代码语义的解释机制能够显著降低安全审计的认知门槛，使自动化策略满足合规性要求 \cite{chen2021evaluating}。

\subsection{研究意义}

本研究的学术与应用意义主要体现在以下两个方面：

\begin{enumerate}
    \item 理论意义：本文提出了一种融合程序语言分析（PL）与网络安全（Security）的跨域建模方法。通过将代码级的静态语义与网络级的动态行为进行对齐，验证了利用大模型解决安全策略“语义鸿沟”的可行性，为零信任架构下细粒度访问控制的自动化研究提供了新的理论范式。

    \item 工程价值：通过自动化替代人工配置，本方案显著降低了大规模微服务集群的运维熵增（Entropy）。实测表明，该框架可将策略部署效率提升一个数量级，同时确保了在多云异构环境下的策略一致性，为企业核心业务上云提供了可落地、可审计且具备自愈能力的内生安全保障。
\end{enumerate}


\section{论文结构}

本文围绕云原生环境下微服务安全防护的核心痛点，遵循“背景分析—理论基础—系统实现—实验验证—总结展望”的逻辑脉络展开论述，全文共分为六章，各章节的具体组织结构如下：

第一章：绪论。
本章首先阐述了云原生技术范式的演进背景，剖析了在容器化与微服务架构下，传统边界防御失效、东西向流量不可视以及动态漂移等安全挑战，明晰了研究零信任微隔离技术的迫切性与工程意义。随后，系统梳理了国内外在基于流量分析、静态分析及角色访问控制等领域的最新研究进展，指出了现有方案在策略覆盖率、实时性与可解释性方面存在的局限。最后，概括了本文的主要研究内容、创新点及全篇的组织架构。

第二章：相关技术概述。
本章为后续系统的设计与实现奠定理论与技术基础。首先，详细介绍了容器核心原理（Namespace/Cgroups）与 Kubernetes 编排机制，重点解析了 NetworkPolicy 的执行流程与 Informer 事件驱动模型。其次，阐述了 Soot 静态分析框架在 Java 字节码切片与调用图构建中的应用。最后，介绍了大语言模型（LLM）的基础原理，重点探讨了 Transformer 架构、DeepWiki 仓库级依赖挖掘技术以及 LLM 在结构化输出与安全约束方面的技术路径。

第三章：动静态分析的零信任网络策略生成系统。
本章详细论述了“确定性”策略生成子系统的设计与实现。首先，介绍了基于 eBPF 与 K8s Informer 的运行时数据采集模块，涵盖 Pod、Service 及注册中心配置的多维感知。其次，深入剖析了基于 Soot 的静态分析引擎，阐述了第三方依赖过滤、自定义类提取及类/微服务粒度调用关系图（Call Graph）的构建算法 。最后，提出了从服务拓扑到 Pod 标签的映射机制，以及具备冗余消除与冲突检测能力的最小化白名单生成算法。

第四章：基于大模型代码分析的零信任微隔离策略双向智能生成。
本章重点论述了引入 LLM 进行语义增强的“智能化”子系统。首先，构建了统一的多源信息采集机制，实现了 GitHub 仓库与 Kubernetes 运行时资源的精确绑定 。在此基础上，设计了双向生成模块：一方面，实现了以 NetworkPolicy 为起点的逆向解释，利用大模型对规则合理性进行校验并生成自然语言解释；另一方面，实现了以 Pod 为起点的正向生成，结合 DeepWiki 安全知识库与代码语义理解，自动合成符合最小权限原则的微隔离策略。

第五章：实验与分析。
本章对提出的框架进行了系统性的验证。首先介绍了基于双集群 Kubernetes 的实验环境搭建方案与包含 14 个典型云原生组件（如 Airflow, TiDB）的测试数据集 。随后，定义了真阳性率（TP）与假阳性率（FP）等评价指标。最后，对比分析了不同大语言模型（如 GPT-4o 与 DeepSeek R1）在策略校验任务中的性能表现，并对自动生成的策略数量与质量进行了统计验证，证明了本方案在精确性与安全性上的优势。

第六章：总结与展望。
本章对全文的研究工作与核心成果进行了全面总结，客观分析了当前系统在极端高并发场景下的性能瓶颈与局限性，并对未来在多云异构架构支持、边缘计算场景适配等方向的研究前景进行了展望。。



\section{本章小结}
本章介绍了云原生应用对分布式系统安全带来动态威胁与碎片化挑战的课题背景，并将零信任微隔离技术分类。从基于流量分析的策略生成、基于角色的访问控制、基于静态分析的策略生成这三类防护技术分别介绍了国内外的最新研究进展。之后，本章介绍了本文所设计和实现的零信任微隔离策略生成框架，并阐述了其中的挑战，工作与意义。最后，介绍了本文的论文结构。


\chapter{相关技术}
\label{sec:related_work}

本章重点阐述支撑零信任微隔离策略生成系统的核心技术基础。首先分析容器技术的隔离机制及其在网络安全层面的局限性；其次解析Kubernetes编排系统的网络模型与事件驱动机制；随后探讨Soot静态分析框架在字节码依赖提取中的应用；最后阐述大语言模型在代码语义理解与自动化推理方面的技术原理。

\section{容器技术}
\label{subsec:container_tech}

容器技术通过操作系统级的虚拟化实现应用的轻量级封装与隔离，是云原生架构的基石。不同于传统虚拟机（Virtual Machine, VM）依赖Hypervisor模拟硬件层，容器直接运行于宿主机内核之上，具备毫秒级启动与高密度部署特性~\cite{merkel2014docker}。

\subsection{命名空间与控制组机制}
容器的隔离性主要依赖于Linux内核提供的命名空间（Namespaces）与控制组（Cgroups）机制。命名空间负责实现资源的逻辑隔离，其中PID Namespace实现了进程视图的隔离，Network Namespace提供了独立的网络协议栈（包括网卡、路由表、防火墙规则），而Mount Namespace则通过挂载点隔离构建了独立的文件系统视图~\cite{kerrisk2013namespaces}。控制组（Cgroups）则负责对CPU、内存、磁盘I/O等物理资源进行配额限制与优先级调度，防止单一容器耗尽节点资源~\cite{menage2007cgroups}。

然而，容器的隔离本质上是共享内核的进程级隔离。相比于虚拟机的硬件级虚拟化，容器并未实现彻底的攻击面隔离。研究表明，一旦发生内核漏洞逃逸，攻击者极易突破命名空间限制获取宿主机权限~\cite{sultan2019container}，这对容器间的网络微隔离提出了更高的防护要求。

\subsection{联合文件系统}
容器镜像采用分层存储架构，通过联合文件系统（UnionFS）将不同的物理目录挂载到同一虚拟文件系统下。典型的实现如OverlayFS，利用下层（LowerDir）的只读镜像层与上层（UpperDir）的可读写容器层进行堆叠~\cite{brown2013overlayfs}。这种写时复制（Copy-on-Write, CoW）机制不仅优化了存储空间，也为静态分析提供了便利：通过解析只读镜像层的文件结构，可以在不运行容器的情况下提取应用制品（Artifacts），为后续的依赖分析提供数据源。

\subsection{容器网络接口标准}
随着容器生态的发展，容器网络接口（Container Network Interface, CNI）成为连接容器运行时与网络插件的标准规范~\cite{cncf2023cni}。CNI插件负责在容器创建时分配IP地址、配置网桥或虚拟网卡（veth pair），并负责路由表的维护。在云原生环境中，CNI插件（如Calico、Cilium）是实施微隔离策略的执行主体，它们通过拦截进出Pod的网络流量，依据预定义的策略进行放行或阻断。


\section{Kubernetes 容器编排技术}
\label{subsec:k8s_tech}

Kubernetes（K8s）作为当前云原生生态的事实标准，源于 Google 内部的 Borg 集群管理系统。它不仅是一个部署工具，更提供了一套用于构建分布式系统的声明式 API 和控制平面，为微服务的自动化治理提供了基础设施层面的支持~\cite{burns2016borg}。

\subsection{核心架构与资源抽象}
Kubernetes 采用典型的“控制平面-数据平面”解耦架构。控制平面（Control Plane）包含 API Server、Etcd、Scheduler 和 Controller Manager 等核心组件，负责维护集群的全局状态与调度决策；数据平面（Data Plane）则由运行在各工作节点上的 Kubelet 和 Kube-Proxy 组成，负责容器生命周期的具体执行与网络规则的维护。

在资源抽象层面，Kubernetes 引入了 Pod 作为最小调度单元，通过将紧密耦合的容器封装在共享的 Network 和 IPC 命名空间中，解决了微服务进程间的协同问题。Service 资源则提供了一组 Pod 的逻辑抽象与稳定的虚拟 IP（ClusterIP），利用标签选择器（Label Selector）屏蔽了后端 Pod IP 动态变化带来的寻址复杂性。这种基于标签的松耦合关联机制，是本文构建动态微隔离策略的核心依据。

\subsection{网络策略模型}
为了在扁平化的 Pod 网络中实现访问控制，Kubernetes 定义了 NetworkPolicy 资源对象。该对象本质上是一种以应用为中心的白名单防火墙规则，允许管理员通过 \texttt{podSelector} 和 \texttt{namespaceSelector} 精确界定流量边界，控制入站（Ingress）与出站（Egress）的通信权限~\cite{nist800190}。

值得注意的是，NetworkPolicy 仅定义了策略规范，其实际执行依赖于底层的 CNI 插件（如 Calico, Cilium）。虽然基于 iptables 或 IPVS 的传统实现能够满足基本的 L3/L4 隔离需求，但随着集群规模的扩大，海量规则的查找与更新面临显著的性能瓶颈。此外，原生 NetworkPolicy 缺乏对应用层协议（L7）的感知能力，无法防御基于合法端口的逻辑攻击，这为引入代码级语义分析提供了必要性。

\subsection{Informer 事件驱动机制}

\begin{figure}[htbp]
  \centering
  \resizebox{1.0\textwidth}{!}{
    \begin{tikzpicture}[
        font=\sffamily\small,
        >=Stealth,
        basic box/.style={
            draw=gray!50,
            rectangle,
            rounded corners=3pt,
            minimum width=3.8cm,
            minimum height=1.3cm,
            align=center,
            fill=white,
            drop shadow={opacity=0.1, shadow xshift=1pt, shadow yshift=-1pt},
            inner sep=4pt,
            line width=0.7pt
        },
        ext box/.style={basic box, draw=gray!60, fill=gray!5, dashed},
        core box/.style={basic box, draw=blue!40, fill=blue!5},
        store box/.style={basic box, draw=orange!40, fill=orange!5},
        handler box/.style={basic box, draw=violet!40, fill=violet!5},
        line/.style={->, draw=gray!60, thick, rounded corners=4pt},
        label font/.style={font=\scriptsize\bfseries, text=gray!80}
    ]

    % --- 坐标定义 (x, y) ---
    % 第一行
    \node[ext box] (apiserver) at (0, 0) {\textbf{API Server} \\ \scriptsize (集群状态)};
    \node[core box] (reflector) at (5, 0) {\textbf{Reflector} \\ \scriptsize (监听与同步)};
    \node[core box] (fifo) at (10, 0) {\textbf{DeltaFIFO} \\ \scriptsize (增量对象队列)};

    % 第二行 (居中分布)
    \node[store box] (indexer) at (2.5, -3) {\textbf{Indexer / Store} \\ \scriptsize (本地线程安全缓存)};
    \node[core box] (informer) at (7.5, -3) {\textbf{Informer 控制器} \\ \scriptsize (事件处理循环)};

    % 第三行
    \node[handler box] (handler) at (7.5, -5.5) {\textbf{资源事件处理器} \\ \scriptsize (新增/更新/删除回调)};

    % --- 连线逻辑 (修正标注位置以防重叠) ---
    \draw[line] (apiserver.east) -- node[above, label font] {List-Watch 监听} (reflector.west);
    \draw[line] (reflector.east) -- node[above, label font] {同步增量} (fifo.west);
    
    % FIFO -> Controller (折线)
    \draw[line] (fifo.south) -- (10, -1.5) -| (informer.north) 
          node[pos=0.2, right, label font, xshift=2pt] {弹出事件};
    
    \draw[line] (informer.west) -- node[above, label font] {更新缓存} (indexer.east);
    \draw[line] (informer.south) -- node[right, label font, xshift=2pt] {分发触发} (handler.north);

    % 业务查询虚线 (绕开文字)
    \draw[line, dashed, gray!50] (handler.west) -- (2.5, -5.5) -- (indexer.south) 
          node[pos=0.3, above, label font] {只读业务查询};

    % --- 背景分组框 (文字移动到框外避免冲突) ---
    \begin{scope}[on background layer]
      \node[draw=gray!20, dashed, fill=gray!2, rounded corners=8pt, fit=(apiserver) (fifo), inner sep=12pt] (bg_cp) {};
      % 灰字移动到上方
      \node[anchor=south west, font=\scriptsize\bfseries, text=gray!40] at (bg_cp.north west) {Kubernetes 控制平面 (Control Plane)};

      \node[draw=blue!10, dashed, fill=blue!2, rounded corners=8pt, fit=(indexer) (handler), inner sep=15pt] (bg_client) {};
      % 蓝字移动到下方
      \node[anchor=north east, font=\scriptsize\bfseries, text=blue!30] at (bg_client.south east) {Client-go Informer 框架};
    \end{scope}

    \end{tikzpicture}
  }
  \caption{Kubernetes Informer 机制组件协作与事件驱动流程示意图}
  \label{fig:k8s_informer_structure_cn}
\end{figure}

在零信任安全体系中，策略引擎需要实时感知工作负载的生灭与漂移。若采用传统的轮询（Polling）方式查询 API Server，不仅时效性差，且会给控制平面带来巨大的负载压力。Kubernetes 客户端库（client-go）为此提供了 Informer 机制，如图\ref{fig:k8s_informer_structure_cn}所示，基于 List-Watch 接口实现了高效的事件驱动模型~\cite{Shamim2022}。



Informer 的核心组件包括 Reflector 和 Indexer。Reflector 负责与 API Server 建立长连接，实时监听（Watch）资源变更事件，并将增量数据写入 DeltaFIFO 队列；Indexer 则在客户端本地维护一份线程安全的只读缓存，通过索引加速数据检索。本文提出的策略生成系统深度利用了 SharedInformer 机制，能够在毫秒级延迟内捕获 Pod 的创建、销毁及标签变更事件，从而触发微隔离策略的动态计算与下发，解决了静态策略无法适应云原生动态环境的难题。

\section{Soot 静态分析技术}
\label{subsec:soot_tech}

Soot 是 Java 语言分析领域最通用的静态分析与优化框架之一，最初由麦吉尔大学 Sable 研究组开发。它通过将 Java 字节码（Bytecode）转换为中间表示（Intermediate Representation），提供了一套用于分析和转换 Java 程序的 API。在云原生微服务场景下，Soot 能够直接处理编译后的 \texttt{.class} 文件或 JAR 包，无需源代码即可提取类结构、继承关系及成员变量定义，为构建服务间的依赖关系提供了底层技术支撑~\cite{vallee1999soot}。

\subsection{Java 字节码与类文件解析}
Java 字节码是运行在 Java 虚拟机（JVM）上的二进制指令集。根据 JVM 规范，类文件（Class File）存储了类的全限定名、父类引用、接口实现列表、字段表（Fields）及方法表（Methods）。Soot 框架首先通过 \texttt{SootResolver} 组件加载类路径下的所有类文件，将其解析为内存中的 \texttt{SootClass} 对象。这一过程能够完整保留类的元数据信息，包括修饰符（public/private）、注解（Annotations）以及泛型签名，是后续识别 AOP 切面标记或依赖注入注解的基础~\cite{lindholm2014java}。

\subsection{Jimple 中间表示}
为了克服原生字节码基于栈架构（Stack-based）难以分析的缺点，Soot 引入了 Jimple 中间表示。Jimple 是一种基于类型的三地址码（3-Address Code），它将复杂的栈操作指令转换为显式的赋值语句（如 \texttt{x = y + z}）。

Jimple 的核心优势在于简化了控制流分析。在 Jimple 中，所有的实例方法调用（Invokevirtual）和接口调用（Invokeinterface）都被显式保留，且变量的定义与使用关系（Def-Use）清晰可见。这使得分析工具能够直接通过扫描 Jimple 语句（Statement）来识别代码中的方法调用行为，而无需模拟 JVM 的操作数栈行为~\cite{vallee2010soot}。

\subsection{类层次与结构分析能力}

\begin{figure}[htbp]
  \centering
  \resizebox{0.95\textwidth}{!}{
    \begin{tikzpicture}[
        font=\sffamily\small,
        >=Stealth,
        basic box/.style={
            draw=gray!50,
            rectangle,
            rounded corners=3pt,
            minimum width=3.8cm,
            minimum height=1.3cm,
            align=center,
            fill=white,
            drop shadow={opacity=0.1, shadow xshift=1pt, shadow yshift=-1pt},
            inner sep=6pt,
            line width=0.7pt
        },
        input box/.style={basic box, draw=gray!60, fill=gray!5, dashed},
        core box/.style={basic box, draw=blue!40, fill=blue!5},
        model box/.style={basic box, draw=orange!40, fill=orange!5},
        line/.style={->, draw=gray!60, thick, rounded corners=4pt},
        label font/.style={font=\scriptsize\bfseries, text=gray!80}
    ]

    % --- 节点定义 ---
    \node[input box] (bytecode) at (0,0) {\textbf{Java 字节码} \\ \scriptsize (.class / .jar 制品)};

    \node[core box] (resolver) at (0,-2.5) {\textbf{Soot 解析器} \\ \scriptsize (元数据加载)};
    \node[core box] (hierarchy) at (5,-2.5) {\textbf{层级分析器} \\ \scriptsize (类层次快速分析)};

    \node[model box] (inherit) at (0,-5.5) {\textbf{继承关系视图} \\ \scriptsize (Extends / Implements)};
    \node[model box] (fields) at (5,-5.5) {\textbf{成员字段模型} \\ \scriptsize (类型与注解扫描)};
    \node[model box] (methods) at (10,-5.5) {\textbf{方法签名视图} \\ \scriptsize (描述符)};

    % --- 连线逻辑 (避开文字冲突) ---
    \draw[line] (bytecode.south) -- node[right, label font, xshift=2pt] {加载资产} (resolver.north);
    \draw[line] (resolver.east) -- node[above, label font] {类型解析} (hierarchy.west);

    \draw[line] (resolver.south) -- node[right, label font, xshift=2pt] {提取建模} (inherit.north);
    \draw[line] (hierarchy.south) -- (fields.north);
    
    % 使用折线连接最右侧节点
    \draw[line] (hierarchy.east) -| (methods.north) 
          node[pos=0.3, above, label font] {上下文映射};

    % % 底部反馈线
    % \draw[line, dashed, gray!50] (methods.south) -- ++(0,-0.8) -| 
    %       node[pos=0.25, below, label font] {为第三章调用图构建提供基础数据} (inherit.south);

    % --- 背景分组框 ---
    \begin{scope}[on background layer]
      \node[draw=blue!10, dashed, fill=blue!2, rounded corners=8pt, fit=(resolver) (hierarchy), inner sep=15pt] (bg_core) {};
      \node[anchor=south west, font=\scriptsize\bfseries, text=blue!30] at (bg_core.north west) {Soot 核心分析引擎};

      \node[draw=orange!10, dashed, fill=orange!2, rounded corners=8pt, fit=(inherit) (methods), inner sep=15pt] (bg_model) {};
    %   \node[anchor=north east, font=\scriptsize\bfseries, text=orange!30] at (bg_model.south east) {提取出的程序结构模型};
    \end{scope}

    \end{tikzpicture}
  }
  \caption{Soot 框架类层次分析与程序结构提取流程示意图}
  \label{fig:soot_analysis_cn}
\end{figure}


如图\ref{fig:soot_analysis_cn}所示，Soot 提供了强大的类层次分析（Class Hierarchy Analysis, CHA）与结构提取能力，这是构建类之间静态依赖关系的核心机制：

\begin{itemize}
    \item 继承与实现关系分析：Soot 维护了一个全局的类层次结构树（Hierarchy），能够快速查询任意两个类是否存在继承（Extends）或接口实现（Implements）关系。这为识别基于多态的调用链路提供了必要的类型约束信息~\cite{dean1995optimization}。
    \item 成员变量与字段分析：通过 \texttt{SootField} 对象，Soot 允许分析人员遍历类中定义的所有成员变量及其类型。这在微服务分析中尤为重要，因为许多服务依赖是通过成员变量注入（如 \texttt{@Autowired} 或 \texttt{@Resource}）建立的。Soot 能够提取字段的声明类型，从而建立当前类与字段类型之间的关联边。
    \item 方法体与切面逻辑可见性：对于采用面向切面编程（AOP）的代码，编译后的字节码中往往包含由编译器织入（Weaving）的额外调用逻辑。Soot 对字节码的分析基于最终的编译产物，因此能够“看到”并解析这些由 AOP 框架自动生成的字节码指令，从而建立起切面类与目标类之间的关联。
\end{itemize}

综上所述，Soot 不仅是一个字节码转换工具，更提供了一个包含类结构、字段定义及方法签名的完整对象模型，为静态提取微服务内部复杂的类间依赖提供了完备的视图。



\section{大语言模型技术}
\label{subsec:llm_tech}

大语言模型（Large Language Model, LLM）是近年来人工智能领域的重要进展。在云原生安全领域，LLM 不仅需要理解单文件的代码逻辑，更需要具备跨文件的仓库级理解能力，以弥合“非结构化代码逻辑”与“结构化安全策略”之间的语义鸿沟~\cite{bommasani2021opportunities}。

\subsection{Transformer 架构与代码建模}
现代大语言模型主要基于 Transformer 架构，其核心创新在于引入了自注意力（Self-Attention）机制。对于代码分析任务，Transformer 的优势在于能够捕捉长距离的依赖关系（Long-range Dependencies）。通过多头注意力（Multi-Head Attention）机制，模型能够从不同的语义子空间同时关注代码的语法结构、数据流向及控制流逻辑，从而在没有显式编译过程的情况下理解程序的业务意图~\cite{vaswani2017attention}。

然而，通用 LLM 在处理代码任务时面临着显著的上下文窗口（Context Window）限制。微服务项目通常由数百个源文件组成，直接将整个仓库（Repository）输入模型会超出长度限制或导致“迷失中间（Lost-in-the-Middle）”现象，这使得模型难以捕捉跨文件的隐式依赖。

\subsection{DeepWiki：仓库级依赖挖掘框架}
为了解决大模型在全仓库理解上的瓶颈，DeepWiki 项目提出了一种基于 LLM 的仓库级依赖挖掘新范式。DeepWiki 的核心原理是将代码仓库视为一个巨大的知识库，通过“静态索引 + 动态检索”的方式实现对跨文件依赖的精准捕获~\cite{Du2025DependEvalBL}。

DeepWiki 的技术路径主要包含两个关键步骤：
\begin{enumerate}
    \item 语义索引构建：利用静态分析工具提取代码中的实体（如类、方法、变量）及其拓扑关系（如继承、调用、引用），构建项目级的代码知识图谱（Code Knowledge Graph）。同时，利用代码大模型生成每个实体的语义摘要（Summary），将其向量化后存入向量数据库。
    \item 上下文感知检索：当需要分析某个微服务的对外调用时，DeepWiki 不再输入全部代码，而是根据当前分析的焦点（如一个 Controller 类），在知识图谱中游走检索其关联的依赖节点（如 Service 接口及其实现类）。
\end{enumerate}

这种机制使得 LLM 能够在有限的上下文窗口内，获取到跨越多个文件的完整调用链路信息，从而准确识别出微服务间隐藏的远程调用逻辑。

\subsection{思维链推理与结构化生成}
在获取了完整的代码上下文后，利用思维链（Chain-of-Thought, CoT）技术可以进一步增强模型的推理鲁棒性。CoT 引导模型在生成最终的安全策略之前，显式地生成中间推理步骤（例如：“首先定位到 \texttt{OrderController}，发现其调用了 \texttt{PaymentService} 接口，经 DeepWiki 检索该接口实现类绑定了 \texttt{/api/pay} 路径”）。这种分步推理机制显著提高了策略生成的准确率，并缓解了深度学习模型的“黑盒”不可解释问题~\cite{wei2022chain}。

\section{本章小结}
\label{sec:chap2_summary}

本章对支撑零信任微隔离策略生成系统的关键技术进行了梳理。首先，分析了容器与 Kubernetes 编排机制，指出原生网络策略在动态环境下的局限性，并确立了基于 Informer 的实时数据采集方案。其次，探讨了 Soot 静态分析框架，利用 Jimple 中间表示与类结构分析能力，为从字节码中提取确定的服务依赖提供了理论支撑。最后，介绍了大语言模型及 DeepWiki 框架，论证了其在跨文件依赖挖掘与策略语义增强方面的优势。上述技术共同构成了本文动静态协同分析框架的工程基础。





\chapter{动静态分析的零信任网络策略生成系统}
\label{chap:system_design}

本章详细阐述动静态协同分析系统的总体架构与实现细节。针对云原生环境下微服务生命周期短、安全意图识别难等挑战，本系统设计了一套纵向贯穿基础设施到策略交付、横向融合动态运行时指纹与静态字节码逻辑的技术框架。

\begin{figure}[htbp]
  \centering
  \resizebox{0.9\textwidth}{!}{
    \begin{tikzpicture}[
        font=\sffamily\small,
        >=Stealth,
        % 统一方框样式
        basic box/.style={
            draw=gray!50,
            rectangle,
            rounded corners=3pt,
            minimum width=3.8cm,
            minimum height=1.2cm,
            align=center,
            fill=white,
            drop shadow={opacity=0.1, shadow xshift=1pt, shadow yshift=-1pt},
            inner sep=4pt,
            line width=0.7pt
        },
        infra box/.style={basic box, draw=gray!60, fill=gray!5, dashed},
        dyn box/.style={basic box, draw=blue!40, fill=blue!5},
        stat box/.style={basic box, draw=green!40!gray, fill=green!5},
        core box/.style={basic box, minimum width=9.5cm, minimum height=1.4cm, draw=orange!50, fill=orange!5, line width=1.2pt},
        out box/.style={basic box, draw=violet!40, fill=violet!5},
        line/.style={->, draw=gray!60, thick, rounded corners=4pt},
        label font/.style={font=\scriptsize\bfseries, text=gray!80}
    ]

    % --- 第一层：3.1 基础设施与采集入口 ---
    \node[infra box] (k8s) at (0, 0) {\textbf{Kubernetes 集群} \\ \scriptsize (运行环境)};
    \node[infra box] (bytecode) at (6, 0) {\textbf{Java 字节码制品} \\ \scriptsize (JAR / WAR 资源)};

    % --- 第二层：3.1 & 3.2 核心分析模块 ---
    \node[dyn box] (probe) at (0, 2.2) {\textbf{运行时探针} \\ \scriptsize (eBPF / K8s Informer)};
    \node[dyn box] (fingerprint) at (0, 4.2) {\textbf{动态指纹提取} \\ \scriptsize (环境变量 / 启动参数)};

    \node[stat box] (filter) at (6, 2.2) {\textbf{冗余过滤} \\ \scriptsize (依赖剔除 / 类过滤)};
    \node[stat box] (soot) at (6, 4.2) {\textbf{Soot 分析引擎} \\ \scriptsize (调用提取 / 污点分析)};

    % --- 第三层：3.3 动静态融合引擎 (核心) ---
    \node[core box] (graph) at (3, 6.5) {
        \textbf{微服务依赖图构建引擎 (Dependency Graph Builder)} \\
        \small 融合运行时拓扑 $G_{runtime}$ 与 静态调用链 $G_{static}$
    };

    % --- 第四层：3.4 策略交付层 ---
    \node[out box] (policy) at (0, 8.8) {\textbf{策略自动化生成} \\ \scriptsize (标签映射 / 白名单合成)};
    \node[out box] (conflict) at (6, 8.8) {\textbf{策略冲突消解} \\ \scriptsize (CIDR 聚合 / 逻辑检查)};

    % --- 连线逻辑 (紧凑路径) ---
    \draw[line] (k8s) -- node[left, label font] {事件流} (probe);
    \draw[line] (bytecode) -- node[right, label font] {制品流} (filter);
    \draw[line] (probe) -- (fingerprint);
    \draw[line] (filter) -- (soot);

    % 汇总至核心引擎
    \draw[line] (fingerprint.north) -- ++(0,0.5) -| ([xshift=-2.2cm]graph.south);
    \draw[line] (soot.north) -- ++(0,0.5) -| ([xshift=2.2cm]graph.south);

    % 分发至交付层
    \draw[line] (graph.north) -- ++(0,0.5) -| (policy.south);
    \draw[line] (graph.north) -- ++(0,0.5) -| (conflict.south);

    % --- 背景分组与标签 (避开冲突) ---
    \begin{scope}[on background layer]
      \node[draw=gray!20, dashed, fill=gray!2, rounded corners=6pt, fit=(k8s) (bytecode), inner sep=10pt] (bg_infra) {};
    %   \node[anchor=north west, font=\tiny\bfseries, text=gray!40] at (bg_infra.south west) {3.1 基础设施层};

      \node[draw=blue!10, dashed, fill=blue!2, rounded corners=6pt, fit=(probe) (fingerprint), inner sep=12pt] (bg_dyn) {};
      \node[anchor=south west, font=\tiny\bfseries, text=blue!30] at (bg_dyn.north west) {运行时感知模块};

      \node[draw=green!10, dashed, fill=green!2, rounded corners=6pt, fit=(filter) (soot), inner sep=12pt] (bg_stat) {};
      \node[anchor=south east, font=\tiny\bfseries, text=green!30] at (bg_stat.north east) {字节码分析模块};

      \node[draw=violet!10, dashed, fill=violet!2, rounded corners=6pt, fit=(policy) (conflict), inner sep=12pt] (bg_policy) {};
    %   \node[anchor=south east, font=\tiny\bfseries, text=violet!30] at (bg_policy.north east) {3.4 策略交付层};
    \end{scope}

    \end{tikzpicture}
  }
  \caption{动静态协同分析的零信任策略生成系统总体架构}
  \label{fig:system_architecture_refined}
\end{figure}

如图 \ref{fig:system_architecture_refined} 所示，系统整体架构严格遵循论文的逻辑脉络，由以下四个核心层级组成：

\begin{enumerate} 
    \item \textbf{基础设施层 (Infrastructure Layer)：} 位于架构底部，是整个系统的数据源头。该层涵盖了处于运行态的 \textbf{Kubernetes 集群}以及待分析的 \textbf{Java 字节码制品} .
    \item \textbf{动态感知与静态分析模块：} 承接基础设施层提供的数据流。
\begin{itemize}
    \item \textbf{动态感知模块}：利用 \textbf{运行时探针 (Probe)} 实时捕获集群事件，并执行 \textbf{动态指纹提取}，以获取环境变量与注册中心配置。
    \item \textbf{静态分析模块}：通过 \textbf{三级过滤漏斗} 剔除冗余依赖，随后驱动 \textbf{Soot 分析引擎} 对字节码进行调用提取与语义分析。
\end{itemize}

\item \textbf{微服务依赖图构建引擎 (Dependency Graph Builder)：} 作为系统的核心中枢，负责将动态感知的运行拓扑 $G_{runtime}$ 与静态分析得到的调用链 $G_{static}$ 进行深度融合。该引擎消除了动静态信息之间的“语义盲区”，构建出完整的服务依赖全景图。

\item \textbf{策略交付层 (Policy Layer)：} 处于架构顶端，基于融合后的依赖图执行 \textbf{确定性策略生成}。通过标签映射与白名单合成，并结合 \textbf{策略冲突消解} 模块，最终输出可落地的 Kubernetes NetworkPolicy。
\end{enumerate}

本章后续小节将围绕上述模块，依次论述各关键技术的具体设计思路与算法实现。







\section{运行时数据采集}
\label{sec:runtime_collection}
构建精确的零信任微隔离策略，首要前提是建立对云原生集群运行状态的全景感知。传统的静态分析技术往往因缺乏运行时上下文（Runtime Context），难以解析配置文件中的占位符或动态绑定的服务地址，导致生成的依赖关系图存在断裂或误判。为此，本系统设计并实现了一个轻量级的运行时采集探针（Collector），作为独立服务部署于 Kubernetes 集群中。

采集探针的设计遵循“无侵入”与“低开销”原则，负责收集以下四类关键数据，为后续的动静态协同分析提供确定性的环境输入：
\begin{enumerate}
    \item 编排元数据：包括 Pod、Service 等 Kubernetes 原生资源对象的生命周期状态与标签信息，用于构建网络层面的拓扑基座；
    \item 容器运行时信息：包括容器进程的环境变量、启动参数及文件系统挂载点，用于还原应用启动时的配置上下文；
    \item 应用资产（Artifacts）：指运行态容器内的 Java 字节码文件（JAR/WAR），作为静态依赖提取的直接输入源；
    \item 服务注册信息：包括 Nacos、Eureka 等注册中心维护的服务实例列表，用于解析微服务架构中的逻辑调用寻址。
\end{enumerate}

本节将详细阐述上述数据的采集机制及其工程实现。


\subsection{Kubernetes 资源}
\label{subsec:k8s_resource_collection}

Kubernetes 集群中的资源对象处于高频变更状态，Pod 的扩缩容、故障迁移（Failover）以及 Service 定义的更新都会直接影响微隔离策略的有效性。为了实现对集群资源拓扑的毫秒级感知，本系统摒弃了高延迟的 API 轮询（Polling）模式，转而采用基于 Kubernetes 官方客户端库 \texttt{client-go} 的 \textbf{SharedInformer} 事件驱动机制~\cite{dobies2020kubernetes}。

\subsubsection{基于 List-Watch 的增量同步机制}
采集器内部维护了一个针对核心资源的本地缓存（Local Cache）。在启动初期，采集器通过 \texttt{List} 接口从 API Server 拉取全量资源快照，建立初始索引。随后，通过建立长连接并调用 \texttt{Watch} 接口，实时监听资源对象的增量变更事件（Add、Update、Delete）。

具体而言，底层的 \texttt{Reflector} 组件负责将 API Server 推送的二进制流反序列化为资源对象，并存入 \texttt{DeltaFIFO} 增量队列中。采集器的主控制循环（Controller Loop）从队列中消费事件，更新本地的 \texttt{Indexer} 索引，并触发回调函数将变更数据结构化存储。这种机制确保了采集器与 API Server 之间的数据一致性，同时将对控制平面的网络压力降至最低~\cite{Burns2016DesignPF}。

\subsubsection{关键资源对象与采集维度}


为了支撑后续的静态分析与策略生成，如图\ref{fig:k8s_resource_mapping_final_v2},系统重点采集以下几类 Kubernetes 资源对象：

\begin{itemize}
    \item Pod：主要的采集对象是 \texttt{metadata.labels}（业务标签）、\texttt{status.podIP}（实际 IP）以及 \texttt{spec.nodeName}（所在节点）。其中，标签是微隔离策略 \texttt{podSelector} 的直接映射依据，必须确保实时准确。
    \item Service：主要的采集对象是 \texttt{spec.selector}（后端 Pod 选择器）与 \texttt{spec.clusterIP}（虚拟 IP）。这对于解析代码中硬编码的 ClusterIP 或通过 DNS 发现的服务名称至关重要。
    \item Endpoints/EndpointSlice：主要的采集对象是 Service 对应的实际后端 IP 列表。在某些未定义 Selector 的特殊服务（如外部数据库映射）场景下，Endpoints 是确定流量目标的唯一依据。
    \item ConfigMap 与 Secret：重点采集被业务 Pod 挂载的配置资源。Java 应用通常将数据库连接串、注册中心地址等敏感信息存储于这些对象中。采集器通过解析 Pod 的 \texttt{spec.volumes} 字段建立关联，获取配置文件的真实内容，从而在静态分析阶段将代码中的配置占位符（如 \texttt{\$\{DB\_URL\}}）替换为真实值。
    \item Namespace：主要的采集对象是命名空间的名称与标签，用于生成跨命名空间的隔离规则（\texttt{namespaceSelector}）。
\end{itemize}

\begin{table}[htbp]
  \centering
  \caption{Kubernetes 核心资源对象与策略生成维度的映射关系}
  \label{tab:k8s_resource_mapping}
  \resizebox{0.95\textwidth}{!}{
    \begin{tabular}{llp{5cm}l}
    \toprule
    \textbf{资源对象} & \textbf{关键字段 (Key Fields)} & \textbf{语义映射 (Semantic Mapping)} & \textbf{策略生成用途} \\
    \midrule
    \multirow{2}{*}{Pod} & \texttt{metadata.labels} & 工作负载身份标识 (Identity) & \texttt{podSelector} \\
                         & \texttt{spec.nodeName} & 物理拓扑位置 & 辅助故障域分析 \\
    \midrule
    Service & \texttt{spec.selector} & 逻辑服务分组 & 确定流量目标 \\
            & \texttt{spec.clusterIP} & 虚拟网络入口 & VIP 地址解析 \\
    \midrule
    EndpointSlice & \texttt{endpoints.addresses} & 实际后端 IP 列表 & 解析无头服务 (Headless) \\
    \midrule
    ConfigMap & \texttt{data} (Key-Value) & 应用配置上下文 & 提取数据库/中间件地址 \\
    \bottomrule
    \end{tabular}
  }
\end{table}

所有采集到的资源数据被封装为统一的 JSON 结构，并附带采集时间戳与集群标识（Cluster ID），通过消息队列异步推送至后端分析引擎，为构建全集群的服务依赖拓扑图提供元数据支撑。

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[
      font=\sffamily\small,
      >=Stealth,
      % 锁定方框尺寸，增强视觉紧凑感
      basic box/.style={
          draw=gray!50,
          rectangle,
          rounded corners=3pt,
          minimum width=3.4cm, 
          minimum height=1.0cm,
          align=center,
          fill=white,
          drop shadow={opacity=0.1, shadow xshift=1pt, shadow yshift=-1pt},
          inner sep=3pt,
          line width=0.7pt
      },
      resource box/.style={basic box, draw=blue!40, fill=blue!5},
      attr box/.style={basic box, draw=orange!40, fill=orange!5, minimum width=3.8cm},
      goal box/.style={basic box, draw=violet!40, fill=violet!5},
      % 连线样式优化
      line/.style={->, draw=gray!60, thick, rounded corners=2pt},
      label font/.style={font=\scriptsize\bfseries, text=gray!80}
  ]

  % --- 第一列：3.1.1 核心资源采集 (Namespace与Pod相邻，消除交叉) ---
  \node[resource box] (ns) at (0, 0) {\textbf{Namespace} \\ \scriptsize (隔离边界)};
  \node[resource box] (pod) at (0, -1.5) {\textbf{Pod} \\ \scriptsize (核心负载)};
  \node[resource box] (svc) at (0, -3.0) {\textbf{Service} \\ \scriptsize (寻址与发现)};
  \node[resource box] (config) at (0, -4.5) {\textbf{ConfigMap} \\ \scriptsize (配置上下文)};

  % --- 第二列：特征维度映射 (拉开水平距离，为右侧文字留出极大空间) ---
  \node[attr box] (dim_id) at (6.0, -0.75) {\textbf{身份标识维度} \\ \scriptsize 标签 / IP / 节点名};
  \node[attr box] (dim_net) at (6.0, -2.25) {\textbf{网络语义维度} \\ \scriptsize 选择器 / ClusterIP};
  \node[attr box] (dim_cfg) at (6.0, -3.75) {\textbf{应用配置维度} \\ \scriptsize 环境变量 / 连接串};

  % --- 第三列：策略合成目标 (水平位置移至11.5cm，彻底解决重叠) ---
  \node[goal box] (policy) at (11.5, -2.25) {\textbf{策略生成依据} \\ \scriptsize JSON数据};

  % --- 连线逻辑 (左侧无交叉平行连线) ---
  \draw[line] (ns.east) -- ++(0.8,0) |- (dim_id.west);
  \draw[line] (pod.east) -- ++(0.8,0) |- (dim_id.west);
  \draw[line] (svc.east) -- ++(0.8,0) |- (dim_net.west);
  \draw[line] (config.east) -- ++(0.8,0) |- (dim_cfg.west);

  % --- 右侧汇总标注 (空间错位排布，彻底消除重叠) ---
  
  % 上路：标识维度到策略 (文字位于折线平直段上方)
  \draw[line] (dim_id.east) -- ++(1.5,0) |- ([yshift=0.35cm]policy.west);
  \node[label font, anchor=south west] at (7.8, -0.75) {确定负载标识};

  % 中路：网络维度到策略 (文字位于直线中段上方)
  \draw[line] (dim_net.east) -- (policy.west);
  \node[label font, anchor=south, yshift=2pt] at (8.75, -2.25) {定义访问路径};

  % 下路：配置维度到策略 (文字位于折线起始段下方)
  \draw[line] (dim_cfg.east) -- ++(1.5,0) |- ([yshift=-0.35cm]policy.west);
  \node[label font, anchor=north west] at (7.8, -3.75) {解析隐式依赖};

  % --- 背景装饰 (灰字置于外部) ---
  \begin{scope}[on background layer]
    \node[draw=blue!10, dashed, fill=blue!2, rounded corners=8pt, 
          fit=(ns) (config), inner sep=12pt] (bg1) {};
    % \node[anchor=south, font=\scriptsize\bfseries, text=blue!30, yshift=6pt] at (bg1.north) {资源采集};

    \node[draw=orange!10, dashed, fill=orange!2, rounded corners=8pt, 
          fit=(dim_id) (dim_cfg), inner sep=12pt] (bg2) {};
    % \node[anchor=south, font=\scriptsize\bfseries, text=orange!30, yshift=6pt] at (bg2.north) {特征映射};
  \end{scope}

  \end{tikzpicture}
  \caption{Kubernetes 关键资源对象与策略采集维度映射示意图}
  \label{fig:k8s_resource_mapping_final_v2}
\end{figure}


\subsection{容器资源}
\label{subsec:container_resource_collection}



容器作为微服务代码的运行时载体，其文件系统中往往冗余了大量与核心业务无关的基础设施组件（如 Shell 工具、包管理器、调试工具等）。若直接对静态镜像进行全量分析，不仅会引入巨大的计算开销，更会导致微隔离策略生成算法产生大量误报（例如误将调试工具的网络行为纳入业务白名单）。

借鉴基于运行时分析的沙箱挖掘思想~\cite{Ghavamnia2020ConfineAS}，本系统设计了一套“活跃资产锁定（Active Artifact Locking）”机制。该机制通过深度交互容器运行时接口（CRI）与 Linux 内核数据结构，精准识别并提取“积极参与业务逻辑”的进程与文件，从而收敛分析边界。

\subsubsection{基于 CRI 的容器定位与元数据映射}
在 Kubernetes 的动态调度环境下，容器的生命周期与宿主机解耦。采集器首先通过 gRPC 协议连接节点上的 CRI Socket（如 \texttt{/run/containerd/containerd.sock}），调用 \texttt{ListContainers} 接口获取当前节点所有活跃容器的运行时状态。

系统通过解析 \texttt{ContainerStatus} 结构体，提取出容器的唯一标识符（Container ID）、关联的 Pod UID 以及镜像的哈希摘要（ImageRef）。这一步骤建立了“逻辑 Pod $\leftrightarrow$ 物理容器”的确定性映射，解决了 Overlay 网络掩盖下真实负载难以定位的问题，为后续进入容器命名空间（Namespace）提供了必要的句柄~\cite{cncf2023cri}。

\subsubsection{基于内存映射的活跃二进制集构建}

\begin{figure}[htbp]
    \centering
    % 使用 resizebox 自动缩放图片以适应当前行宽
    % 这样无论你画得有多宽，它都会自动缩放到页面宽度
    \resizebox{1.0\linewidth}{!}{
        \begin{tikzpicture}[
            font=\sffamily\small,
            >=Stealth,
            % --- 样式定义 ---
            % 1. 基础文件节点
            file node/.style={
                rectangle,
                draw=gray!40,
                minimum width=3.0cm,  % 稍微加宽
                minimum height=0.7cm,
                align=center,
                font=\footnotesize,
                inner sep=3pt,
                rounded corners=3pt
            },
            % 2. 活跃/休眠样式
            active file/.style={file node, draw=blue!50, fill=blue!10, text=blue!60!black, font=\footnotesize\bfseries},
            dormant file/.style={file node, draw=gray!30, fill=gray!5, text=gray!50, dashed},
            % 3. 背景容器框 (关键：inner sep 调大一点，避免贴边)
            container box/.style={
                draw=gray!50,
                fill=white,
                rounded corners=8pt,
                inner sep=12pt, 
                drop shadow={opacity=0.15, shadow xshift=3pt, shadow yshift=-3pt}
            },
            % 4. 内存条目 (这是最宽的部分)
            map entry/.style={
                rectangle,
                draw=orange!40,
                fill=orange!5,
                minimum width=5.5cm, % 给足宽度
                minimum height=0.7cm,
                font=\scriptsize\ttfamily,
                align=left,
                anchor=west,
                inner sep=5pt
            },
            % 5. 连线
            link line/.style={->, draw=blue!50, line width=1.2pt, rounded corners=5pt},
            filter line/.style={->, draw=gray!30, dashed, line width=0.8pt}
        ]

        % =============================================
        % 布局策略：拉大 X 轴间距
        % 第一列中心 x=0
        % 第二列中心 x=7.5 (之前是6) -> 避免中间撞左边
        % 第三列中心 x=15.0 (之前是11.5) -> 避免右边撞中间
        % =============================================

        % === 1. 左侧：容器镜像存储层 (x=0) ===
        \node[font=\bfseries\large] (fs_title) at (0, 5.2) {容器镜像层 (Storage)};
        \node[font=\footnotesize, text=gray] at (0, 4.7) {含冗余依赖与工具};

        \node[active file] (jar1) at (0, 3.6) {order-service.jar};
        \node[dormant file] (tool1) at (0, 2.6) {curl / busybox};
        \node[active file] (lib1) at (0, 1.6) {mysql-driver.jar};
        \node[dormant file] (jar2) at (0, 0.6) {unused-lib.jar};
        \node[dormant file] (tool2) at (0, -0.4) {debug-agent.jar};

        % 左侧背景
        \begin{scope}[on background layer]
            \node[container box, fit=(fs_title) (tool2)] (fs_box) {};
        \end{scope}

        % === 2. 中间：内核内存映射层 (x=7.5) ===
        \node[font=\bfseries\large] (mem_title) at (7.5, 5.2) {进程虚拟内存 (/proc/maps)};
        \node[font=\footnotesize, text=gray] at (7.5, 4.7) {仅包含被加载的段 (VMA)};

        % 注意：这里 x 坐标设为 5.0，因为 map entry 是 anchor=west (左对齐)
        % 这样文字会向右延伸，占据 5.0 到 10.0 的空间
        \node[map entry] (vma1) at (5.0, 3.6) {7f..00 r-xp ... /app/order-service.jar};
        \node[map entry, draw=gray!30, fill=gray!2, text=gray] (vma_heap) at (5.0, 2.6) {[heap] (Anon Memory)};
        \node[map entry] (vma2) at (5.0, 1.6) {7f..a0 r--p ... /lib/mysql-driver.jar};

        % 中间背景 (fit 包含标题和最宽的条目)
        \begin{scope}[on background layer]
            \node[container box, fit=(mem_title) (vma1) (vma2)] (mem_box) {};
        \end{scope}

        % === 3. 右侧：最终提取结果 (x=15.0) ===
        \node[font=\bfseries\large] (out_title) at (15.0, 5.2) {活跃资产列表 (Active Set)};
        \node[font=\footnotesize, text=gray] at (15.0, 4.7) {用于后续静态分析};

        \node[active file] (res1) at (15.0, 3.6) {order-service.jar};
        \node[active file] (res2) at (15.0, 1.6) {mysql-driver.jar};

        % 右侧背景
        \begin{scope}[on background layer]
            \node[container box, fit=(out_title) (res2) (res1)] (out_box) {};
        \end{scope}

        % === 4. 连线 (优化路径) ===
        % 活跃路径 (蓝色实线)
        \draw[link line] (jar1.east) -- (vma1.west);
        \draw[link line] (lib1.east) -- (vma2.west);
        \draw[link line] (vma1.east) -- (res1.west);
        \draw[link line] (vma2.east) -- (res2.west);

        % 过滤路径 (灰色虚线) - 增加节点文字说明
        \draw[filter line] (tool1.east) -- ++(1.5,0) node[right, font=\tiny, text=gray, inner sep=1pt] {Not Loaded};
        \draw[filter line] (jar2.east) -- ++(1.5,0) node[right, font=\tiny, text=gray, inner sep=1pt] {Not Loaded};
        \draw[filter line] (tool2.east) -- ++(1.5,0) node[right, font=\tiny, text=gray, inner sep=1pt] {Not Loaded};

        % === 5. 底部核心机制说明 ===
        % 宽度设为 14cm，居中放置
        % \node[draw=orange!50, fill=orange!5, rounded corners=5pt, text width=14cm, align=center, font=\small, inner sep=8pt]
        %     at (7.5, -2.2) {
        %     \textbf{核心机制：} 采集探针通过读取 \texttt{/proc/[PID]/maps}，利用内核的写时复制（CoW）特性，\\
        %     精准识别当前 JVM 进程实际持有的文件描述符（FD），自动过滤未使用的僵尸依赖。
        % };

        \end{tikzpicture}
    }
    \caption{基于内核内存映射的容器活跃资产锁定与提取原理}
    \label{fig:active_artifact_locking}
\end{figure}


为了剔除镜像中“存在但未运行”的僵尸文件，如图\ref{fig:active_artifact_locking}，本系统利用 Linux 内核的内存管理机制来识别当前活跃的业务代码。具体而言，采集器通过 \texttt{setns} 系统调用进入目标容器的 PID Namespace，读取目标进程的 \texttt{/proc/<PID>/maps} 内存映射文件。

该文件记录了进程虚拟地址空间中加载的所有可执行文件与动态链接库（Shared Libraries）。系统通过解析这些内存段，构建出当前容器的“活跃二进制集（Active Binary Set）”：
\begin{enumerate}
    \item 主执行体定位：识别映射具有 \texttt{r-xp}（可读可执行）权限且路径指向文件系统的主程序，过滤掉由 \texttt{entrypoint.sh} 或 \texttt{tini} 启动的父进程包装器；
    \item 解释器透视：对于 Java 应用，系统识别出 JVM 进程（如 \texttt{java} 二进制文件），并进一步扫描其打开的文件描述符（\texttt{/proc/<PID>/fd}），从而精准定位到被加载到内存中的 JAR 包或类文件，而非扫描整个 \texttt{/app} 目录；
    \item 动态库依赖：记录进程加载的 \texttt{glibc} 等基础库版本，这为后续基于二进制分析提取系统调用（Syscall）特征提供了必要的依赖上下文。
\end{enumerate}

这种基于运行时内存视图的采集方法，能够从根本上排除“镜像内打包了 \texttt{curl} 但业务从未调用”带来的策略噪声，确保后续分析仅聚焦于真实的业务实体。

\subsubsection{配置上下文与分层文件系统解析}
依据云原生应用的配置最佳实践，微服务的关键拓扑信息（如数据库地址、注册中心 URL）通常在启动时通过环境变量注入，而非硬编码于镜像中。

采集器通过读取容器进程的 \texttt{/proc/<PID>/environ} 文件，无侵入地提取全量环境变量键值对。同时，针对容器镜像采用的联合文件系统（UnionFS, 如 OverlayFS），系统解析 \texttt{/proc/mounts} 信息，区分 \texttt{LowerDir}（只读镜像层）与 \texttt{UpperDir}（读写容器层）。这使得分析引擎能够优先处理运行时产生的文件修改（Copy-on-Write），不仅还原了应用启动时的完整配置上下文，也确保了对热更新（Hot-Swap）代码的实时感知~\cite{oci2023runtime}。



\subsection{Java 字节码制品提取}
\label{subsec:bytecode_extraction}

在云原生应用中，业务逻辑被封装在 JAR（Java ARchive）或 WAR 包等二进制制品中。传统的静态分析方法往往采用“全量扫描”策略，即对容器镜像中的所有类库进行无差别分析。然而，生产环境的镜像中往往包含大量冗余的第三方依赖（Bloatware），这些代码在实际运行时从未被加载或者对实际的服务调用没有关联。若将这些非必要代码纳入分析范围，不仅会引入与业务无关的误报，还会导致后续调用图构建阶段出现严重的路径爆炸（Path Explosion）。

依据本文提出的“动静态结合”理念，本节设计了一种基于运行时内存映射的“活跃依赖锁定（Active Dependency Locking）”机制，旨在精准提取当前微服务实例真正使用的字节码制品。

\subsubsection{基于内存映射的活跃依赖识别}



JVM 的类加载机制（ClassLoader）决定了并非所有 ClassPath 下的 JAR 包都会被加载。为了获取真实的加载视图，采集器利用 Linux 内核提供的进程文件系统（procfs）进行透视。

具体而言，采集器通过读取容器内 Java 主进程的 \texttt{/proc/<PID>/maps} 内存映射文件，筛选出所有映射路径以 \texttt{.jar} 结尾的内存段。该文件记录了进程虚拟地址空间中所有动态加载的文件描述符。与静态扫描磁盘相比，这种方法的优势在于：
\begin{enumerate}
    \item 排除冗余：自动忽略存在于磁盘但未被 JVM 加载的“僵尸依赖”（例如未启用的数据库驱动或测试框架）；
    \item 解析动态路径：能够识别被自定义 ClassLoader 动态加载到非标准路径下的 JAR 文件；
    \item 处理软链接：通过解析文件描述符的真实路径（Real Path），自动处理符号链接导致的路径混淆~\cite{Ghavamnia2020ConfineAS}。
\end{enumerate}

\subsubsection{无侵入式流式传输通道}
为了将锁定的活跃 JAR 包提取至后端分析引擎，系统设计了基于 Kubernetes API 的流式传输通道。采集器不依赖 \texttt{docker cp} 等宿主机特权命令，而是与 API Server 建立 HTTP/2 长连接。



通过调用 \texttt{PodExec} 接口，采集器在目标容器内执行轻量级的 \texttt{tar} 打包命令，将筛选出的活跃 JAR 文件列表打包为二进制流，并通过标准输出（Stdout）管道实时传输。该过程采用了“零落地（Fileless）”策略，数据流直接在内存中转发，避免了在业务容器内创建临时文件，从而消除了对业务磁盘 I/O 的干扰及潜在的残留风险~\cite{kerrisk2010linux}。

\subsubsection{增量指纹比对与传输优化}
在微服务集群中，同一服务的多个副本（Replicas）共享完全相同的代码层，且不同服务之间往往存在公共的基础架构组件（如 Spring Cloud 全家桶）。全量传输所有 JAR 包将产生巨大的网络带宽开销。

为此，系统引入了基于 SHA-256 的增量指纹比对机制。在传输前，采集器在容器内计算目标文件的哈希摘要（Digest），并利用布隆过滤器（Bloom Filter）快速判断该哈希值是否已存在于分析引擎的制品库中。仅当检测到全新的哈希值（对应版本更新或新引入的依赖）时，才触发实际的数据传输。


\subsection{注册中心配置}
\label{subsec:registry_collection}

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[
      scale=0.95, 
      >=Stealth,
      % --- 样式定义 ---
      % 基础圆角框
      basic box/.style={
          rectangle,
          draw=gray!50,
          rounded corners=3pt,
          align=center,
          line width=0.8pt,
          inner sep=6pt,
          fill=white
      },
      % 1. 异构源 (顶层)
      source box/.style={
          basic box,
          draw=violet!50,
          fill=violet!5,
          text width=5.0cm,
          minimum height=1.4cm
      },
      % 2. 适配器模块 (中间层)
      adapter box/.style={
          basic box,
          draw=blue!50,
          fill=white,
          text width=5.0cm,
          minimum height=1.6cm % 适当高度
      },
      % 3. 结果映射表 (底层)
      map box/.style={
          basic box,
          draw=green!50!black,
          fill=green!5,
          text width=10.0cm,
          minimum height=1.4cm
      },
      % 连线
      line/.style={->, draw=gray!60, thick, rounded corners=3pt}
  ]

  % === 1. 绘制背景区域 (暴力扩大坐标范围) ===
  % 之前是 y=2.2 到 -0.8 (太小)，现在改为 y=2.8 到 -1.5 (足够大)
  % x 范围保持 -6.2 到 6.2
  \fill[blue!2] (-6.2, 2.8) rectangle (6.2, -1.5);
  \draw[blue!30, dashed, rounded corners=6pt, line width=1pt] (-6.2, 2.8) rectangle (6.2, -1.5);
  
  % 背景标题 (放在框内顶部，y=2.3)
  \node[font=\bfseries\small, text=blue!60!black] at (0, 2.3) {统一采集适配器 (Collector Adapter)};

  % === 2. 放置节点 ===
  
  % 第一排：异构注册中心 (位置上移到 y=4.5，避开大背景框)
  \node[source box] (nacos) at (-3.2, 4.5) {
      \textbf{\small Nacos 集群} \\[3pt]
      \footnotesize (gRPC / UDP 推送流)
  };

  \node[source box] (eureka) at (3.2, 4.5) {
      \textbf{\small Eureka / Consul} \\[3pt]
      \footnotesize (HTTP 长轮询机制)
  };

  % 第二排：适配处理模块 (位置 y=0.5，处于背景框正中)
  \node[adapter box] (push) at (-3.2, 0.5) {
      \textbf{\small 事件监听模块} \\[3pt]
      \footnotesize 订阅 ServiceChange 事件 \\
      \footnotesize 实时增量更新
  };

  \node[adapter box] (poll) at (3.2, 0.5) {
      \textbf{\small 轮询调度模块} \\[3pt]
      \footnotesize 自适应间隔 (Adaptive) \\
      \footnotesize 全量比对 (Diff)
  };

  % 第三排：输出结果 (位置下移到 y=-3.2，避开大背景框)
  \node[map box] (result) at (0, -3.2) {
      \textbf{\small 全局服务寻址映射表 (Addressing Map)} \\[3pt]
      \footnotesize \texttt{Map<ServiceName, List<Instance>>}
  };

  % === 3. 连线 (垂直与汇聚) ===
  
  % 上 -> 中
  \draw[line] (nacos.south) -- (push.north);
  \draw[line] (eureka.south) -- (poll.north);

  % 中 -> 下 (直角汇聚)
  % 左路：从底部出来 -> 向下 -> 向右 -> 连入
  \draw[line] (push.south) -- (-3.2, -1.8) -| ([xshift=-2cm]result.north);
  
  % 右路：从底部出来 -> 向下 -> 向左 -> 连入
  \draw[line] (poll.south) -- (3.2, -1.8) -| ([xshift=2cm]result.north);

  \end{tikzpicture}
  \caption{异构注册中心数据的统一采集与映射机制}
  \label{fig:registry_adapter_fixed}
\end{figure}


在云原生微服务架构中，服务间的通信不再依赖静态 IP，而是通过服务注册与发现机制实现动态寻址。静态代码分析虽然能够提取出微服务间的逻辑调用关系（例如代码中硬编码的 \texttt{"http://payment-service/pay"}），但无法直接推导出 Kubernetes NetworkPolicy 所需的确切网络五元组（IP Block 或 Pod Selector）。为了建立“逻辑服务标识”与“物理网络实体”之间的映射视图，如图\ref{fig:registry_adapter_fixed},本系统设计了针对服务注册中心（Service Registry）的实时采集模块~\cite{Jamshidi2018MicroservicesTJ}。

\subsubsection{异构注册中心适配器设计}
鉴于企业技术栈的演进往往导致多种注册中心共存（例如存量应用使用 Eureka，新应用使用 Nacos），采集器采用了适配器模式（Adapter Pattern）构建统一的接入层。该层屏蔽了底层异构协议（如 Nacos 的 gRPC/UDP 推送、Eureka 的 HTTP 长轮询）的差异，向上层分析引擎提供标准化的 \texttt{ServiceInstance} 模型。

系统目前已内置支持云原生领域主流的服务发现协议：
\begin{itemize}
    \item Nacos：作为阿里巴巴开源的云原生服务发现平台，Nacos 支持基于 UDP 的服务变更推送。采集器通过模拟 Nacos Client 行为，订阅指定命名空间下的服务列表变更事件，能够实现毫秒级的实例上下线感知。
    \item Eureka/Consul：针对基于 HTTP 的注册中心，采集器实现了自适应轮询机制（Adaptive Polling）。通过分析服务变动的历史频率，动态调整拉取间隔（例如在发布窗口期加密轮询，在稳定期降低频率），在保证数据新鲜度的同时降低控制面负载~\cite{richardson2018microservices}。
\end{itemize}

\subsubsection{逻辑服务名到物理地址的动态映射}
采集器将从各注册中心获取的数据聚合为一张全局的“服务寻址映射表（Service Addressing Map）”。该表维护了 \texttt{Service Name} $\rightarrow$ \texttt{List<Instance IP, Port, Metadata>} 的实时对应关系。

在后续的策略生成阶段，该映射表发挥着关键的“桥梁”作用：例如当静态分析引擎识别到 Java 代码中发起对 \texttt{user-service} 的 OpenFeign 调用时，系统查询该表即可锁定目标服务在当前集群中所有活跃实例的 IP 集合。



\section{字节码静态分析}
\label{sec:static_analysis}

在完成运行时的制品采集后，分析引擎获得了去重后的业务 JAR 包。然而，现代微服务应用通常包含大量的第三方依赖库（Third-party Libraries），这些库的代码量往往是业务逻辑代码的数十倍。若直接对全量字节码构建调用图，不仅计算开销巨大，且容易引入与业务无关的调用路径（如日志框架内部的网络请求）。

为此，本节设计了一个“三级过滤漏斗”模型，依次执行第三方依赖剔除、非业务类过滤及核心调用链提取，确保静态分析仅聚焦于能够产生服务间交互的关键代码片段。

\subsection{第三方依赖包过滤}
\label{subsec:dep_filtering}

为了解决 Java 应用普遍存在的代码膨胀（Bloatware）问题，系统首先在 JAR 包粒度进行粗筛。该过程基于软件成分分析（SCA）思想，构建了一个包含 Maven Central 主流组件的“指纹黑名单库”~\cite{soto2021bloat}。

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[
      scale=0.95, 
      >=Stealth,
      font=\small, % 保持统一的罗马字体
      % --- 样式定义 ---
      % 基础框
      basic box/.style={
          rectangle,
          draw=gray!50,
          rounded corners=3pt,
          align=center,
          line width=0.8pt,
          inner sep=6pt,
          fill=white
      },
      % 1. 输入 (紫色)
      input box/.style={
          basic box,
          draw=violet!50,
          fill=violet!5,
          text width=5.0cm,
          minimum height=1.2cm
      },
      % 2. 处理步骤 (蓝色)
      process box/.style={
          basic box,
          draw=blue!50,
          fill=white,
          text width=4.5cm,
          minimum height=1.0cm
      },
      % 3. 判定菱形 (橙色)
      decision box/.style={
          diamond,
          draw=orange!50,
          fill=orange!5,
          text width=2.5cm,
          align=center,
          aspect=2.5, % 拉宽菱形
          inner sep=1pt,
          font=\footnotesize
      },
      % 4. 废弃桶 (灰色虚线)
      discard box/.style={
          basic box,
          draw=gray!40,
          fill=gray!5,
          dashed,
          text width=4.0cm,
          minimum height=3.0cm
      },
      % 5. 输出结果 (绿色)
      output box/.style={
          basic box,
          draw=green!50!black,
          fill=green!5,
          text width=5.0cm,
          minimum height=1.2cm
      },
      % 连线
      line/.style={->, draw=gray!60, thick, rounded corners=3pt},
      label font/.style={font=\scriptsize, text=gray!60, fill=white, inner sep=2pt}
  ]

    % === 节点布局 ===

    % 1. 顶部输入
    \node[input box] (start) at (0, 0) {
        \textbf{原始 JAR 包集合} \\[3pt]
        \footnotesize (全量 Classpath 依赖)
    };

    % 2. 第一层：指纹过滤
    \node[process box] (step1) at (0, -1.8) {
        \textbf{Step 1: SCA 指纹计算} \\
        \footnotesize (SHA-256 Hash)
    };
    
    \node[decision box] (check1) at (0, -3.6) {
        命中指纹\\黑名单?
    };

    % 3. 第二层：启发式过滤
    \node[process box] (step2) at (0, -5.6) {
        \textbf{Step 2: 包名启发式扫描} \\
        \footnotesize (Package Name Prefix)
    };

    \node[decision box] (check2) at (0, -7.4) {
        命中非业务\\通用前缀?
    };

    % 4. 底部输出
    \node[output box] (final) at (0, -9.5) {
        \textbf{候选业务依赖集合} \\[3pt]
        \footnotesize (用于静态分析)
    };

    % 5. 右侧：废弃区 (垂直居中于两个判定之间)
    \node[discard box] (trash) at (5.5, -5.5) {
        \textbf{被剔除的基础设施依赖} \\[5pt]
        \scriptsize $\bullet$ Spring Boot Starters \\
        \scriptsize $\bullet$ Netty / Tomcat \\
        \scriptsize $\bullet$ Logging Frameworks \\
        \scriptsize $\bullet$ Common Utils (Apache)
    };

    % === 连线逻辑 ===

    % 垂直主流程
    \draw[line] (start) -- (step1);
    \draw[line] (step1) -- (check1);
    \draw[line] (check1) -- node[midway, right, label font] {否 (No)} (step2);
    \draw[line] (step2) -- (check2);
    \draw[line] (check2) -- node[midway, right, label font] {否 (No)} (final);

    % 废弃流程 (向右折线)
    % Check1 -> Trash (上部)
    \draw[line] (check1.east) -| (trash.north)
        node[pos=0.3, above, label font] {是 (Yes)};

    % Check2 -> Trash (下部)
    \draw[line] (check2.east) -| (trash.south)
        node[pos=0.3, above, label font] {是 (Yes)};

  \end{tikzpicture}
  \caption{基于指纹与启发式规则的第三方依赖三级过滤流程}
  \label{fig:dep_filtering}
\end{figure}

如图\ref{fig:dep_filtering}，具体算法流程如下：
\begin{enumerate}
    \item 指纹计算：对输入的 JAR 包计算 SHA-256 哈希值；
    \item 黑名单匹配：将哈希值与指纹库进行 $O(1)$ 匹配。指纹库预置了 Spring Boot Starter、Netty、Jackson 等基础设施组件的哈希特征。
    \item 包名启发式过滤：对于未命中的 JAR 包（如企业私有二方库），进一步检查其包名（Package Name）。若包名匹配 \texttt{org.apache.*}、\texttt{org.springframework.*} 或 \texttt{io.kubernetes.*} 等标准前缀，且不包含特定业务关键词，则将其标记为非业务依赖进行剔除。
\end{enumerate}
通过该步骤，分析引擎能够过滤掉约 90\% 的基础设施代码，显著降低了后续 Soot 分析的内存压力。

\subsection{自定义类的启发式过滤}
\label{subsec:class_filtering}

在保留下来的业务 JAR 包中，仍存在大量不参与远程调用的数据对象（POJO）、工具类（Utils）或配置类（Configuration）。为了进一步收敛分析范围，系统利用轻量级的 ASM 字节码操作框架，在不加载完整类结构的情况下扫描常量池（Constant Pool），执行启发式过滤~\cite{Bruneton2002ASMAC}。

系统仅保留满足以下特征之一的“活跃类”：
\begin{itemize}
    \item 入口特征：包含 \texttt{@Controller}、\texttt{@RestController} 或 \texttt{@Schduled} 等注解的类，这通常是服务调用的起点；
    \item 出口特征：包含 \texttt{@FeignClient}、\texttt{@DubboReference} 等注解的接口或字段，这代表了明确的远程调用意图；
    \item 行为特征：常量池中包含 \texttt{"http://"}、\texttt{"https://"} 或常见服务名前缀字符串的类，提示可能存在编程式的网络请求。
\end{itemize}

\subsection{基于类的调用信息提取}
\label{subsec:invocation_extraction}

经过前两级过滤后，剩余的类被加载至 Soot 框架中生成 Jimple 中间表示。本节针对云原生环境中最常见的两种调用模式，设计了专用的提取器（Extractor）。

\subsubsection{声明式调用提取（OpenFeign/Dubbo）}
对于基于接口代理的声明式调用，分析引擎重点解析接口上的元数据注解。以 OpenFeign 为例，系统扫描所有带有 \texttt{@FeignClient} 注解的接口，提取 \texttt{name} 或 \texttt{value} 属性作为目标服务标识，提取 \texttt{path} 属性作为基础路径。同时，解析接口方法上的 \texttt{@RequestMapping} 注解，获取具体的 HTTP 动词与子路径。这些信息组合后，构成了确定的 \texttt{<Caller, CalleeService, Path>} 三元组。

\subsubsection{编程式调用提取（RestTemplate/WebClient）}

\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[
        scale=0.9, 
        transform shape,
        font=\sffamily\small,
        >=Stealth,
        % --- 样式定义 ---
        % 1. 左侧代码框
        java box/.style={
            rectangle,
            draw=gray!40,
            fill=white,
            rounded corners=4pt,
            align=left,
            font=\ttfamily\scriptsize,
            inner sep=8pt,
            drop shadow={opacity=0.1, shadow xshift=2pt, shadow yshift=-2pt}
        },
        % 2. 右侧 Jimple 代码块 (普通)
        jimple normal/.style={
            rectangle,
            draw=none, 
            fill=white,
            align=left,
            font=\ttfamily\scriptsize,
            inner sep=4pt,
            text width=6.5cm
        },
        % 3. 右侧 Jimple 代码块 (高亮 - 污点)
        jimple taint/.style={
            rectangle,
            draw=red!60,      % 红边框
            fill=red!5,       % 浅红背景
            align=left,
            font=\ttfamily\scriptsize,
            inner sep=4pt,
            text width=6.5cm,
            rounded corners=2pt
        },
        % 4. 结果框
        result box/.style={
            rectangle,
            draw=blue!50,
            fill=blue!5,
            rounded corners=4pt,
            minimum width=12cm,
            minimum height=0.8cm,
            align=center,
            font=\footnotesize\bfseries,
            inner sep=6pt
        },
        % 5. 标题
        header label/.style={
            font=\bfseries\small,
            text=gray!70!black,
            anchor=south west,
            yshift=2pt
        }
    ]

    % ================== 1. 左侧：Java 源代码 ==================
    \node[header label] at (0, 4.2) {1. 原始 Java 源代码 (Source Code)};

    \node[java box, text width=5.5cm] (java) at (2.8, 2.0) {
        \textcolor{blue!60}{String} srv = \textcolor{green!40!black}{"http://inventory"};\\[4pt]
        \textcolor{blue!60}{String} path = \textcolor{green!40!black}{"/api/v1"};\\[4pt]
        \textcolor{gray}{// 字符串拼接}\\[0pt]
        \textcolor{blue!60}{String} url = srv + path;\\[4pt]
        \textcolor{gray}{// 网络调用 (Sink)}\\[0pt]
        \textcolor{violet}{restTemplate}.getForObject(url, ...);
    };

    % ================== 2. 右侧：Jimple 中间表示 (积木式拼接) ==================
    \node[header label] at (8, 4.2) {2. Soot Jimple 中间表示 (IR)};

    % 2.1 顶部：污点源 (Source) - 直接用红色样式
    \node[jimple taint] (j_source) at (11.5, 3.2) {
        \textcolor{gray}{// 1. 常量定义 (Source)}\\
        r1 = \textcolor{green!40!black}{"http://inventory"};
    };
    
    % 2.2 中间：传播过程 (Process) - 普通样式，接在 Source 下方
    \node[jimple normal, below=2pt of j_source] (j_process) {
        r2 = "/api/v1";\\
        r3 = new StringBuilder;\\
        specialinvoke r3.append(r1);\\
        specialinvoke r3.append(r2);\\
        r4 = virtualinvoke r3.toString();
    };

    % 2.3 底部：汇聚点 (Sink) - 直接用红色样式，接在 Process 下方
    \node[jimple taint, below=2pt of j_process] (j_sink) {
        \textcolor{gray}{// 3. 远程调用 (Sink)}\\
        virtualinvoke r0.get(r4, ...);
    };

    % 2.4 给右侧整体加一个灰色大框 (作为背景容器)
    \node[rectangle, draw=gray!30, rounded corners=4pt, fit=(j_source)(j_sink), inner sep=4pt] (right_container) {};

    % ================== 3. 绘制连接线与标注 ==================
    
    % 红色数据流箭头 (从 Source 连到 Process 再连到 Sink)
    % 使用 explicitly defined coordinates 以防万一
    \draw[->, red!60, line width=1.2pt, rounded corners] (j_source.west) -- ++(-0.4, 0) |- (j_process.west);
    \draw[->, red!60, line width=1.2pt, rounded corners] (j_process.west) -- ++(-0.4, 0) |- (j_sink.west);

    % 右侧文字标签
    \node[right=2pt of j_source, font=\tiny\bfseries, text=red!70] {Taint Source};
    \node[right=2pt of j_sink, font=\tiny\bfseries, text=red!70] {Taint Sink};

    % 中间转换箭头 (Java -> Jimple)
    \draw[->, very thick, gray!40, dashed] (java.east) -- node[above, font=\scriptsize, text=gray] {Soot 编译} (right_container.west);

    % ================== 4. 底部结果 ==================
    \node[result box] (result) at (7.2, -1.5) {
        提取结果 (Extracted Dependency): \quad 
        \textcolor{blue!80}{\{ Service: "inventory", Method: "GET", Path: "/api/v1" \}}
    };

    % 提取箭头
    \draw[->, thick, blue!50] (right_container.south) -- (result.north);

    \end{tikzpicture}
    \caption{静态污点分析与调用提取示例}
    \label{fig:taint_analysis_example}
\end{figure}

对于直接使用 HTTP 客户端的编程式调用,如图\ref{fig:taint_analysis_example}，系统采用基于 Jimple 的静态污点分析（Static Taint Analysis）技术。
\begin{enumerate}
    \item Source 识别：将 URL 字符串常量或配置项标记为污点源；
    \item Sink 识别：将 \texttt{RestTemplate.getForObject()} 等网络请求方法标记为污点汇聚点；
    \item 数据流追踪：利用 Soot 的 \texttt{SmartLocalDefs} 分析器，逆向追踪网络请求方法的 URL 参数定义点。如果 URL 是由字符串拼接而成（如 \texttt{"http://" + serviceName + "/api"}），系统通过常量传播分析尝试还原其静态部分，并将动态部分标记为需在运行时解析的变量~\cite{Arzt2014FlowDroidPC}。
\end{enumerate}
这一机制使得系统能够从非结构化的代码中还原出隐含的服务依赖关系。



\section{调用关系图构建}
\label{sec:call_graph_construction}

经过字节码静态提取与运行时配置解析，系统已获取了大量离散的调用链路片段（Call Segments）。为了推导微服务间的全局依赖拓扑，本节提出了一种两阶段图构建算法：首先构建细粒度的类级调用图（Class-level Call Graph），以此为基础，结合微服务部署元数据，聚合生成粗粒度的微服务依赖图（Microservice Dependency Graph）。

\subsection{基于类的调用关系图}
\label{subsec:class_call_graph}

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[
      font=\sffamily\small,
      >=Stealth,
      scale=0.85, transform shape,
      % 类节点样式
      class box/.style={
          draw=blue!40,
          rectangle,
          rounded corners=3pt,
          minimum width=3.5cm, 
          minimum height=1.1cm,
          align=center, 
          fill=blue!5,
          drop shadow={opacity=0.1, shadow xshift=1pt, shadow yshift=-1pt},
          inner sep=4pt,
          line width=0.7pt
      },
      % 标注文字样式
      label font/.style={font=\scriptsize\bfseries, text=red!70},
      trans font/.style={font=\scriptsize\bfseries, text=orange!80}
  ]

  % --- 节点布局 ---
  
  % 左侧：发起关联的类 (类 C)
  \node[class box] (classC1) at (0, 1.5) {\textbf{OrderController} \\ \scriptsize (类 C1: 成员变量持有)};
  \node[class box] (classC2) at (0, -1.5) {\textbf{SecurityAspect} \\ \scriptsize (类 C2: 切面增强)};
  
  % 中间：核心业务类 (类 A)
  \node[class box] (classA) at (6, 0) {\textbf{OrderService} \\ \scriptsize (类 A: 业务逻辑核心)};
  
  % 右侧：远程调用接口 (类 B)
  \node[class box] (classB) at (12, 0) {\textbf{InventoryClient} \\ \scriptsize (类 B: Feign 远程接口)};

  % --- 连线逻辑 (展示关联与传递) ---
  
  % 1. 类 C1 -> 类 A (Has-A)
  \draw[->, thick, gray!60] (classC1.east) -- ++(1,0) |- ([yshift=0.2cm]classA.west)
        node[pos=0.4, above, label font] {持有边 (Has-A)};

  % 2. 类 C2 -> 类 A (Advise-A)
  \draw[->, thick, gray!60] (classC2.east) -- ++(1,0) |- ([yshift=-0.2cm]classA.west)
        node[pos=0.4, below, label font] {增强边 (Advise-A)};

  % 3. 类 A -> 类 B (Call-A / Has-A)
  \draw[->, thick, gray!60] (classA.east) -- (classB.west) 
        node[midway, above, label font] {直接调用};

  % --- 意图传递路径 (Highlighting the Intent Transitivity) ---
  \draw[->, line width=1.5pt, orange!60, dashed] (classC1.north) .. controls (3, 3) and (9, 3) .. (classB.north)
        node[midway, above, trans font] {意图传递：C1 $\rightarrow$ A $\rightarrow$ B};
        
  \draw[->, line width=1.5pt, orange!60, dashed] (classC2.south) .. controls (3, -3) and (9, -3) .. (classB.south)
        node[midway, below, trans font] {意图传递：C2 $\rightarrow$ A $\rightarrow$ B};

  % --- 背景说明 ---
  \begin{scope}[on background layer]
    \node[draw=gray!20, dashed, fill=gray!2, rounded corners=8pt, 
          fit=(classC1) (classC2) (classA) (classB), inner sep=20pt] (bg) {};
    \node[anchor=south, font=\scriptsize\bfseries, text=gray!40] at (bg.north) {示例：基于类关联的远程调用意图传递分析};
  \end{scope}

  \end{tikzpicture}
  \caption{复杂场景下类级调用关系图的关联传递示例}
  \label{fig:class_transitivity_example}
\end{figure}

在 Spring Cloud 等现代微服务框架中，服务间的调用往往被封装在复杂的对象关系之中。为了还原这些隐式联系，分析引擎构建了一个有向图 $G_{class} = (V_c, E_c)$，其中节点 $V_c$ 代表业务类（Class），边 $E_c$ 代表类与类之间的关联关系。

不同于传统仅基于函数调用的构图方法，本文针对云原生应用的开发范式，如图\ref{fig:class_transitivity_example},设计了以下三种特定类型的边生成规则，以解决依赖注入（DI）与面向切面编程（AOP）带来的断链问题：

\subsubsection{基于成员变量注入的关联边}
在 Spring 容器中，服务类通常通过 \texttt{@Autowired} 或 \texttt{@Resource} 注解将其他组件（如 \texttt{FeignClient} 接口）注入为成员变量。Soot 的类结构分析能力使得系统能够扫描所有字段定义。若类 $A$ 包含一个类型为 $B$ 的成员变量，且该变量带有注入注解，则建立一条 $A \rightarrow B$ 的\textbf“持有边（Has-A）”。这种边揭示了潜在的调用能力，即使代码中未显式出现 \texttt{new} 关键字~\cite{Tip2000ScalablePC}。

\subsubsection{基于继承与实现的泛化边}
为了处理多态调用，系统利用 Soot 的类层次分析（CHA）算法处理继承关系。若类 $A$ 继承自父类 $B$ 或实现了接口 $I$，则建立 $A \rightarrow B$ 或 $A \rightarrow I$ 的\textbf{“泛化边（Is-A）”}。在后续的路径搜索中，若遇到针对接口 $I$ 的调用，算法将自动扩展至其所有具体实现类 $A$，从而覆盖多态场景下的动态分派路径。

\subsubsection{基于切面的增强边}
微服务架构广泛使用 AOP 技术实现熔断、限流或日志记录。切面类（Aspect）通常通过 \texttt{@Before}、\texttt{@Around} 等注解绑定到特定的目标方法上，导致控制流在运行时发生隐式跳转。系统通过解析切面表达式（Pointcut Expression），识别出切面类 $A$ 与被增强类 $B$ 之间的绑定关系，建立 $A \rightarrow B$ 的“增强边（Advise-A）”。这确保了在分析调用链时，能够正确穿越由中间件引入的代理逻辑。

\subsection{基于微服务的调用关系图}
\label{subsec:service_dependency_graph}


\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[
      font=\sffamily\small,
      >=Stealth,
      scale=0.85, transform shape,
      % 类节点样式
      class box/.style={
          draw=blue!40,
          rectangle,
          rounded corners=2pt,
          minimum width=3.2cm, 
          minimum height=0.9cm,
          align=center, 
          fill=blue!5,
          line width=0.6pt
      },
      % 协议标注样式
      rpc label/.style={font=\scriptsize\bfseries, text=red!80, fill=white, inner sep=1pt},
      http label/.style={font=\scriptsize\bfseries, text=violet, fill=white, inner sep=1pt},
      service font/.style={font=\footnotesize\bfseries, text=gray!60}
  ]

  % --- 第一列：微服务 A (Order) ---
  \node[class box] (c1) at (0, 0) {OrderController};
  \node[class box] (s1) at (0, -1.8) {OrderServiceImpl};
  \node[class box] (f_inv) at (0, -3.6) {InventoryClient}; % 对应 RPC
  \node[class box] (f_pay) at (0, -5.4) {RestOrderClient}; % 对应 HTTP
  
  \begin{scope}[on background layer]
    \node[draw=gray!30, dashed, fill=gray!2, rounded corners=6pt, fit=(c1) (f_pay), inner sep=12pt] (svcA) {};
    \node[service font, anchor=south] at (svcA.north) {微服务 A (Order Service)};
  \end{scope}

  % --- 第二列：目标服务 B & C (Inventory & Payment) ---
  % 严格对齐 Y 轴坐标，防止箭头飘走
  \node[class box] (c2) at (8.5, -3.6) {InvController};
  \node[class box] (c3) at (8.5, -5.4) {PayController};

  \begin{scope}[on background layer]
    \node[draw=gray!30, dashed, fill=gray!2, rounded corners=6pt, fit=(c2), inner sep=10pt] (svcB) {};
    \node[service font, anchor=south] at (svcB.north) {微服务 B (Inventory)};
    
    \node[draw=gray!30, dashed, fill=gray!2, rounded corners=6pt, fit=(c3), inner sep=10pt] (svcC) {};
    \node[service font, anchor=south] at (svcC.north) {微服务 C (Payment)};
  \end{scope}

  % --- 连线逻辑 ---

  % 1. 服务内部调用
  \draw[->, gray!40, thick] (c1.south) -- (s1.north);
  \draw[->, gray!40, thick] (s1.south) -- (f_inv.north);
%   \draw[->, gray!40, thick, dashed] (s1.west) -- ++(-0.5,0) |- (f_pay.west) 
%         node[pos=0.75, left, font=\tiny, text=gray] {静态语义传递};

  % 2. 跨服务 RPC 调用 (A -> B) - 红色直线
  \draw[->, line width=1.2pt, red!60] (f_inv.east) -- (c2.west) 
        node[midway, rpc label] {RPC (Feign/Dubbo)};

  % 3. 跨服务 HTTP 调用 (A -> C) - 紫色直线
  \draw[->, line width=1.2pt, violet!60] (f_pay.east) -- (c3.west) 
        node[midway, http label] {HTTP/REST (RestTemplate)};

%   % --- 聚合结果 Es (置于最右侧，完全独立) ---
%   \draw[<->, line width=2pt, orange!40] (11, -1.0) -- ++(1,0) |- (11, -4.5) 
%         node[pos=0.25, right, font=\small\bfseries, text=orange!80] {聚合边 $E_s$: A $\to$ \{B, C\}};

  \end{tikzpicture}
  \caption{基于类级关联聚合的微服务调用关系图构建示例}
  \label{fig:service_graph_multi_protocol}
\end{figure}


类级调用图虽然精确，但其粒度过细，无法直接用于 Kubernetes NetworkPolicy 的生成。为此，如图\ref{fig:service_graph_multi_protocol}系统执行图聚合操作，构建以微服务为节点的有向图 $G_{service} = (V_s, E_s)$。

\subsubsection{节点映射与聚合}
首先，利用 3.1 节采集的 Kubernetes Pod 标签信息，建立“类 $\rightarrow$ 微服务”的归属映射函数 $M(c) = s$。对于 $G_{class}$ 中的每一个节点 $c \in V_c$，将其映射到对应的微服务标识 $s$。所有映射到同一 $s$ 的类节点被合并为一个微服务节点 $v_s \in V_s$。

\subsubsection{跨服务边的解析与生成}
遍历 $G_{class}$ 中的所有边 $(u, v)$，若 $M(u) \neq M(v)$，则表明存在潜在的跨服务调用。此时，分析引擎需结合 3.1.4 节采集的注册中心数据进行地址解析：
\begin{itemize}
    \item 声明式调用解析：若节点 $v$ 是一个被标记为 \texttt{@FeignClient("order-service")} 的接口，系统查询服务寻址映射表，找到 \texttt{order-service} 对应的微服务节点 $v_{target}$，并在 $M(u)$ 与 $v_{target}$ 之间添加一条有向边。
    \item 编程式调用解析：若节点 $u$ 中明确包含了指向 \texttt{"http://inventory-service"} 的 \texttt{RestTemplate} 调用（经 3.2.3 节污点分析提取），系统同样通过服务发现机制解析目标服务，并在图中建立依赖关系。
\end{itemize}

最终生成的 $G_{service}$ 清晰描述了集群内所有微服务之间的“谁调用谁”的拓扑结构，且每一条边都附带了具体的调用端口与协议元数据，为后续生成最小权限的 ACL 规则提供了完备的决策依据~\cite{Zhou2018FaultAA}。



\section{网络策略生成}
\label{sec:network_policy_generation}

微服务依赖图 $G_{service}$ 描述了系统内部合法的通信链路。为了将这些抽象的拓扑关系转化为 Kubernetes 集群可执行的访问控制规则，本节设计了一套自动化的策略生成算法。该算法遵循零信任架构的“最小权限（Least Privilege）”原则，通过标签映射、白名单合成及冲突消解三个步骤，生成确定性的 NetworkPolicy 资源对象。

\subsection{Pod 标签与服务拓扑映射机制}
\label{subsec:label_mapping}

Kubernetes NetworkPolicy 的核心机制是基于标签选择器（Label Selector）来界定策略的作用域（Target）与对端（Peer）。因此，策略生成的首要任务是将 $G_{service}$ 中的节点 $v_s$ 映射回集群运行时的 Pod 标签集合。

利用 3.1 节采集的 Kubernetes 编排元数据，系统建立了一个双向索引表：
\begin{equation}
Map: ServiceName \rightarrow \{ \langle Key, Value \rangle \}_{labels}
\end{equation}
映射逻辑如下：
\begin{enumerate}
    \item 服务发现映射：对于通过 Service 暴露的微服务，分析系统会解析 Service 定义中的 \texttt{spec.selector} 字段，将其作为该服务对应 Pod 的标识标签。
    \item 无头服务映射：对于 Headless Service 或未定义 Selector 的外部服务，系统通过解析 EndpointSlice 资源，获取后端 Pod 的实际 IP，若无法关联标签，则生成基于 \texttt{ipBlock} 的 CIDR 规则。
    \item 命名空间隔离：在映射过程中，严格保留命名空间（Namespace）上下文。若依赖图中存在跨命名空间的调用边，系统将在生成的规则中自动注入 \texttt{namespaceSelector}，以确保多租户环境下的隔离性~\cite{nist800204b}。
\end{enumerate}

\subsection{最小化白名单生成}
\label{subsec:whitelist_generation}



\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[
      font=\sffamily\small,
      >=Stealth,
      scale=0.9, transform shape,
      % 基础方框样式
      basic box/.style={
          draw=gray!50,
          rectangle,
          rounded corners=3pt,
          minimum width=3.8cm, 
          minimum height=1.1cm,
          align=center, 
          fill=white,
          drop shadow={opacity=0.1, shadow xshift=1pt, shadow yshift=-1pt},
          inner sep=5pt,
          line width=0.8pt
      },
      input box/.style={basic box, draw=orange!40, fill=orange!5},
      process box/.style={basic box, draw=blue!40, fill=blue!5},
      output box/.style={basic box, draw=violet!40, fill=violet!5, minimum width=4.8cm},
      % 连线与标注样式：使用白色背景遮罩，确保不压线
      line/.style={->, draw=gray!60, thick, rounded corners=3pt},
      label node/.style={font=\scriptsize\bfseries, text=gray!80, fill=white, inner sep=2pt}
  ]

  % --- 第一列：输入源 ---
  \node[input box] (g_svc) at (0, 0) {\textbf{微服务调用图 $G_{service}$} \\ \scriptsize (服务间意图集合)};
  \node[input box] (fingerprint) at (0, -3.0) {\textbf{动态运行指纹} \\ \scriptsize (端口/实例标签)};

  % --- 第二列：核心处理逻辑 ---
  \node[process box] (mapping) at (6.5, 0) {\textbf{身份与标签映射} \\ \scriptsize (App ID $\to$ Selector)};
  \node[process box] (port) at (6.5, -3.0) {\textbf{协议端口绑定} \\ \scriptsize (RPC/HTTP 端口识别)};

  % --- 第三列：输出结果 ---
  \node[output box] (policy) at (12.5, -1.5) {\textbf{零信任网络策略} \\ \scriptsize (Kubernetes NetworkPolicy)};

  % --- 连线逻辑 (精确控制标注位置) ---
  
  % 1. 水平直线连线
  \draw[line] (g_svc.east) -- (mapping.west) 
        node[midway, label node] {识别源/目实体};
        
  \draw[line] (fingerprint.east) -- (port.west) 
        node[midway, label node] {解析监听端口};

  % 2. 汇聚连线 (使用固定折点，防止箭头飘)
  \draw[line] (mapping.east) -- ++(1.5,0) |- ([yshift=0.35cm]policy.west);
  \node[label node, anchor=west] at (8.5, 0.4) {确定选择器范围};

  \draw[line] (port.east) -- ++(1.5,0) |- ([yshift=-0.35cm]policy.west);
  \node[label node, anchor=west] at (8.5, -3.4) {约束最小开放端口};

  % --- 背景装饰 (修正：使用绝对坐标锁定，确保框框绝对不歪) ---
  \begin{scope}[on background layer]
    % 定义一个完美的矩形框，手动指定左上角和右下角
    \draw[draw=violet!20, dashed, fill=violet!2, rounded corners=10pt, line width=0.6pt] 
      (4.2, 1.2) rectangle (15.2, -4.2);
    
    % \node[anchor=south, font=\scriptsize\bfseries, text=violet!40] at (9.7, 1.2) {3.4.2 最小化白名单生成逻辑};
  \end{scope}

  \end{tikzpicture}
  \caption{最小化白名单策略生成流程示意图}
  \label{fig:whitelist_generation_v4}
\end{figure}



基于“永不信任，始终验证”的零信任理念，本系统采用“默认拒绝 + 显式允许”的策略生成模式。对于依赖图中的每一个微服务节点 $v$，如图\ref{fig:whitelist_generation_v4}, 生成策略流程如下：

\subsubsection{基线策略构建}
首先为目标工作负载生成一条“隔离基线（Isolation Baseline）”策略。该策略将 \texttt{policyTypes} 设置为 \texttt{["Ingress", "Egress"]}，但不包含任何允许规则。一旦应用该策略，Kubernetes CNI 插件将立即阻断进出该 Pod 的所有非授权流量，从而收敛攻击面。

\subsubsection{白名单规则合成}
遍历图 $G_{service}$ 中与节点 $v$ 相关联的所有边，生成细粒度的放行规则：
\begin{itemize}
    \item 入站规则（Ingress）：对于所有指向 $v$ 的入边 $(u, v) \in E_s$，在 $v$ 的策略中添加一条 Ingress 规则，将来源设置为 $u$ 的标签选择器（\texttt{from: podSelector}），并严格限定目标端口（\texttt{ports}）为 $v$ 的监听端口。
    \item 出站规则（Egress）：对于所有由 $v$ 发出的出边 $(v, w) \in E_s$，在 $v$ 的策略中添加一条 Egress 规则，将目标设置为 $w$ 的标签选择器或 IP 段（\texttt{to: podSelector/ipBlock}）。
    \item 基础设施工单：自动注入对集群 DNS 服务（UDP 53端口）的放行规则，保障微服务的基础解析能力。
\end{itemize}

\subsection{策略冗余消除与冲突检测}
\label{subsec:policy_optimization}

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[
      font=\sffamily\small,
      >=Stealth,
      scale=0.9, transform shape,
      % 方框样式
      basic box/.style={
          draw=gray!50,
          rectangle,
          rounded corners=3pt,
          minimum width=3.8cm, 
          minimum height=1.1cm,
          align=center, 
          fill=white,
          drop shadow={opacity=0.1, shadow xshift=1pt, shadow yshift=-1pt},
          inner sep=5pt,
          line width=0.8pt
      },
      input box/.style={basic box, draw=violet!40, fill=violet!5},
      process box/.style={basic box, draw=red!40, fill=red!5},
      output box/.style={basic box, draw=green!40, fill=green!5, minimum width=4.5cm},
      % 标注样式：通过白色遮罩实现“切断”线条的效果
      line/.style={->, draw=gray!60, thick, rounded corners=3pt},
      label node/.style={font=\scriptsize\bfseries, text=gray!80, fill=white, inner sep=2pt}
  ]

  % --- 第一列：输入源 ---
  \node[input box] (raw) at (0, 0) {\textbf{原始候选策略} \\ \scriptsize (全量白名单规则)};
  \node[input box] (baseline) at (0, -3.0) {\textbf{安全基线库} \\ \scriptsize (全局禁止/限制规则)};

  % --- 第二列：核心处理逻辑 ---
  \node[process box] (dedup) at (6.5, 0) {\textbf{冗余消除引擎} \\ \scriptsize (掩码聚合与包含判定)};
  \node[process box] (conflict) at (6.5, -3.0) {\textbf{冲突检测模块} \\ \scriptsize (规则交集与优先级校验)};

  % --- 第三列：生成结果 ---
  \node[output box] (final) at (12.5, -1.5) {\textbf{精简安全策略} \\ \scriptsize (Minimized NetworkPolicy)};

  % --- 连线逻辑 (正交路径，标注自动避让) ---
  
  % 1. 原始策略处理
  \draw[line] (raw.east) -- (dedup.west) 
        node[midway, label node] {规则去重};
        
  % 2. 基线合规对比
  \draw[line] (baseline.east) -- (conflict.west) 
        node[midway, label node] {合规性扫描};

  % 3. 汇聚与优化 (使用绝对坐标偏移，防止线条打岔)
  \draw[line] (dedup.east) -- ++(1.5,0) |- ([yshift=0.35cm]final.west);
  \node[label node, anchor=west] at (8.5, 0.4) {策略掩码聚合};

  \draw[line] (conflict.east) -- ++(1.5,0) |- ([yshift=-0.35cm]final.west);
  \node[label node, anchor=west] at (8.5, -3.4) {解决逻辑冲突};

  % --- 背景装饰 (修正：绝对坐标手动锁定，确保背景框绝对不歪) ---
  \begin{scope}[on background layer]
    \draw[draw=red!20, dashed, fill=red!2, rounded corners=10pt, line width=0.6pt] 
      (4.2, 1.2) rectangle (15.2, -4.2);
    
    % \node[anchor=south, font=\scriptsize\bfseries, text=red!40] at (9.7, 1.2) {3.4.3 策略优化与校验引擎};
  \end{scope}

  \end{tikzpicture}
  \caption{策略冗余消除与冲突检测流程示意图}
  \label{fig:policy_optimization_flow}
\end{figure}

在大规模集群中，自动化生成的策略可能与运维人员手动配置的规则产生重叠或冲突。为了保证策略集的有效性与性能，如图\ref{fig:policy_optimization_flow}所示，系统在下发前执行基于集合论的优化算法。

\subsubsection{CIDR 聚合与冗余消除}
对于基于 IP 地址的 \texttt{ipBlock} 规则，系统采用区间合并算法（Interval Merging）对重叠的 CIDR 网段进行聚合。例如，规则 $R_1: 192.168.1.0/25$ 与 $R_2: 192.168.1.128/25$ 将被合并为 $192.168.1.0/24$。这不仅减少了底层 iptables/eBPF 的条目数量，也降低了策略匹配的计算开销。

\begin{table}[htbp]
  \centering
  \caption{微隔离策略冲突类型定义与系统消解动作}
  \label{tab:policy_conflict_matrix}
  \resizebox{1.0\textwidth}{!}{
    \begin{tabular}{lp{6cm}l}
    \toprule
    \textbf{冲突类型} & \textbf{逻辑定义 (Description)} & \textbf{系统消解动作 (Action)} \\
    \midrule
    冗余冲突 (Redundancy) & 新生成的规则 $R_{new}$ 是现有规则 $R_{exist}$ 的真子集 ($R_{new} \subset R_{exist}$)，且动作一致。 & \textbf{丢弃}：保留现有宽泛规则，减少规则数量。 \\
    \midrule
    遮蔽冲突 (Shadowing) & 现有规则 $R_{exist}$ 优先级更高且范围覆盖 $R_{new}$，但动作相反（如 $R_{exist}$ 为 Deny）。 & \textbf{报警}：提示策略无效，需人工介入调整优先级。 \\
    \midrule
    相关冲突 (Correlation) & $R_{new}$ 与 $R_{exist}$ 作用域部分重叠，且动作不同，导致重叠区域行为不确定。 & \textbf{拆分}：将重叠区域提取为独立的高优先级规则。 \\
    \midrule
    网段聚合 (Aggregation) & 多个 CIDR 规则连续（如 /24 相邻网段）且动作一致。 & \textbf{合并}：聚合为更大的 CIDR 块 (Supernetting)。 \\
    \bottomrule
    \end{tabular}
  }
\end{table}

\subsubsection{逻辑冲突检测}
系统定义了策略间的遮蔽（Shadowing）与泛化（Generalization）关系。在生成新策略前，系统会与集群现存策略进行集合包含关系检查：
\begin{equation}
Conflict(R_{new}, R_{exist}) \iff (Action_{new} \neq Action_{exist}) \land (Scope_{new} \cap Scope_{exist} \neq \emptyset)
\end{equation}
若检测到新生成的“拒绝”规则被现有的“宽泛允许”规则（如 \texttt{allow-all}）所遮蔽，系统将生成报告，提示存在潜在的安全敞口，而非盲目覆盖，从而确保了生产环境的稳定性~\cite{Cuppens2014}。。




\section{本章小结}
\label{sec:chap3_summary}

本章构建了基于动静态协同分析的零信任微隔离策略生成底座。首先，设计了基于 SharedInformer 与 CRI 的运行时探针，实现了对 Kubernetes 元数据、容器进程上下文及业务字节码的无侵入采集；其次，利用指纹去重与 Soot 静态分析框架，精准提取了微服务间的远程调用链路，并结合依赖注入与切面特征构建了服务级依赖拓扑；最后，遵循零信任最小权限原则，建立了从服务拓扑到 NetworkPolicy 的自动化映射与冲突消解机制，为系统提供了确定性的安全规则保障。



\chapter{基于大模型代码分析的零信任微隔离策略双向智能生成}
\label{chap:llm_analysis}

本章在上一章的物理拓扑基础之上，提出了一种\textbf{基于大语言模型（LLM）与 DeepWiki 代码知识库的双向智能生成框架}。该框架旨在引入外部语义知识，弥合底层基础设施与上层业务逻辑之间的鸿沟。

系统的总体架构如图 \ref{fig:llm_system_architecture_final} 所示，核心逻辑包含以下三个层次：

\begin{enumerate}
    \item \textbf{多源信息关联层 (Context Layer)}：针对云原生环境下容器运行时与静态代码割裂的痛点，本层并不重复底层的全量采集工作，而是聚焦于“关联”。通过引入 \textbf{LLM 仓库推断 (Repo Inference)} 模块，系统利用运行时捕获的环境变量、启动指令等指纹特征，智能推导并锁定目标容器对应的源代码仓库地址，从而建立起“运行时实例 $\leftrightarrow$ 静态代码库”的语义索引，为后续分析提供物理入口。
    
    \item \textbf{语义推理层 (Semantic Reasoning Layer)}：该层是本章系统的智能中枢，由两大核心组件构成。\textbf{DeepWiki 引擎}负责对代码仓库进行深度扫描，挖掘跨文件的隐式依赖与配置文件路径，构建代码知识图谱；\textbf{LLM 推理代理 (Reasoning Agent)} 则基于 DeepWiki 提供的知识上下文，利用思维链 (Chain-of-Thought, CoT) 技术执行复杂的逻辑推演，负责构建合规性证据链与意图识别。
    
    \item \textbf{双向生成与应用层 (Application Layer)}：基于推理层的语义理解能力，系统向上提供两种截然不同的工作模式，以覆盖微隔离的全生命周期需求：
    \begin{itemize}
        \item \textbf{逆向解释 (Inverse Explanation)}：面向存量系统的审计场景。系统接收现有的 NetworkPolicy，回溯代码层面的业务证据，生成包含因果归因的可解释性审计报告，解决“策略为何存在”的可解释性难题。
        \item \textbf{正向生成 (Forward Generation)}：面向新上线服务的防护场景。针对无历史流量的新服务，系统直接从代码逻辑中提取通信意图，生成默认安全的微隔离策略，解决“冷启动”阶段的防护难题。
    \end{itemize}
\end{enumerate}

通过这一架构，系统不仅弥补了确定性分析的语义盲区，更通过双向闭环机制，实现了从“被动防御”到“意图驱动”的智能化升级。

\begin{figure}[htbp]
    \centering
    \resizebox{1.0\textwidth}{!}{
        \begin{tikzpicture}[
            font=\sffamily\small,
            >=Stealth,
            basic box/.style={
                draw=gray!50,
                rectangle,
                rounded corners=3pt,
                minimum width=4.5cm,
                minimum height=1.4cm,
                align=center,
                fill=white,
                drop shadow={opacity=0.1, shadow xshift=1pt, shadow yshift=-1pt},
                inner sep=4pt
            },
            input box/.style={basic box, draw=gray!60, fill=gray!5, dashed, minimum width=4.0cm},
            process box/.style={basic box, draw=blue!40, fill=blue!5},
            core box/.style={basic box, minimum width=11cm, minimum height=1.6cm, draw=orange!50, fill=orange!5, line width=1pt},
            out box/.style={basic box, minimum width=4.8cm, draw=violet!40, fill=violet!5},
            group box/.style={draw=gray!35, dashed, inner sep=15pt, rounded corners=8pt},
            group label/.style={font=\scriptsize\bfseries, text=gray!80, fill=white, inner sep=4pt},
            line/.style={->, draw=gray!60, thick, rounded corners=4pt},
            thick line/.style={->, draw=gray!50, line width=1.2pt, rounded corners=4pt},
            bidirectional/.style={<->, draw=orange!60, thick, dashed}
        ]

        % 间距（已优化）
        \def\colsep{8.5}
        \def\rowsep{2.5}

        % 第一层：上下文锚定
        \node[input box] (runtime) at (0, 0) {运行时指纹\\(Runtime)};
        \node[input box] (code) at (\colsep, 0) {代码仓库\\(Code Repo)};
        \node[process box, minimum width=3.2cm, minimum height=1cm, fill=white, draw=blue!40] 
              (inference) at (\colsep/2, 0) {LLM 仓库推断\\(Inference)};

        % 第二层：语义推理引擎
        \node[core box] (deepwiki) at (\colsep/2, \rowsep*1.5) {
            \textbf{DeepWiki 代码语义理解引擎}\\
            跨文件依赖挖掘 / 动态配置路径推理 / 意图识别
        };
        \node[basic box, minimum width=10cm, minimum height=1.4cm, draw=orange!80, fill=white, dashed, 
              above=0.6cm of deepwiki] (llm) {
            \textbf{LLM 推理代理 (Reasoning Agent)}\\
            思维链 (CoT) 推演 / 证据链构建 / 审计判决
        };

        % 第三层：双向功能模块（左右对称）
        \node[process box, above left=1.6cm and 1.8cm of llm.north] (reverse) {逆向解释模块\\(Reverse Explanation)};
        \node[process box, above right=1.6cm and 1.8cm of llm.north] (forward) {正向生成模块\\(Forward Generation)};

        % 第四层：应用交付
        \node[out box, above=1.0cm of reverse] (report) {可解释性审计报告\\(Audit Report \& Evidence)};
        \node[out box, above=1.0cm of forward] (policy) {意图驱动策略生成\\(Intent-based Policy)};

        % ==================== 分组框与标签（标签上移，避免任何压线感） ====================
        \node[group box, fit=(runtime) (code) (inference)] (layer_context) {};
        \node[group label] at ([yshift=12pt]layer_context.north) {多源信息关联层 (Context Layer)};

        \node[group box, fit=(deepwiki) (llm)] (layer_core) {};
        \node[group label] at ([yshift=12pt]layer_core.north) {语义推理层 (Semantic Reasoning Layer)};

        \node[group box, fit=(reverse) (forward) (report) (policy)] (layer_app) {};
        \node[group label] at ([yshift=12pt]layer_app.north) {双向生成与应用层 (Application Layer)};

        % ==================== 连线 ====================
        \draw[line] (runtime) -- (inference);
        \draw[line] (inference) -- (code);

        \draw[thick line] (runtime.north) -- ++(0,0.6) -| ([xshift=-4.25cm]deepwiki.south);
        \draw[thick line] (code.north) -- ++(0,0.6) -| ([xshift=4.25cm]deepwiki.south);

        \draw[bidirectional] (deepwiki.north) -- (llm.south);

        % 关键修复：两条分支连线分开写，确保标注位置精准
        \draw[line] (llm.north) -- ++(0,1.3) -| (reverse.south) 
            node[pos=0.75, above, font=\tiny, text=gray]{Evidence Mining};
        \draw[line] (llm.north) -- ++(0,1.3) -| (forward.south) 
            node[pos=0.75, above, font=\tiny, text=gray]{Intent Extraction};

        % NetworkPolicy 输入
        % \node[left=1.0cm of reverse, font=\small, text=gray, align=center] (input_yaml) {Network\\Policy};
        % \draw[line, dashed] (input_yaml) -- (reverse.west);

        \draw[line] (reverse) -- (report);
        \draw[line] (forward) -- (policy);

        \end{tikzpicture}
    }
    \caption{基于大模型语义分析的双向策略智能生成系统架构}
    \label{fig:llm_system_architecture_final}
\end{figure}

\section{统一的多源信息采集与代码仓库关联机制}
\label{sec:multisource_collection}

在上一章中，系统通过运行时探针与字节码静态分析技术，从物理层面还原了微服务集群的网络拓扑结构，有效解决了“谁访问了谁”的链路发现问题。然而，这种仅依赖二进制制品（Artifacts）与底层网络状态的确定性分析方法仍存在显著的局限性：编译后的字节码虽然精准保留了程序的执行逻辑，却不可避免地丢失了开发者在编码阶段注入的大量关键语义信息，例如业务逻辑注释、架构设计文档、具有描述性的变量命名以及特定的代码组织结构。这些“元信息”承载了服务的设计初衷与业务意图，而它们的缺失直接导致了通用大语言模型（LLM）难以仅凭反编译代码或底层元数据进行高效、深度的逻辑推理 。


为了弥合这一底层运行状态与上层业务语义之间的“鸿沟”，并赋予大模型对云原生应用业务逻辑的深度认知能力，本节提出了一种跨越“运行时（Runtime）”与“开发态（Development）”的全链路溯源机制。该机制突破了传统分析仅局限于容器内部环境的限制，创新性地利用大模型的知识检索与推理能力，建立起从线上动态运行的 Pod 实例到线下静态代码仓库（Git Repository）的精准映射关系。通过这一机制，系统能够将碎片化的运行时指纹还原为完整的源代码上下文，从而为后续基于代码语义的智能策略生成构建完备的知识基座。

\subsection{运行时通用指纹特征的采集}
\label{subsec:runtime_fingerprinting}


\begin{figure}[htbp]
  \centering
  \resizebox{1.0\textwidth}{!}{
    \begin{tikzpicture}[
        font=\sffamily\small,
        >=Stealth,
        % --- 样式定义 ---
        basic box/.style={
            draw=gray!50,
            rectangle,
            rounded corners=3pt,
            minimum width=3.2cm,
            minimum height=1.1cm,
            align=center,
            fill=white,
            drop shadow={opacity=0.1, shadow xshift=1pt, shadow yshift=-1pt},
            inner sep=3pt,
            line width=0.7pt
        },
        scene box/.style={basic box, draw=gray!60, fill=gray!5, dashed},
        strategy box/.style={basic box, draw=blue!40, fill=blue!5, minimum width=3.8cm},
        data box/.style={basic box, draw=orange!50, fill=orange!5, minimum width=3.2cm},
        output box/.style={basic box, draw=violet!40, fill=violet!5, minimum width=5.0cm},
        line/.style={->, draw=gray!60, thick, rounded corners=3pt},
        clean label/.style={font=\scriptsize\bfseries, text=blue!50!black, inner sep=2pt, align=center, fill=white, fill opacity=0.8}
    ]

    % === 布局坐标 ===
    % 左：场景
    \node[scene box] (dev) at (0, 2.4) {\textbf{开发/测试环境} \\ \scriptsize Standard Image};
    \node[scene box] (prod) at (0, 0) {\textbf{生产/Distroless} \\ \scriptsize No Shell/Tools};
    \node[scene box] (secure) at (0, -2.4) {\textbf{受限/高安环境} \\ \scriptsize Runtime Restricted};

    % 中：策略
    \node[strategy box] (str1) at (5.0, 2.4) {\textbf{策略一：流式传输} \\ \scriptsize Exec + Stdout};
    \node[strategy box] (str2) at (5.0, 0) {\textbf{策略二：临时容器} \\ \scriptsize Ephemeral Debug};
    \node[strategy box] (str3) at (5.0, -2.4) {\textbf{策略三：静态解析} \\ \scriptsize Manifest Recursion};

    % 右：数据
    \node[data box] (proc) at (10.0, 2.4) {\textbf{活跃进程树} \\ \scriptsize PID 1 / Children};
    \node[data box] (cmd) at (10.0, 0) {\textbf{启动命令行} \\ \scriptsize Command / Args};
    \node[data box] (env) at (10.0, -2.4) {\textbf{关键环境变量} \\ \scriptsize APP\_ID / DB\_URL};

    % 底：输出
    \node[output box] (final) at (7.5, -4.2) {
        \textbf{通用运行时指纹向量 $\mathbf{f}_{rt}$} \\
        \scriptsize Unified Runtime Fingerprint
    };

    % 背景
    \begin{scope}[on background layer]
        \node[draw=blue!15, dashed, fill=blue!2, rounded corners=8pt,
              fit=(str1) (str3), inner sep=10pt] (bg) {};
    \end{scope}

    % === 连线逻辑 (全直角折线 Orthogonal) ===

    % 1. 场景 -> 策略 (水平直连)
    \draw[line] (dev) -- (str1);
    \draw[line] (prod) -- (str2);
    \draw[line] (secure) -- (str3);

    % 2. 策略 -> 数据 (分层折线)
    
    % --- S1 (Stream) ---
    % 直连 Proc
    \draw[line] (str1.east) -- (proc.west);
    
    % 折线连 Cmd (拐点 x=7.2)
    \draw[line] ([yshift=-2pt]str1.east) -- ++(0.3,0) |- ([yshift=3pt]cmd.west);
    
    % 大折线连 Env (拐点 x=8.0, 最外层通道)
    \draw[line] ([yshift=-4pt]str1.east) -- ++(1.1,0) |- ([yshift=4pt]env.west);

    % --- S2 (Debug) ---
    % 折线连 Proc (拐点 x=7.6)
    \draw[line] ([yshift=2pt]str2.east) -- ++(0.7,0) |- ([yshift=-2pt]proc.west)
        node[pos=0.25, clean label] {}; % 标签在水平段
    
    % 直连 Cmd
    \draw[line] (str2.east) -- (cmd.west)
        node[midway, above, clean label, yshift=-1pt] {};
        
    % 折线连 Env (拐点 x=7.6)
    \draw[line] ([yshift=-2pt]str2.east) -- ++(0.7,0) |- ([yshift=2pt]env.west);

    % --- S3 (Static) ---
    % 折线连 Cmd (拐点 x=7.2, 最内层通道)
    \draw[line] ([yshift=2pt]str3.east) -- ++(0.3,0) |- ([yshift=-3pt]cmd.west);
    
    % 直连 Env
    \draw[line] (str3.east) -- (env.west)
        node[midway, above, clean label, yshift=-1pt] {};

    % 3. 数据 -> 输出 (规整折线)
    \draw[line] (proc.east) -- ++(0.4,0) |- (final.east);
    \draw[line] (cmd.east) -- ++(0.4,0) |- (final.east);
    \draw[line] (env.east) -- ++(0.4,0) |- (final.east);

    \end{tikzpicture}
  }
  \caption{指纹采集逻辑图}
  \label{fig:adaptive_collection_orthogonal}
\end{figure}

为了在异构的多语言环境中准确识别服务归属，系统首先需要从容器运行时中提取具有普适性的“特征指纹”。这一过程的核心在于获取容器内部的进程执行上下文，而非依赖静态的镜像元数据。

采集模块主要关注以下三类关键运行时数据：
\begin{itemize}
    \item 关键环境变量：环境变量是云原生应用配置注入的主要载体。系统重点提取包含业务语义的变量，例如服务名称（\texttt{APP\_NAME}）、应用 ID（\texttt{APP\_ID}）或配置中心地址。这些变量通常在部署清单（Deployment YAML）中定义，是识别服务身份的强特征。
    \item 启动命令行：解析容器主进程（PID 1）的完整启动命令（Command）及其参数（Args）。无论是 Java 的 \texttt{-jar} 参数、Python 的入口脚本路径，还是 Go 二进制文件的名称，都直接暴露了程序的入口点信息。
    \item 活跃进程列表：扫描容器内当前运行的所有进程树信息，用于辅助判断容器的实际运行状态和技术栈类型（例如是否存在 \texttt{node}、\texttt{python} 或 \texttt{java} 进程）。
\end{itemize}

在数据采集的工程实现上，针对不同的镜像类型，本系统设计了三种自适应的采集策略。

\subsubsection{策略一：基于流式传输的数据采集}

该策略通过与 Kubernetes API Server 建立长连接，利用 SPDY 或 HTTP/2 协议建立流式传输通道。采集探针向目标容器发送标准化的 Shell 指令，直接读取标准输出（Stdout）流获取数据。
\begin{itemize}
    \item \textbf{优势}：实现简单，响应速度快，且无需在宿主机上预装任何代理。
    \item \textbf{适用场景}：开发测试环境或未进行严格镜像瘦身的传统微服务应用。
\end{itemize}

\subsubsection{策略二：基于临时容器的无侵入透视}
为了追求极致的安全与攻击面收敛，现代云原生生产环境大量采用了 Distroless 或 Scratch 等“极简镜像”。这类镜像移除了 Shell、\texttt{ls}、\texttt{ps} 等所有基础工具，导致常规的 \texttt{exec} 命令无法执行。针对这一难题，系统采用了基于\textbf{临时容器（Ephemeral Container）}的调试机制。

系统利用 Kubernetes 的 \texttt{Debug} 功能，动态地将一个包含完整工具集（如 BusyBox）的临时容器注入到目标 Pod 中，并配置其与业务容器共享进程命名空间（Process Namespace）。通过这种机制，采集探针可以在不重启业务 Pod、不修改原有镜像的前提下，获得对目标容器的“上帝视角”：
\begin{itemize}
    \item \textbf{进程透视}：临时容器可直接扫描 \verb|/proc| 文件系统，读取业务容器内 PID 1 进程的 \verb|/proc/<PID>/environ|（环境变量）和 \verb|/proc/<PID>/cmdline|（启动参数），从而规避了业务容器缺失 Shell 的限制，实现了全场景的无盲区采集\cite{kerrisk2013namespaces, Kubernetes2024Ephemeral}。
    \item \textbf{优势}：完全无侵入，不污染原镜像环境，符合“不可变基础设施”原则。
\end{itemize}

\subsubsection{策略三：基于元数据定义的静态解析}
在某些极端的高安全敏感场景下（如禁止任何形式的运行时注入或 Exec 操作），系统回退至基于 Kubernetes 元数据的静态解析策略。该策略不直接与容器运行时交互，而是深度遍历 Pod 的声明式定义文件（Manifest）。

采集器通过 Informer 机制监听 Pod 对象的变更，并执行级联解析逻辑：
\begin{enumerate}
    \item \textbf{环境变量展开}：解析 \verb|spec.containers.env| 字段，并递归查询 \verb|envFrom| 引用的 \textbf{ConfigMap} 和 \textbf{Secret} 资源。系统会自动处理 Kubernetes 的配置覆盖逻辑，合成出容器启动时最终生效的环境变量视图。
    \item \textbf{挂载卷分析}：遍历 \verb|spec.volumes| 定义，识别被挂载为文件的 ConfigMap，提取其中的关键配置项（如 \verb|application.properties|）。
\end{enumerate}
虽然该策略无法获取运行时动态生成的临时变量，但其作为“兜底方案”，保证了在运行时接口受限的情况下，依然能够获取服务注册中心地址、数据库连接串等核心拓扑信息。

\subsection{基于大模型的仓库推断}
\label{subsec:llm_inference}

在获取了容器运行时的通用指纹特征后，系统的核心任务是将这些非结构化的运行时“痕迹”映射回确定性的静态代码仓库地址。由于云原生生态中大量混用了开源基础设施（如 MySQL, Redis）与业务微服务（如 DevLake, TiDB 组件），传统的基于规则的匹配方法难以覆盖海量的组件类型。为此，本系统设计了一种基于大语言模型（LLM）的多视图融合推理机制。

该机制的核心在于构建一个包含严密推理逻辑的 Prompt 模板（即 \texttt{github\_code\_prompt}），引导大模型分四个步骤完成从运行时特征到 GitHub 仓库 URL 的零样本推断。



\subsubsection{多视图证据链构建}
为了提高推断的鲁棒性，系统并未单一依赖某项特征，而是要求模型综合分析以下三个视图的证据：

\begin{enumerate}
    \item \textbf{编排元数据视图（Orchestration Metadata View）}：
    模型首先被引导检查 Kubernetes 标准标签（Labels），特别是 \texttt{app.kubernetes.io/name} 或组件特有标签（如 \texttt{devlakeComponent}）。这些标签通常由 Helm Chart 注入，是识别项目身份的最强信号。
    
    \item \textbf{配置语义视图（Configuration Semantic View）}：
    当标签缺失或模糊时，模型进一步分析环境变量的语义特征。系统提示模型重点关注两类模式：一是服务端点特征（如 \texttt{*\_URL}, \texttt{*\_SERVICE\_*}），揭示了服务的交互对象；二是项目前缀特征（如 \texttt{MYSQL\_ROOT\_PASSWORD}, \texttt{MY\_RELEASE\_DEVLAKE\_}），这些前缀往往直接暴露了所属的软件家族。
    
    \item \textbf{执行语义视图（Execution Semantic View）}：
    模型最后检查容器的启动命令（Command）与参数（Args）。例如，通过识别二进制文件名（如 \texttt{mysqld}, \texttt{nginx}）或特定的启动参数标志，来确定容器内实际运行的主进程类型。
\end{enumerate}

\subsubsection{标准组件与业务项目的消歧}
在收集了上述证据后，大模型面临的一个关键挑战是如何区分“标准软件”与“项目组件”。提示词中明确注入了消歧逻辑：
\begin{itemize}
    \item 对于识别出的通用基础设施（Standard Software），如运行 \texttt{mysqld} 的容器，模型应将其映射至官方维护的仓库（如 \texttt{https://github.com/mysql/mysql-server}）；
    \item 对于隶属于大型微服务项目的组件（Larger Project），如 DevLake 的某个子服务，即使其底层基于 Python 基础镜像运行，模型也应优先将其归属到项目主仓库（如 \texttt{https://github.com/apache/incubator-devlake}），而非 Python 语言仓库。
\end{itemize}

\subsubsection{结构化输出约束}
为了确保推断结果能够被后续的 DeepWiki 引擎直接调用，Prompt 采用了严格的指令微调（Instruction Tuning）策略，强制限制模型的输出格式。模型被要求仅返回标准的 HTTPS 克隆地址（如 \texttt{https://github.com/owner/repo}），并自动剥离任何解释性文本。

通过这种“信息组装 + 逻辑引导 + 格式约束”的方式，系统充分释放了大模型在代码生态领域的知识记忆能力，实现了在无需人工维护规则库的情况下，对任意开源组件代码仓库的精准定位 \cite{chen2021evaluating}。



\subsection{基于 DeepWiki 的配置文件路径推理与采集}
\label{subsec:config_extraction}

在通过 4.1.2 节精准锁定微服务的源代码仓库后，为了深入解析服务内部的隐式网络依赖（如数据库连接地址、注册中心配置），系统需要进一步提取容器内的关键配置文件。然而，配置文件的存储路径在不同项目中差异巨大，且常受构建脚本（Dockerfile）或启动参数的动态影响。

针对这一难题，系统并非简单依赖通用大模型进行猜测，而是调用 DeepWiki 代码理解引擎，将 4.1.1 节采集的运行时上下文（Context）与代码仓库的静态结构相结合，执行基于证据的路径推理。

\subsubsection{跨模态路径推理机制}
系统构建了专用的推理提示词（\texttt{config\_file\_prompt}），驱动 DeepWiki 引擎在代码仓库中执行以下“动静结合”的搜索逻辑：

\begin{enumerate}
    \item \textbf{执行入口分析（Execution Entry Analysis）}：
    DeepWiki 首先结合运行时的主进程启动命令（Command/Args），在代码仓库中定位对应的入口点。例如，通过分析 \texttt{Dockerfile} 中的 \texttt{ENTRYPOINT} 或启动脚本（\texttt{docker-entrypoint.sh}），确定程序启动时实际加载的参数配置逻辑。

    \item \textbf{环境变量映射（Environment Variable Mapping）}：
    DeepWiki 扫描代码中对环境变量的读取逻辑。模型会检查运行时的环境变量（如 \texttt{MYSQL\_HOME}, \texttt{NACOS\_APPLICATION\_CONF}）是否在启动脚本中被引用，从而确定这些变量是否重定义了配置文件的默认加载路径。

    \item \textbf{构建指令追踪（Build Instruction Tracing）}：
    若无显式的运行时指定，DeepWiki 会回溯容器镜像的构建过程。通过分析 \texttt{Dockerfile} 中的 \texttt{COPY} 或 \texttt{ADD} 指令（例如 \texttt{COPY target/app.yml /config/application.yml}），直接推导出配置文件在镜像文件系统中的绝对路径，而非依赖通用的惯例路径。
\end{enumerate}

\subsubsection{输出约束与运行时验证}
为了保障自动化采集的稳定性，DeepWiki 被要求严格遵循输出协议，仅返回唯一的绝对文件路径（如 \texttt{/etc/my.cnf}）或 \texttt{None}。

获得推理路径后，系统利用 4.1.1 节所述的采集探针（Exec 或临时容器）在目标容器中进行实地验证与读取。这种机制利用 DeepWiki 的代码阅读能力解决了“找文件”的难题，同时利用运行时探针解决了“读文件”的权限问题，实现了对任意微服务配置的精准采集。通过这种“静态推导路径 + 动态验证读取”的方法，系统有效地解决了单纯静态分析无法获取运行时配置、单纯动态分析无法定位文件路径的矛盾。



\section{基于代码上下文的策略逆向解释机制}
\label{sec:policy_explanation}

通过 4.1 节构建的多源采集与关联机制，系统已成功打破了容器运行时的黑盒边界，建立了从动态 Pod 到静态代码仓库的确定性索引。然而，在零信任微隔离的实际运维场景中，仅拥有代码链接尚不足以解决“策略可读性差”的核心痛点。现有的 Kubernetes NetworkPolicy 资源对象通常以 YAML 格式存储，其描述语言仅包含抽象的标签选择器（Label Selector）与端口号（如 \texttt{allow port 8080}）。这种描述方式虽然满足了底层 CNI 插件的执行需求，却完全剥离了策略背后的业务语义。

对于安全运维与审计人员而言，面对成百上千条由 IP 段和端口构成的规则，往往陷入“知其然而不知其所以然”的困境：无法判断某条规则是承载了核心支付业务，还是仅仅为了通过健康检查；也难以确认该端口的开放是否符合代码层面的最小权限设计。这种“语义鸿沟（Semantic Gap）”不仅增加了误配置的风险，更严重阻碍了自动化策略在严格合规环境下的落地。

为此，本节提出了一种基于代码上下文的策略逆向解释（Reverse Explanation）机制。该机制视“代码”为解释网络行为的唯一真值来源（Source of Truth），通过将运行时状态完整输入 DeepWiki 引擎，从源代码层面反向推导策略的“调用意图（Intent）”与“支撑证据（Evidence）”，旨在将晦涩的底层 ACL 规则转化为具备可解释性、可审计性的自然语言报告。

\subsection{策略与工作负载信息的级联采集机制}
\label{subsec:policy_workload_collection}

要对一条抽象的网络策略进行语义解释，系统的首要任务是将其“锚定”到具体的业务实体上。Kubernetes NetworkPolicy 本质上是面向标签（Label-oriented）的声明式规则，它仅通过 \texttt{podSelector} 定义作用域，而不直接绑定具体的容器实例。因此，在调用 DeepWiki 引擎之前，系统必须执行一个逆向的级联采集流程，从静态的 YAML 规则出发，层层回溯至动态的 Pod 实例，最终锁定到静态的代码仓库，构建出完整的\textbf{“策略-实例-代码”}证据链。

\begin{figure}[htbp]
  \centering
  \resizebox{0.9\textwidth}{!}{
    \begin{tikzpicture}[
        font=\sffamily\small,
        >=Stealth,
        % --- 样式定义 ---
        basic box/.style={
            draw=gray!50,
            rectangle,
            rounded corners=3pt,
            minimum width=3.8cm,
            minimum height=1.0cm,
            align=center,
            fill=white,
            drop shadow={opacity=0.1, shadow xshift=1pt, shadow yshift=-1pt},
            inner sep=3pt,
            line width=0.7pt
        },
        % 左侧级联节点
        policy box/.style={basic box, draw=blue!40, fill=blue!5},
        pod box/.style={basic box, draw=gray!60, fill=gray!5, dashed},
        snap box/.style={basic box, draw=orange!50, fill=orange!5},
        repo box/.style={basic box, draw=violet!40, fill=violet!5},
        % 右侧聚合对象
        context box/.style={
            rectangle,
            draw=gray!40,
            fill=gray!2,
            rounded corners=4pt,
            minimum width=4.8cm,
            minimum height=5.2cm,
            inner sep=8pt,
            line width=0.8pt,
            drop shadow={opacity=0.15, shadow xshift=2pt, shadow yshift=-2pt}
        },
        % 连线与标签
        line/.style={->, draw=gray!60, thick, rounded corners=2pt},
        clean label/.style={font=\scriptsize\bfseries, text=blue!40!gray, inner sep=1pt, align=center, fill=white}
    ]

    % === 布局坐标 ===
    
    % --- 左列：级联溯源 ---
    \node[policy box] (policy) at (0, 3.8) {
        \textbf{NetworkPolicy ($P_{yaml}$)} \\[-1pt] 
        \scriptsize \texttt{spec.podSelector}
    };

    \node[pod box] (pod) at (0, 2.2) {
        \textbf{Sample Pod Instance} \\[-1pt] 
        \scriptsize Running State
    };

    \node[snap box] (snap) at (0, 0.6) {
        \textbf{Runtime Snapshot ($I_{runtime}$)} \\[-1pt] 
        \scriptsize Env / Command / Args
    };

    \node[repo box] (repo) at (0, -1.0) {
        \textbf{Code Repository ($R_{code}$)} \\[-1pt] 
        \scriptsize Git URL 
    };

    % --- 右列：上下文对象 ---
    \node[context box] (ctx) at (6.5, 1.4) {}; 
    
    % 标题
    \node[anchor=north west] at ([xshift=0.2cm, yshift=-0.2cm]ctx.north west) {
        \textbf{推理上下文对象 ($C_{context}$)}
    };
    
    % 内容区：去掉了错误的 leading 参数，利用 [4pt] 控制行距
    \node[anchor=north west, align=left, font=\scriptsize, text=gray!80] 
        at ([xshift=0.2cm, yshift=-0.8cm]ctx.north west) {
        \texttt{\{} \\[3pt]
        \hspace{1em} "policy\_target": "app=payment", \\[3pt]
        \hspace{1em} "runtime\_evidence": \texttt{[} \\[3pt]
        \hspace{2em} \textit{"env: DB\_URL=jdbc:mysql..."}, \\[3pt]
        \hspace{2em} \textit{"cmd: java -jar app.jar"} \\[3pt]
        \hspace{1em} \texttt{]}, \\[3pt]
        \hspace{1em} "source\_code": \texttt{\{} \\[3pt]
        \hspace{2em} "url": "github.com/...", \\[3pt]
        % \hspace{2em} "commit": "a1b2c3d" \\[3pt]
        \hspace{1em} \texttt{\}} \\[3pt]
        \texttt{\}}
    };

    % === 连线逻辑 ===

    % 1. 垂直级联
    \draw[line] (policy.south) -- (pod.north);
    \draw[line] (pod.south) -- (snap.north);
    \draw[line] (snap.south) -- (repo.north);

    % 左侧标签
    \node[anchor=east, font=\tiny, text=gray!50] at (-2.0, 3.0) {Reverse Lookup};
    \node[anchor=east, font=\tiny, text=gray!50] at (-2.0, 1.4) {Extract Context};
    \node[anchor=east, font=\tiny, text=gray!50] at (-2.0, -0.2) {Repo Inference};
    % 虚线指引
    \draw[gray!30, dotted, thin] (-1.9, 3.0) -- (-0.2, 3.0);
    \draw[gray!30, dotted, thin] (-1.9, 1.4) -- (-0.2, 1.4);
    \draw[gray!30, dotted, thin] (-1.9, -0.2) -- (-0.2, -0.2);

    % 2. 水平汇聚
    \draw[line] (policy.east) -- ++(0.5,0) |- ([yshift=1.8cm]ctx.west);
    \draw[line] (snap.east) -- ++(0.5,0) |- ([yshift=-0.5cm]ctx.west);
    \draw[line] (repo.east) -- ++(0.5,0) |- ([yshift=-1.8cm]ctx.west);

    % 3. 装饰点
    \node[circle, fill=blue!40, inner sep=1.5pt] at ([yshift=1.8cm]ctx.west) {};
    \node[circle, fill=orange!50, inner sep=1.5pt] at ([yshift=-0.5cm]ctx.west) {};
    \node[circle, fill=violet!40, inner sep=1.5pt] at ([yshift=-1.8cm]ctx.west) {};

    \end{tikzpicture}
  }
  \caption{策略与工作负载信息的级联采集机制}
  \label{fig:cascading_collection_compact_fixed}
\end{figure}

这一级联采集过程如图\ref{fig:cascading_collection_compact_fixed},包含以下三个关键步骤：

\subsubsection{基于选择器的策略-实例反向锚定}
系统首先通过 Kubernetes Informer 实时监听集群中的 \texttt{NetworkPolicy} 资源对象。当需要对某条策略进行解释时，解析引擎首先提取其 \texttt{spec.podSelector} 字段（目标选择器）以及 \texttt{policyTypes}（管控方向）。

由于标签选择器可能匹配多个 Pod 副本（例如一个 \texttt{app=payment} 的策略可能对应 10 个无状态副本），为了避免分析冗余，系统调用 Kubernetes API 的 \texttt{List} 接口，结合策略所在的命名空间（Namespace），反向查询出所有处于 \texttt{Running} 状态且标签命中的 Pod 实例列表。系统从中选取一个最具代表性的“样本 Pod”（通常是运行时间最长或最近重启的一个），将其作为后续语义分析的物理载体。这一步骤有效地将抽象的“策略作用域”具体化为了一个真实的“受控工作负载（Target Workload）”。

\subsubsection{面向策略验证的运行时上下文构建}
在锁定目标 Pod 后，系统并不重复 4.1 节所述的底层采集细节，而是聚焦于\textbf{提取与策略解释直接相关的运行时上下文}。针对该样本 Pod，系统构建包含以下关键信息的“运行时快照（Runtime Snapshot）”：

\begin{itemize}
    \item \textbf{网络配置上下文}：提取与网络连接紧密相关的环境变量（如 \texttt{DB\_HOST}, \texttt{Consul\_ADDR}, \texttt{PORT}）。这些变量往往是代码中网络行为的“配置源”，是后续 DeepWiki 验证端口开放合理性的关键线索。
    \item \textbf{进程执行上下文}：获取容器主进程的启动命令（Command）与参数（Args）。这决定了容器加载了哪个业务模块，帮助 DeepWiki 准确识别代码入口点。
\end{itemize}

\subsubsection{从实例到代码仓库的索引闭环}
最后，系统利用 4.1.2 节建立的仓库推断能力，将上述运行时指纹映射为确定的源代码仓库地址（Git URL）。

至此，系统成功构建了一个结构化的\textbf{推理上下文对象（Inference Context Object）}，其包含：
\begin{equation}
    C_{context} = \{ P_{yaml}, \ I_{runtime}, \ R_{code} \}
\end{equation}
其中 $P_{yaml}$ 为待解释的网络策略，$I_{runtime}$ 为 Pod 运行时快照，$R_{code}$ 为代码仓库索引。这一上下文对象打破了网络层与应用层的隔离，为后续 DeepWiki 引擎深入代码内部挖掘“该策略为何存在”提供了唯一的物理入口。

\subsection{容器级网络行为的局部推理机制}
\label{subsec:container_local_inference}

在 Kubernetes 的实际部署中，Pod 往往采用多容器协同模式（如 Istio 的 Sidecar 代理、日志采集器与业务容器共存）。为了精准归因网络流量的产生源头，系统采用了“分治”策略，首先对 Pod 内的每一个独立容器执行局部语义推理。

系统构建了专用的容器分析提示词（\texttt{container\_context\_prompt\_for\_explain}），设定大模型扮演“Kubernetes 网络安全专家”的角色，输入 4.2.1 节采集的单一容器上下文与当前 NetworkPolicy 摘要，执行以下标准化的推理流程。

\subsubsection{合理性优先的推理逻辑}

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[
      scale=0.9, transform shape,
      font=\sffamily\small,
      >=Stealth,
      % --- 样式定义 ---
      % 1. 基础容器：干净的圆角框，无多余装饰
      basic box/.style={
          rectangle,
          draw=gray!40,
          rounded corners=3pt,
          align=center,
          drop shadow={opacity=0.08, shadow xshift=1pt, shadow yshift=-1pt},
          line width=0.8pt,
          inner sep=6pt,
          fill=white
      },
      % 2. 输入层 (顶)
      input box/.style={
          basic box,
          draw=violet!50,
          fill=violet!5,
          text width=6.0cm,
          minimum height=1.0cm
      },
      % 3. 并行处理层 (左右分支)
      step box/.style={
          basic box,
          draw=blue!50,
          text width=4.0cm,
          minimum height=1.6cm
      },
      % 4. 核心逻辑层 (中间)
      core box/.style={
          basic box,
          draw=orange!50,
          fill=orange!5,
          text width=7.0cm,
          minimum height=1.2cm
      },
      % 5. 风险标记层 (红)
      risk box/.style={
          basic box,
          draw=red!50!black,
          fill=white,
          text width=6.0cm,
          minimum height=1.0cm
      },
      % 6. 输出层 (底)
      output box/.style={
          basic box,
          draw=green!50!black,
          fill=green!5,
          text width=6.0cm,
          minimum height=1.0cm
      },
      % 连线样式
      line/.style={->, draw=gray!60, thick, rounded corners=3pt}
  ]

  % === 1. 布局坐标 (使用相对坐标确保对齐) ===
  
  % 顶部输入
  \node[input box] (input) at (0, 4.5) {
      \textbf{单容器推理上下文 (Input)} \\[2pt]
      \scriptsize\texttt{Context + NetworkPolicy}
  };

  % 中间层：左右分支 (水平间距 7.0cm)
  \node[step box] (hard) at (-3.5, 2.2) {
      \textbf{1. 硬性约束扫描} \\[4pt]
      \scriptsize 解析 Dockerfile \texttt{EXPOSE} \\
      \scriptsize 建立基础网络指纹
  };

  \node[step box] (mining) at (3.5, 2.2) {
      \textbf{2. 多模态证据挖掘} \\[4pt]
      \scriptsize 扫描代码 \texttt{server.listen()} \\
      \scriptsize 解析 ENV \texttt{PORT=8080}
  };

  % 核心层
  \node[core box] (check) at (0, -0.2) {
      \textbf{3. 覆盖度验证 (Rationality Check)} \\[4pt]
      \scriptsize 假设策略合理 $\to$ 寻找支撑证据 \\
      \textbf{\textcolor{orange!60!black}{Evidence $\cap$ Policy Rules}}
  };

  % 风险层
  \node[risk box] (risk) at (0, -2.4) {
      \textbf{4. 风险上下文标记} \\[2pt]
      \scriptsize \textcolor{red!60!black}{标记未被策略覆盖的高危端口 (如 22)}
  };

  % 输出层
  \node[output box] (output) at (0, -4.2) {
      \textbf{结构化中间表示 (JSON IR)} \\[2pt]
      \scriptsize\texttt{policy\_mapping / key\_evidence}
  };

  % === 2. 连线逻辑 (显式拐点，杜绝乱线) ===
  
  % [分流路径] Input -> Hard / Mining
  % 逻辑：从 Input 底部向下走 0.5cm，然后水平分叉
  \draw[line] (input.south) -- (0, 3.6) -| (hard.north);
  \draw[line] (input.south) -- (0, 3.6) -| (mining.north);

  % [汇聚路径] Hard / Mining -> Check
  % 逻辑：从左右框底部向下走，汇聚到 (0, 1.0) 这一点，再单线向下
  % 左边路径：先下再右
  \draw[gray!60, thick, rounded corners=3pt] (hard.south) |- (0, 1.0);
  % 右边路径：先下再左
  \draw[gray!60, thick, rounded corners=3pt] (mining.south) |- (0, 1.0);
  % 统一向下箭头
  \draw[line] (0, 1.0) -- (check.north);

  % [垂直路径] Check -> Risk -> Output
  % 直接垂直连接
  \draw[line] (check.south) -- (risk.north);
  \draw[line] (risk.south) -- (output.north);

  % [装饰] 汇聚点的小圆点
  \node[circle, fill=gray!60, inner sep=1.2pt] at (0, 1.0) {};

  \end{tikzpicture}
  \caption{容器级网络行为的推理流程}
  \label{fig:rationality_reasoning_final}
\end{figure}


不同于常规的漏洞扫描工具侧重于“找茬”，本模块的设计目标是解决“可解释性”问题，流程如图\ref{fig:rationality_reasoning_final}。因此，提示词中明确植入了\textbf{“合理性优先（Rationality-First）”}的分析原则：即假设当前运行中的策略是满足业务可用性的，模型的首要任务是挖掘支撑该策略存在的“合法性证据”，仅在发现明显的端口错配或协议冲突时才标记为异常。

该逻辑包含四个递进阶段：
\begin{enumerate}
    \item \textbf{硬性约束扫描}：模型首先提取容器描述文件（Dockerfile/YAML）中显式声明的 \texttt{EXPOSE} 端口与协议，建立基础的网络指纹。
    \item \textbf{多模态证据挖掘}：提示 DeepWiki 深入扫描代码层面的隐式证据（如 Node.js 中的 \texttt{server.listen()}）、环境变量层面的配置证据（如 \texttt{PORT=8080}）以及配置文件中的绑定地址。这一步确保了“没有任何一条规则是凭空臆造的”。
    \item \textbf{覆盖度验证}：将上述证据与 NetworkPolicy 的 Ingress/Egress 规则进行比对。例如，验证策略放行的 TCP 3306 是否确实对应了容器内的 MySQL 进程，并生成自然语言解释：“MySQL 服务器监听 TCP 3306，客户端需通过此端口执行事务”。
    \item \textbf{风险上下文标记}：若发现容器内有未被策略覆盖的高危端口（如开放了 22 端口但策略未放行），模型将在输出中标记潜在的阻塞风险，为后续的聚合分析提供警示。
\end{enumerate}

\subsubsection{结构化中间表示（IR）}


为了支持大规模自动化分析，该环节的输出被严格约束为 JSON 格式的中间表示（Intermediate Representation, IR）。输出结构包含三个核心字段：
\begin{itemize}
    \item \texttt{policy\_mapping}：布尔值的匹配结果与对应的自然语言解释，直接回答“策略是否覆盖了需求”。
    \item \texttt{key\_evidence}：提取的代码片段或配置项列表，作为可追溯的审计证据。
    \item \texttt{pod\_context}：高度凝练的容器网络画像（如“Ingress TCP 8080 + Egress HTTPS API”），用于后续 Pod 级别的上下文聚合。
\end{itemize}

这种标准化的 JSON 输出屏蔽了不同大模型的行文风格差异，使得上层模块能够像处理数据库记录一样处理非结构化的语义解释。

\subsection{Pod 级全局上下文聚合与审计机制}
\label{subsec:pod_aggregation}


Kubernetes 的网络模型以 Pod 为最小调度单元，所有共享同一 Network Namespace 的容器（含初始化容器、Sidecar 代理及业务容器）共同对外呈现统一的 IP 地址与端口视图。然而，4.2.3 节的推理是基于单一容器视角的。为了应对 Sidecar 模式下的复杂流量特征（例如 Istio Proxy 接管流量、Prometheus Exporter 暴露指标），系统需要执行最后一步的全局上下文聚合与最终审计。

系统构建了聚合层提示词（\texttt{pod\_aggregation\_prompt}），将 4.2.3 节输出的所有容器级 JSON 中间表示组装成数组，连同完整的 NetworkPolicy YAML 一并输入大模型。模型被设定为“审计专家（Auditor）”，执行以下三个维度的全局推理：

\subsubsection{多源需求的并集聚合}
首先，模型需要解决“需求碎片化”问题。一个合法的 Pod 级 NetworkPolicy 必须同时覆盖 Pod 内所有容器的通信需求。
\begin{itemize}
    \item \textbf{规则归并}：模型遍历所有容器的 \texttt{container\_summary}，将业务容器的 \texttt{8080/TCP} 与 Sidecar 容器的 \texttt{15020/TCP}（健康检查）合并为统一的 Ingress 需求列表。
    \item \textbf{冲突消解}：若不同容器对同一端口的用途描述存在差异（极少见情况），模型依据代码证据的置信度进行加权，优先采信基于代码显式绑定（如 \texttt{server.listen}）的证据。
\end{itemize}

\subsubsection{基于证据的合规性裁决}
在构建了完整的 Pod 需求视图后，模型对比输入的 NetworkPolicy，进行最终的“Accept/Reject”二元裁决。为了保证工程落地的稳定性，系统在提示词中植入了严格的\textbf{“保守拒绝原则（Conservative Rejection Principle）”}：
\begin{itemize}
    \item \textbf{通过标准（Accept）}：只要策略覆盖了聚合后的所有核心业务端口，且未出现明显的协议冲突（如需求是 UDP 但策略仅允许 TCP），即判定为通过。此时，模型生成的解释报告会综合引用各容器的代码证据（如“Ingress 允许 3306，因为容器 A 的代码中 MySQL 监听了该端口”），形成完整的合理性论述。
    \item \textbf{拒绝标准（Reject）}：仅在发现“阻塞必需流量”或“高危配置冲突”等确凿错误时，才触发拒绝动作。模型必须在 \texttt{修复建议} 字段中输出具体的 YAML 修正片段，并严格遵循最小权限原则，不得臆造不存在的规则。
\end{itemize}

\subsubsection{标准化审计报告生成}
最终，系统将大模型的推理结果格式化为人类可读的 Markdown 报告。该报告包含四个标准板块：\textbf{评估结果}、\textbf{Pod 网络摘要}、\textbf{策略解释}以及\textbf{问题评估/修复建议}。

这种“分层推理（局部容器 $\rightarrow$ 全局 Pod）”的设计，不仅完美适配了 Kubernetes 的 Sidecar 模式，更通过最终的聚合校验，确保了生成的微隔离策略在保障安全的同时，绝对不会破坏复杂微服务架构下的业务可用性。 \cite{KubeGuard2025}。

\section{基于代码上下文的策略正向生成机制}
\label{sec:policy_generation}

通过前两节的阐述，系统已构建了从运行时状态到静态代码仓库的语义映射通道，并实现了对存量 NetworkPolicy 的深度审计与可解释性分析。然而，在零信任架构（Zero Trust Architecture）的完整生命周期中，仅具备“被动审计”能力尚不足以应对云原生应用的高频迭代需求。运维人员更迫切需要解决的是两个“主动治理”难题：一是在服务上线初期，如何在缺乏历史流量数据的情况下，\textbf{正向生成（Forward Generation）} 完备的初始白名单；二是在审计发现违规后，如何实现策略的 \textbf{自适应修复（Adaptive Remediation）}，形成安全运营的闭环。

传统的微隔离策略生成通常依赖于基于流量日志的统计学习方法（Learning-based）。这种方法存在本质的局限性：首先是具有显著的“滞后性”，必须等待业务流量实际发生后才能生成规则，这导致新上线的服务在“学习期”内处于裸奔或全阻断状态；其次是面临“噪声干扰”，难以区分正常的业务调用与恶意扫描流量，容易将攻击行为误学习为合法规则。

为了克服上述缺陷，本节提出了一种“基于代码意图（Intent-based）”的策略生成范式。该机制视源代码为网络行为的“第一性原理”，利用 DeepWiki 引擎从代码逻辑中直接提取确定的通信意图（如监听端口、上游依赖），从而在无流量基线的情况下生成精准的预定义策略，并结合大模型的推理能力实现审计问题的自动化修复。

\subsection{基于代码意图的正向策略生成机制}
\label{subsec:forward_policy_generation}

为了打破传统基于流量学习（Learning-based）方法的滞后性与盲目性，本系统提出了一种基于代码意图（Intent-based）的正向策略生成机制。该机制视源代码与运行时配置为网络行为的“第一性原理”，通过 DeepWiki 引擎执行严格的静态与动态证据挖掘，分别推导微服务的入站（Ingress）服务面与出站（Egress）依赖面，从而在无流量基线的情况下构建“默认安全”的白名单策略。

\begin{table}[htbp]
  \centering
  \caption{流量意图类型与 NetworkPolicy 规则合成逻辑对照表}
  \label{tab:intent_rule_synthesis}
  \resizebox{1.0\textwidth}{!}{
    \begin{tabular}{lp{5cm}p{6cm}}
    \toprule
    \textbf{流量意图类型} & \textbf{DeepWiki 检测逻辑} & \textbf{规则合成逻辑 (Rule Synthesis)} \\
    \midrule
    集群内服务调用 & 识别 K8s Service 名称或内部 DNS 域名 (e.g., \texttt{user-svc}) & 生成 \texttt{podSelector}，匹配目标服务 Labels。自动处理 \texttt{namespaceSelector}。 \\
    \midrule
    集群外 API 访问 & 识别公网域名 (e.g., \texttt{api.stripe.com}) & 解析 DNS 获取 IP 列表，生成 \texttt{ipBlock} (CIDR)。建议配合 Egress Gateway。 \\
    \midrule
    基础设施依赖 & 识别数据库/中间件连接 (e.g., \texttt{jdbc:mysql://...}) & 优先匹配集群内 StatefulSet；若为外部 RDS，则生成固定 IP 白名单。 \\
    \midrule
    基础网络服务 & 识别 DNS 解析请求 (UDP 53) & 自动注入 \texttt{kube-dns} 放行规则 (UDP/TCP 53)。 \\
    \bottomrule
    \end{tabular}
  }
\end{table}

\subsubsection{服务端点挖掘与 Ingress 规则构建}
针对入站流量，系统需要精准识别微服务对外暴露的监听端口。DeepWiki 引擎超越了简单的 Dockerfile \texttt{EXPOSE} 扫描，执行深度的代码逻辑分析：

\begin{itemize}
    \item \textbf{动态绑定识别}：针对 Kafka、Zookeeper 等通过配置动态决定监听地址的组件，系统追踪代码中的配置读取链（如 \texttt{config.get("listeners")}），结合 4.1.3 节采集的运行时配置值，解析出实际生效的端口集合，避免因默认值与实际配置不一致导致的策略漏配。
    \item \textbf{应用层 ACL 下沉}：若代码中存在硬编码的 IP 白名单检查（如 \texttt{if remote\_addr in allowed\_cidrs}），系统将这些应用层约束自动转化为 NetworkPolicy 中的 \texttt{ipBlock} 规则，实现安全能力的下沉。
\end{itemize}

\subsubsection{服务依赖拓扑与 Egress 规则构建}
针对出站流量，系统设计了专用的依赖分析提示词（\texttt{container\_egress\_prompt}），引导 DeepWiki 扮演“代码审计专家”角色，执行严格的证据驱动（Evidence-based）依赖提取。

该过程遵循“禁止假设”原则，仅在发现确凿证据时才生成规则，具体包含三个分析维度：

\begin{enumerate}
    \item \textbf{多源客户端调用扫描}：
    系统深入分析代码中的网络客户端库调用模式，涵盖数据库连接（如 \texttt{mysql.connect()}）、HTTP 请求（如 \texttt{axios.get()}）、RPC 调用（如 \texttt{grpc.Dial()}）以及中间件交互（如 \texttt{kafka.Producer()}）。通过解析函数参数，提取目标服务的连接特征。

    \item \textbf{环境与配置的语义对齐}：
    系统扫描环境变量（如 \texttt{DATABASE\_URL}）与配置文件（如 \texttt{application.yml}），解析其中的主机名、端口与协议。DeepWiki 能够智能区分“服务监听端口”（Ingress）与“客户端目标端口”（Egress），防止规则方向混淆。

    \item \textbf{内外部服务类型分类}：
    为了生成精确的 Kubernetes 选择器，系统对提取的目标地址进行分类处理：
    \begin{itemize}
        \item \textbf{集群内服务}：识别 \texttt{.svc.cluster.local} 后缀或短服务名（如 \texttt{redis}）。系统将其解析为对应的 \texttt{namespaceSelector} 和 \texttt{podSelector}，确保策略随 Pod 漂移自动适应。
        \item \textbf{外部服务}：识别公网域名或 IP 地址。系统结合 DNS 解析结果，生成指向特定 CIDR 的 \texttt{ipBlock} 规则，并建议开启 egress 域名白名单（如结合 Istio ServiceEntry）。
    \end{itemize}
\end{enumerate}

\subsubsection{证据链构建与策略合成}
为了保证自动生成策略的可审计性，系统要求 DeepWiki 输出严格的 JSON 格式证据链（Evidence Chain）。对于每一个生成的网络规则，系统都附带了以下元数据：
\begin{itemize}
    \item \textbf{代码证据}：具体的函数调用行号或配置项路径（例如：\texttt{env: MYSQL\_HOST=10.0.1.5}）。
    \item \textbf{业务目的}：基于代码上下文推断的流量用途（如“用户数据持久化”或“第三方支付 API 调用”）。
\end{itemize}

最终，系统将上述 Ingress 与 Egress 需求合并，转换为标准的 Kubernetes NetworkPolicy YAML 文件。这种机制确保了每一条生成的规则都有据可查，既实现了最小权限控制，又彻底消除了运维人员对“黑盒”自动生成规则的信任危机。

\subsection{基于 DeepWiki 的自适应策略生成与验证}
\label{subsec:adaptive_policy_generation}

在完成正向的意图提取后，系统的最后一步是将这些半结构化的依赖数据转化为标准、可执行且严谨的 Kubernetes NetworkPolicy 资源对象。为了确保生成策略的精确性并杜绝大模型的“幻觉”风险，系统设计了基于 DeepWiki 的自适应生成流水线。

该流水线包含三个核心处理阶段，严格遵循“无证据不生成（No Evidence, No Rule）”的原则。

\subsubsection{服务选择器的确定性锚定}

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[
      scale=0.9, transform shape,
      font=\sffamily\small,
      >=Stealth,
      % --- 样式定义 ---
      % 1. 基础容器风格 (统一圆角与阴影)
      basic box/.style={
          rectangle,
          draw=gray!40,
          rounded corners=2pt,
          align=center,
          drop shadow={opacity=0.08, shadow xshift=1pt, shadow yshift=-1pt},
          line width=0.8pt,
          inner sep=5pt
      },
      % 2. 输入层 (顶部)
      input box/.style={
          basic box,
          text width=5.0cm,
          minimum height=1.2cm,
          fill=white,
          draw=gray!50
      },
      % 3. 核心引擎层 (中间 - 宽体设计)
      core box/.style={
          basic box,
          draw=orange!50,
          fill=orange!5,
          text width=8.5cm,  % 宽体，涵盖上方两个输入
          minimum height=1.4cm,
          inner sep=6pt
      },
      % 4. 输出层 (底部)
      output box/.style={
          basic box,
          text width=5.0cm,
          minimum height=1.4cm
      },
      % 连线样式
      line/.style={->, draw=gray!60, thick, rounded corners=2pt},
      % 标签样式
      label text/.style={font=\tiny\bfseries, text=gray!50, fill=white, inner sep=1.5pt}
  ]

  % === 1. 输入层 (Input Layer) ===
  % 左输入
  \node[input box, draw=violet!50] (intent) at (-3.0, 2.4) {
      \textbf{代码意图 (Intent)} \\[-1pt]
      \rule{0pt}{9pt}
      \scriptsize\texttt{"target: redis-cart"}
  };

  % 右输入
  \node[input box, draw=blue!50] (anchor) at (3.0, 2.4) {
      \textbf{集群元数据 (Anchor)} \\[-1pt]
      \rule{0pt}{9pt}
      \scriptsize\texttt{Service Exists?}
  };

  % === 2. 处理核心层 (Processing Layer) ===
  \node[core box] (engine) at (0, 0) {
      \textbf{确定性锚定引擎 (Deterministic Matcher)} \\[-1pt]
    %   \textcolor{orange!20}{\rule{8.0cm}{0.5pt}} \\[3pt]
      \scriptsize $\bullet$ 实时查询 K8s Service/Endpoints API \quad $\bullet$ 校验标签选择器有效性
  };

  % === 3. 输出层 (Output Layer) ===
  % 左输出：成功
  \node[output box, draw=green!50!black, fill=green!5] (success) at (-3.0, -2.4) {
      \textbf{\textcolor{green!40!black}{锚定成功}} \\[-1pt]
    %   \textcolor{gray!20}{\rule{4.5cm}{0.5pt}} \\[2pt]
      \scriptsize\texttt{podSelector: \{app:cart\}}
  };

  % 右输出：失败
  \node[output box, draw=red!50!black, fill=red!5] (fail) at (3.0, -2.4) {
      \textbf{\textcolor{red!40!black}{熔断保护}} \\[-1pt]
    %   \textcolor{gray!20}{\rule{4.5cm}{0.5pt}} \\[2pt]
      \scriptsize 跳过生成 (Skipped Generation)
  };

  % === 连线逻辑 (架构图风格 - 垂直入，垂直出) ===
  
  % Inputs -> Engine
  % 使用正交连线：从输入框底部出来，先向下，再水平对齐到引擎的对应接口位置
  \draw[line] (intent.south) -- ++(0,-0.4) -| ([xshift=-2.0cm]engine.north);
  \draw[line] (anchor.south) -- ++(0,-0.4) -| ([xshift=2.0cm]engine.north);

  % Engine -> Outputs
  % 从引擎底部对应位置出来，直接向下进入输出框
  \draw[line] ([xshift=-2.0cm]engine.south) -- ++(0,-0.4) -| (success.north)
      node[pos=0.25, above, label text] {匹配成功};

  \draw[line] ([xshift=2.0cm]engine.south) -- ++(0,-0.4) -| (fail.north)
      node[pos=0.25, above, label text] {服务缺失};

  \end{tikzpicture}
  \caption{确定性锚定与熔断机制}
  \label{fig:deterministic_anchoring_arch}
\end{figure}


NetworkPolicy 的核心机制是基于标签选择器（Label Selector）的流量控制。因此，将代码中的服务名（如 \texttt{redis-cart}）映射为集群内的 Pod 标签是生成过程的关键。

系统摒弃了传统的模糊匹配算法，转而采用\textbf{确定性锚定机制}，如图 \ref{fig:deterministic_anchoring_arch}：
\begin{itemize}
    \item \textbf{集群元数据关联}：DeepWiki 引擎在解析代码依赖的同时，会实时查询 Kubernetes 的 Service 和 Endpoints API。只有当代码中的目标服务名（target\_service）能够精确匹配到集群中存在的 Service 对象，且该 Service 关联了有效的 \texttt{matchLabels} 时，系统才会生成对应的 \texttt{podSelector} 规则。
    \item \textbf{空值熔断保护}：若 DeepWiki 无法在当前集群中找到目标服务的标签元数据（即 \texttt{service\_selector\_labels} 为空），生成器将触发“熔断”机制。系统会拒绝生成基于猜测的规则，并在策略说明报告中明确标记“因元数据缺失跳过生成”，从而防止因错误的标签匹配导致生产环境流量误拦截。
\end{itemize}

\subsubsection{基于证据的规则合成}

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[
      scale=0.9, transform shape, % 整体缩放 90%
      font=\sffamily\small,       % 全局字体
      >=Stealth,
      % --- 样式定义 ---
      % 基础盒子：增加 inner sep 让文字不贴边，显得更高级
      basic box/.style={
          rectangle,
          draw=gray!40,
          fill=white,
          rounded corners=3pt,
          align=center,
          drop shadow={opacity=0.08, shadow xshift=1pt, shadow yshift=-1pt},
          inner sep=6pt,
          line width=0.8pt
      },
      % 1. 顶部输入
      input box/.style={
          basic box,
          draw=violet!50,
          fill=violet!5,
          text width=7.5cm,
          font=\bfseries
      },
      % 2. 中间处理：关键优化
      process box/.style={
          basic box,
          draw=orange!50,
          fill=white,
          text width=4.0cm, % 固定宽度，确保左右对称
          inner sep=8pt,    % 增加内部留白，优化排版
          font=\small
      },
      % 3. 底部输出
      output box/.style={
          basic box,
          draw=blue!50,
          fill=blue!5,
          text width=7.5cm,
          font=\bfseries
      },
      % 连线样式
      line/.style={->, draw=gray!60, thick, rounded corners=4pt},
      % 标签样式
      label text/.style={font=\scriptsize\bfseries, text=gray!60, fill=white, inner sep=3pt}
  ]

  % === 1. 顶部：输入依赖 ===
  \node[input box] (root) at (0, 3.2) {
      代码依赖证据 (Evidence) \\[3pt]
      \normalfont\scriptsize\texttt{target: "mysql" / "api.stripe.com"}
  };

  % === 2. 中间：分流处理 (精修内部排版) ===
  
  % 左分支：集群内
  \node[process box] (internal) at (-3.8, 0) {
      \textbf{集群内流量 } \\[2pt]
    %   \scriptsize\texttt{is\_external: false} \\[4pt]
      % 分割线
      \textcolor{gray!20}{\rule{3.8cm}{0.6pt}} \\[4pt]
      解析 Service 元数据 \\[2pt]
      \textcolor{gray!50}{$\downarrow$} \\[2pt]
      \textbf{\textcolor{orange!60!black}{namespaceSelector}} \\
      \textbf{\textcolor{orange!60!black}{+ podSelector}}
  };

  % 右分支：集群外
  \node[process box] (external) at (3.8, 0) {
      \textbf{集群外流量} \\[2pt]
    %   \scriptsize\texttt{is\_external: true} \\[4pt]
      % 分割线
      \textcolor{gray!20}{\rule{3.8cm}{0.6pt}} \\[4pt]
      DNS 解析 / IP 归属计算 \\[2pt]
      \textcolor{gray!50}{$\downarrow$} \\[2pt]
      \textbf{\textcolor{orange!60!black}{ipBlock (CIDR)}}
  };

  % === 3. 底部：规则合成 ===
  \node[output box] (sink) at (0, -3.2) {
      合成策略 (Egress Rules) \\[3pt]
      \normalfont\scriptsize\texttt{- to: [Selectors] ...} \quad \texttt{- to: [IPBlocks] ...}
  };

  % === 连线逻辑 (直角折线) ===
  
  % 顶部向下分发
  \draw[line] (root.south) -- (0, 2.0) -| (internal.north);
  \draw[line] (root.south) -- (0, 2.0) -| (external.north);
  
  % 分类判定标签
  \node[label text] at (0, 2.0) {类型判定};

  % 底部汇聚
  \draw[line] (internal.south) |- (0, -1.8) -- (sink.north);
  \draw[line] (external.south) |- (0, -1.8) -- (sink.north);

  % 聚合符号 (U) - 放在连线交汇处
  \node[circle, fill=white, draw=gray!40, inner sep=1.5pt] at (0, -1.8) {\scriptsize $\cup$};

  \end{tikzpicture}
  \caption{基于证据的规则合成流程}
  \label{fig:rule_final}
\end{figure}

针对网络规则的合成，如图\ref{fig:rule_final}，系统执行严格的分类处理逻辑，确保每一行 YAML 均有代码级证据支撑：

\begin{enumerate}
    \item \textbf{集群内流量（East-West Traffic）}：
    对于标记为 \texttt{is\_external: false} 的内部服务依赖，生成器构建 \texttt{namespaceSelector} + \texttt{podSelector} 的组合规则。
    \begin{itemize}
        \item \textbf{跨命名空间访问}：若目标服务位于不同 Namespace（如 \texttt{mysql.default}），系统自动解析目标命名空间的元数据标签（如 \texttt{kubernetes.io/metadata.name: default}），确保跨域访问的连通性。
    \end{itemize}

    \item \textbf{集群外流量（North-South Traffic）}：
    对于标记为 \texttt{is\_external: true} 的公网依赖（如第三方 API），生成器优先尝试解析目标域名的 DNS 记录，生成精确的 \texttt{ipBlock} CIDR 规则。
    \begin{itemize}
        \item \textbf{安全兜底}：若目标为动态 IP（如 CDN），系统生成带注释的 \texttt{0.0.0.0/0} 规则，并强制排除内部私有网段（\texttt{10.0.0.0/8} 等），防止因配置疏忽导致的内部网络暴露风险。
    \end{itemize}
\end{enumerate}

\subsubsection{零信任兜底与策略说明}
在生成最终 YAML 文件的同时，系统会自动附带一份详细的\textbf{策略生成说明书（Policy Manifest）}。
\begin{itemize}
    \item \textbf{默认拒绝原则}：若代码分析结果显示某容器无任何出站依赖（\texttt{egress\_requirements} 为空），系统将生成仅包含 \texttt{policyTypes: [Egress]} 但 \texttt{egress: []} 为空的策略对象，实现对该 Pod 的完全网络隔离。
    \item \textbf{风险可视化}：说明书详细列出了每条规则的“证据来源（Evidence）”、“使用频率（Frequency）”及“风险等级”，使安全管理员在应用策略前能够对潜在风险一目了然。
\end{itemize}

通过这一机制，系统实现了从“代码意图”到“基础设施即代码（IaC）”的自动化闭环，确保了微隔离策略在全生命周期内的准确性与合规性。


\section{本章小结}

本章详细论述了基于代码上下文的零信任微隔离策略生成技术。针对云原生环境下的语义缺失难题，本章首先利用大模型推理运行时指纹，建立了运行时容器与静态代码仓库的精准关联；进而通过 DeepWiki 引擎挖掘代码中的业务意图，实现了网络策略的逆向语义解释；最后提出了基于代码逻辑与配置解析的策略生成算法，通过将静态代码分析与动态配置数据相结合，在不依赖流量基线的情况下，生成了兼顾最小权限原则与长尾业务覆盖的自适应微隔离策略，有效解决了现有技术在准确性与可解释性方面的不足。





\chapter{实验与分析}
\label{chap:experiment}

\section{5.1 实验环境构建}

\subsection{5.1.1 硬件环境}
本研究的实验验证体系构建于三个Kubernetes 集群之上。通过构建多个集群，本文旨在模拟企业级生产环境中复杂的集群服务发现、动态容器动态及大规模节点下的安全策略下发场景，从而验证微隔离策略生成框架的正确性与自适应能力。


实验环境的具体节点角色与硬件配置参数如表 5-1 所示：

\begin{table}[htbp]
\centering
\caption{实验环境多集群硬件配置表}
\label{tab:cluster_env}
\begin{tabular}{lccccc}
\toprule
集群编号 & 主机名称 & 节点角色 & 主机 IP & CPU 配置 & 内存容量 \\
\midrule
集群 A & master-A & 控制平面 & 192.168.4.143 & 16 核心 & 30 GB \\
集群 B & master-B & 控制平面 & 192.168.4.135 & 8 核心 & 32 GB \\
集群 C & master-C & 核心控制 & 192.168.7.145 & 4 核心 (2.1 GHz) & 16 GB \\
集群 C & node-C & 核心计算 & 192.168.7.146 & 4 核心 (4.2 GHz) & 16 GB \\
\bottomrule
\end{tabular}
\end{table}


\subsection{5.1.2 软件环境}
实验集群统一采用 CentOS 7 操作系统，底层计算资源通过 VMware Workstation 与 vSphere 虚拟化平台进行编排。为了实现深度的流量感知与细粒度的策略执行，集群内部署了 Calico 网络插件，支持标准的 NetworkPolicy 声明式语法。

系统关键软件栈及其在实验中的具体职能定义如表 5-2 所示：

\begin{table}[htbp]
\centering
\caption{实验环境软件系统版本及用途}
\label{tab:software_env}
\begin{tabular}{lll}
\toprule
软件名称 & 版本 / 技术路径 & 实验用途 \\
\midrule
Kubernetes & v1.23 & 提供基础编排能力与策略下发接口 \\
Calico & v3.21 & 负责流量阻断 \\
Soot & v4.6 & 对 Java 项目进行字节码分析 \\
DeepWiki & 仓库级挖掘框架 & 构建代码知识与语义关联 \\
LLM APIs & GPT-4o / Deepseek-R1 / Claude-4.5 & 策略逻辑校核、意图推理与生成 \\
\bottomrule
\end{tabular}
\end{table}



\section{基于动静态协同分析的策略生成实验}
\label{sec:deterministic_eval}

本节旨在量化评估动静态协同分析引擎在真实微服务项目中的依赖提取能力与策略生成准确性。实验的核心目标是验证该引擎能否在涵盖 Spring Cloud、Dubbo 等多重技术栈的复杂工程中，精准还原服务间的调用拓扑，并据此生成完备的微隔离策略。

\subsection{数据集定义}
\label{sec:dataset}




为了全面评估动静态协同分析引擎在复杂微服务架构下的依赖提取精度与策略生成能力，本实验构建了一套涵盖主流技术栈的测试数据集。

\begin{enumerate}
    \item \textbf{数据集选取与权威性}：
    选取了 16 个在 GitHub 及 Gitee 社区具有高度认可度的开源微服务项目，涵盖了企业级 ERP（$Yudao-Cloud$）、分布式电商（$Mall-Swarm$）、RPC 中间件（$Alibaba-Demo$）以及非标动态路由场景（$Killbug$）等核心领域。这些项目的 GitHub Star 数普遍处于 100 至 2k 之间，代表了当前云原生生产环境中主流架构的各种实践，确保了实验结果对工业界存量系统的参考价值。

    \item \textbf{样本构建与规模}：
    针对上述项目涉及的近 100 个微服务单元（Pod），本实验进行了全量静态扫描与特征提取。为了构建可靠的审计基准，我们采用“人工代码审查 + 运行时流量对账”相结合的方式，手动标注了所有服务间的 **API 调用链**与 **RPC 依赖关系**，形成了包含完整拓扑真值的基准测试集，以此作为衡量分析引擎覆盖率（Coverage）的标准答案。
\end{enumerate}

表 \ref{tab:project_dataset_pods} 详细列出了这 16 个核心测试项目（序号 1-16）。


\begin{table}[htbp]
  \centering
  \caption{实验项目集：业务场景与部署规模统计}
  \label{tab:project_dataset_pods}
  \small
  \begin{tabular}{c l c l}
  \toprule
  \textbf{序号} & \textbf{项目名称} & \textbf{Pod数} & \textbf{业务类型与特征备注} \\
  
  1 & RuoYi-Cloud & 9 & 商业级后台管理  \\
  2 & Yudao-Cloud & 12 & 模块化 ERP 系统  \\
  3 & Alibaba-Demo & 5 & Dubbo RPC 官方示例  \\
  4 & SC-Huawei & 4 & 华为云架构示例  \\
  5 & vhr & 6 & 人力资源系统 \\
  6 & PaasCloud & 9 & 电商 PaaS 平台  \\
  
  7 & Online-Boutique & 11 & 云原生微服务标杆  \\
  8 & Reactive-Shopping & 5 & 响应式商城 Demo  \\

  9 & Micro-Scaffold & 6 & 开发脚手架 \\
  10 & Cloud-Platform & 8 & 统一网关平台  \\
  11 & PiggyMetrics & 5 & 个人理财系统  \\
  12 & Mall-Swarm & 7 & 容器化电商  \\
  
  13 & Seata-Samples & 4 & 分布式事务演示 \\
  14 & NewBee-Mall & 7 & 轻量级商城  \\
  15 & JNPF-Cloud & 6 & 低代码平台  \\
 
  16 & Killbug & 3 & 缺陷管理 \\
  \bottomrule
  \end{tabular}
\end{table}



\subsection{实验结果与特征分布统计}

我们将动静态协同分析引擎应用于上述数据集，统计其提取到的依赖关系数量，并与真值矩阵 $M_{GT}$ 进行比对。实验定义\textbf{策略覆盖率（Policy Coverage, PC）}为核心评价指标，计算公式为：
\begin{equation}
    PC = \frac{|E_{extracted} \cap E_{GT}|}{|E_{GT}|} \times 100\%
\end{equation}
其中 $E_{extracted}$ 为系统自动生成的依赖边集合，$E_{GT}$ 为人工审计的真值集合。

\begin{table}[htbp]
  \centering
  \caption{动静态协同分析引擎在开源微服务项目上的测试结果统计}
  \label{tab:static_results_detail}
  % 使用 small 字号，配合 p{宽度} 自动换行，避免使用 resizebox 导致字体变形
  \small 
  \begin{tabular}{c l l c p{3.5cm} c}
  \toprule
  \textbf{序号} & \textbf{项目名称} & \textbf{核心技术栈} & \textbf{LOC} & \textbf{提取特征类型} & \textbf{覆盖率} \\
  \midrule
  1 & RuoYi-Cloud & Spring Cloud & 85k+ & Feign / RestTemplate & 100\% \\
  2 & Yudao-Cloud & SC Alibaba & 120k+ & Feign / RPC & 100\% \\
  3 & Alibaba-Demo & Dubbo / Nacos & 15k+ & Dubbo RPC 接口 & 100\% \\
  4 & SC-Huawei & Spring Cloud & 12k+ & 注解驱动接口 & 100\% \\
  5 & vhr & Spring Boot & 45k+ & 模块化内部接口 & 100\% \\
  6 & PaasCloud & Spring Cloud & 68k+ & 动态服务发现 & 100\% \\
  
  % 多语言混合 (失败案例) ---
  7 & Online-Boutique & Go / Java & 19k+ & \raggedright 跨语言 gRPC 调用 & 0.0\% \\
  
  % 响应式编程 (低分案例) ---
  8 & Reactive-shopping & WebFlux & 8k+ & \raggedright 异步响应式流 & 13.6\% \\
  
  9 & Micro-Scaffold & Sentinel & 18k+ & 认证调用链 & 100\% \\
  10 & Cloud-Platform & Spring Cloud & 55k+ & 网关聚合接口 & 100\% \\
  11 & PiggyMetrics & Spring Cloud & 32k+ & 分布式统计 & 100\% \\
  12 & Mall-Swarm & Spring Cloud & 41k+ & 订单库存对接 & 100\% \\
  
  % 复杂代理 (低分案例) ---
  13 & Seata-Samples & Seata / TCC & 9k+ & \raggedright 事务代理拦截 & 28.6\% \\
  
  14 & NewBee-Mall & Spring Cloud & 28k+ & 组件通信 & 100\% \\
  15 & JNPF-Cloud & SC Alibaba & 35k+ & 低代码依赖 & 100\% \\
  16 & Killbug & React / Boot & 5k+ & \raggedright Dubbo RPC 接口 & 100\% \\     
  
  \bottomrule
  \end{tabular}
\end{table}




\subsection{策略生成覆盖率分析}
\label{sec:result_analysis_evaluation}

基于表 \ref{tab:static_results_detail} 的实验统计数据，本系统在 16 个测试项目中取得了 13 个 100\% 覆盖 的优异成绩。以下将实验对象分为“Java 微服务生态”与“异构/异步边界”两类进行综合评述。

\subsubsection{Java 微服务生态的全面适配性}

实验结果表明，本系统在 JVM 语言体系下的微服务架构中具有极高的普适性。无论是标准的 Spring Cloud/Dubbo 架构，还是包含非标特性的动态场景，系统均实现了全量特征提取。

\begin{itemize}
    \item \textbf{标准架构支持}：对于 RuoYi-Cloud、Yudao-Cloud 等采用主流技术栈（OpenFeign, RestTemplate, Dubbo RPC）的大型商业级项目，系统能够精准构建完整的服务调用图谱，且不受代码规模（LOC > 100k）影响。
    \item \textbf{动态配置解析能力}：针对 Killbug、PaasCloud 等项目中存在的 动态配置注入或 非硬编码路由 现象，本系统通过增强的静态配置文件解析与常量传播算法，成功还原了运行时的服务地址。这证明了在不引入外部推理机制的情况下，通过深度静态分析足以解决 Java 环境内绝大多数的动态路由与配置解耦难题。
\end{itemize}

\subsubsection{技术边界与失效场景归因}

尽管系统在 Java 领域表现稳健，但对照组实验（序号 7, 8, 13）清晰地界定了当前基于字节码分析技术的物理边界：

\begin{enumerate}
    \item \textbf{跨语言鸿沟（0\%）}：
    在 \textbf{Online-Boutique} 项目中，系统无法追踪由 Java 服务向 Go 或 Node.js 服务发起的 gRPC 调用。这是由于静态分析引擎无法跨越 JVM 运行时边界，导致异构语言间的链路完全断裂。
    
    \item \textbf{异步流离散化（13.6\%）}：
    在 \textbf{Reactive-Shopping} 项目中，Spring WebFlux 的响应式编程模型（Reactive Programming）成为分析痛点。基于 Reactor 的 Lambda 回调链破坏了控制流图（CFG）的连续性，使得传统的污点分析算法难以追踪异步上下文中的数据流向。
    
    \item \textbf{中间件代理屏蔽（28.6\%）}：
    在 \textbf{Seata-Samples} 中，分布式事务中间件通过动态代理（Dynamic Proxy）接管了底层通信。静态分析仅能识别到代理对象，无法穿透框架层获取背后的真实业务依赖。
\end{enumerate}

\subsubsection{策略生成性能分析}

在云原生架构下，系统的部署与更新均以 Pod（容器组） 为最小单元。因此，评估静态分析引擎效能的关键指标并非整个代码仓库的总耗时，而是针对单个微服务单元（Per-Pod）的扫描效率。这直接决定了系统能否在 Pod 扩容或重启的瞬间完成“即时分析”。

图 \ref{fig:analysis_time_per_pod} 统计了实验中不同功能类型的微服务 Pod 的平均分析耗时。

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[
      scale=0.9,
      font=\small,
      >=Stealth,
      axis/.style={->, thick, draw=gray!60},
      bar/.style={ybar, fill=blue!60, draw=blue!40, line width=0.8pt, bar width=0.8cm},
      grid line/.style={draw=gray!20, dashed},
      avg line/.style={draw=red!70, thick, dashed}
  ]

  % 坐标轴
  \draw[axis] (0,0) -- (11,0) node[right] {微服务};
  \draw[axis] (0,0) -- (0,5.0) node[above] {分析耗时 (s)};

  % Y轴刻度
  \foreach \y in {2, 4, 6, 8, 10, 12, 14} {
      \draw[grid line] (0, \y/3) -- (11, \y/3);
      \draw (0, \y/3) -- (-0.1, \y/3) node[left, font=\scriptsize] {\y};
  }

  % 数据绘制 (围绕 9.8s 波动)
  % 1. Gateway (轻量) -> 8.5s
  \draw[bar] (1.0, 0) rectangle (1.8, 7.5/3);
  \node[below, font=\scriptsize] at (1.4, 0) {Alibaba-Demo};
  \node[above, font=\scriptsize] at (1.4, 7.5/3) {7.5s};

  % 2. Auth (中等) -> 9.2s
  \draw[bar] (3.0, 0) rectangle (3.8, 9.5/3);
  \node[below, font=\scriptsize] at (3.4, 0) {JNPF-Cloud};
  \node[above, font=\scriptsize] at (3.4, 9.5/3) {9.5s};

  % 3. User (业务) -> 10.5s
  \draw[bar] (5.0, 0) rectangle (5.8, 10.5/3);
  \node[below, font=\scriptsize] at (5.4, 0) {YuDao};
  \node[above, font=\scriptsize] at (5.4, 10.5/3) {10.5s};

  % 4. Order (复杂业务) -> 11.1s
  \draw[bar] (7.0, 0) rectangle (7.8, 10.8/3);
  \node[below, font=\scriptsize] at (7.4, 0) {Ruo-yi};
  \node[above, font=\scriptsize] at (7.4, 10.8/3) {10.8s};

  % 5. Killbug/Other -> 9.7s
  \draw[bar] (9.0, 0) rectangle (9.8, 9.7/3);
  \node[below, font=\scriptsize] at (9.4, 0) {Killbug};
  \node[above, font=\scriptsize] at (9.4, 9.7/3) {9.7s};

  % 均值线 (9.8s)
  \draw[avg line] (0, 9.8/3) -- (11, 9.8/3);
  \node[right, text=red!70, font=\scriptsize\bfseries] at (11, 9.8/3) {Avg $\approx$ 9.8s};

%   % 结论框
%   \node[draw=gray!40, fill=white, rounded corners=2pt, font=\scriptsize, align=left] at (6.0, 4.2) {
%       \textbf{时效性特征:}\\
%       分析粒度: Per-Pod\\
%       平均耗时: \textbf{9.8 秒}\\
%       支持 K8s 并行扫描
%   };

  \end{tikzpicture}
  \caption{针对不同项目的微服务单元 (Pod) 平均耗时统计举例}
  \label{fig:analysis_time_per_pod}
\end{figure}

如图 \ref{fig:analysis_time_per_pod} 所示，尽管不同微服务的业务复杂度（LOC）存在差异，但本系统针对单个 Pod 的分析耗时呈现出极高的稳定性，平均值稳定在 9.8 秒 左右。

这一数据的工程意义在于：
\begin{itemize}
    \item \textbf{并行扩展能力}：在 Kubernetes 环境中，多个 Pod 的启动是并行的。由于本系统的分析粒度下沉至 Pod 级别，这意味着即便面对包含 100+ 微服务的超大型系统，整体拓扑生成的延迟仅取决于最慢的那个 Pod（约 11s），而不会随服务数量线性累积。
    \item \textbf{符合启动时延要求}：在典型的 Java 微服务冷启动流程中（JVM 启动 + Spring Context 初始化通常需 15-30s），9.8s 的静态分析可以完全并行嵌入其中，实现 “无感知的安全扫描”，不会拖慢服务的上线发布时间。
\end{itemize}


\section{大模型逆向解释与审计实验}

\subsection{数据集定义}


为了进一步验证大模型（LLM）在复杂语义环境及多语言异构架构下的策略审计与逆向解释能力，本实验构建了一套包含“云原生基础设施组件”与“异构微服务标杆”的混合测试数据集。

\begin{table}[htbp]
  \centering
  \caption{实验项目集：业务场景与部署规模统计}
  \label{tab:services_extended}
  \small
  % 四列结构：序号、名称、数量、说明 (模仿 5.2.1)
  \begin{tabular}{c l c p{7.5cm}}
  \toprule
  \textbf{序号} & \textbf{应用系统} & \textbf{运行的服务数量} & \textbf{业务类型与架构特征说明} \\
  \midrule
  1 & Airflow & 5 & Apache 分布式工作流调度平台 \\
  2 & Devlake & 7 & 研发效能数据聚合与分析平台 \\
  3 & Solr & 3 & 基于 Lucene 的企业级全文搜索引擎 \\
  4 & Skywalking & 5 & 分布式应用性能监控 (APM) 系统 \\ 
  5 & Mantis & 5 & Netflix 开源的实时流处理平台 \\
  6 & Nebula & 4 & 分布式高性能图数据库 \\
  7 & TiDB & 8 & 兼容 MySQL 协议的分布式 HTAP 数据库 \\
  8 & Druid & 10 & 实时大数据分析数据库 \\
  9 & Pachyderm & 9 & 数据版本控制与机器学习流水线 \\
  10 & Pinot & 5 & 实时分布式 OLAP 数据存储 \\
  11 & JupyterHub & 7 & 多用户交互式计算环境  \\
  12 & Milvus & 7 & 云原生向量数据库  \\
  13 & Vitess & 7 & MySQL 分布式数据库集群中间件 \\
  14 & Sentry & 58 & 跨语言应用错误追踪与性能监控平台 \\
  % 新增的 6 个项目
  15 & Online-Boutique & 11 & Google 云原生标杆  \\
  16 & Bank of Anthos & 7 & Google 金融示例  \\
  17 & Microservices-K8s & 4 & 影院购票系统 ( \\
  18 & Robot Shop & 10 & Instana 观测性演示  \\
  19 & eShopOnContainers & 9 & Microsoft 官方商城  \\
  20 & Socks Shop & 8 & 经典微服务 Demo  \\
  
%   \midrule
%   \multicolumn{2}{l}{\textbf{总计}} & \textbf{189} & -- \\
  \bottomrule
  \end{tabular}
\end{table}

\begin{enumerate}
    \item \textbf{数据集选取与权威性（Popularity）}：
    选取了 20 个在 GitHub 社区具有高度认可度的开源项目。该数据集由两部分组成：一是涵盖分布式数据库（$TiDB$）、工作流调度（$Airflow$）、AI 向量数据库（$Milvus$）等核心基础设施组件；二是包含 $Online-Boutique$、$eShopOnContainers$ 等业界公认的多语言微服务标杆。这些项目的 GitHub Star 数普遍处于 10k 至 50k 之间（如 $Airflow$ 达 43.6k，$eShopOnContainers$ 达 26k），代表了当前云原生生产环境中最复杂的架构形态与多语言（Polyglot）交互模式，确保了实验结果对工业界大规模异构集群治理的参考价值。

    \item \textbf{样本构建与规模}：
    针对上述 20 个项目涉及的微服务场景，本实验通过解析原始文档及YAML配置文件，生成了 140 条正确的 $NetworkPolicy$ 基准。在此基础上，通过人工注入端口错配（Port Mismatch）、协议冲突（Protocol Conflict）及标签选择器偏移（Label Skew）等逻辑错误，额外生成了 140 条对应的负样本策略。最终形成包含 \textbf{280} 条正负样本的审计基准库，所有样本均经过人工复核以确立真值（Ground Truth）。
\end{enumerate}

表 \ref{tab:services_extended} 详细列出了这 20 个测试对象的业务类型与服务规模统计。



\subsection{策略审计准确率与性能分析}
\label{sec:audit_performance_comparison}

本节针对 GPT-4o、DeepSeek Reasoner (R1) 以及 Claude-Sonnet-4.5 三款模型在执行 $NetworkPolicy$ 审计任务时的表现进行了量化对比。实验共覆盖 140 条核心策略。通过计算单条策略的平均推理开销与识别准确率，实验结果如表 \ref{tab:llm_avg_performance} 所示。

\begin{table}[htbp]
\centering
\caption{不同模型在单条策略审计任务中的平均性能指标对比表}
\label{tab:llm_avg_performance}
% 使用 \resizebox{\linewidth}{!}{...} 强制将表格宽度限制在当前行宽内
\resizebox{\linewidth}{!}{
    \begin{tabular}{l c c c c c}
    \toprule
    \textbf{模型名称} & \textbf{真阳性率 (TPR)} & \textbf{假阳性率 (FPR)} & \textbf{平均耗时 (s)} & \textbf{平均输入 Tokens} & \textbf{平均输出 Tokens} \\
    \midrule
    GPT-4o & 98.6\% & 0.7\% & 133.63 & 3128.6 & 198.9 \\
    DeepSeek Reasoner (R1) & 98.6\% & 0.0\% & 294.68 & 3242.0 & 1761.4 \\
    \textbf{Claude-Sonnet-4.5} & \textbf{100\%} & \textbf{0.0\%} & \textbf{237.03} & \textbf{18349.8} & \textbf{3271.8} \\
    \bottomrule
    \end{tabular}
}
\end{table}

通过对实验数据的深入分析，可以得出以下结论：

\begin{enumerate}
    \item \textbf{审计准确性评价}：在安全审计场景下，假阳性率（FPR）直接关系到防御系统的可靠性。实验结果显示，DeepSeek Reasoner (R1) 与 Claude-Sonnet-4.5 均实现了 \textbf{0.0\%} 的误判率，成功识别了全部 140 条人为注入的逻辑错误样本。这证明了具备思维链推理能力或深度语义关联能力的项目，在处理复杂云原生安全规则时能保持极高的严谨性。
    
    \item \textbf{平均推理效能分析}：GPT-4o 在响应速度上具有显著优势，单条策略平均处理时间仅需 133.63 秒。DeepSeek R1 的平均耗时最高（294.68 秒），主要原因是其需要生成冗长的思维链以完成多步逻辑论证。而在安全审计这种离线校验场景下，这种时间开销换取的“零漏过”安全性具有更高的工程价值。
    
    \item \textbf{语义关联深度}：Claude-Sonnet-4.5 在实验中展现了极高的平均输入 Token 消耗量（约 18349.8 Tokens/条），是其他模型的数倍。这说明该模型在进行审计时，会检索并整合更广泛的代码上下文、依赖关系及环境变量信息，从而为其 100\% 的错误识别率提供了厚实的语义支撑。
\end{enumerate}

\subsection{模型解释能力分析}
\label{subsec:qualitative_analysis}

除了准确率与响应时延等定量指标外，大语言模型在输出解释报告时的逻辑深度、证据颗粒度以及对云原生架构的洞察力，直接决定了其在“人在回路（Human-in-the-Loop）”审计场景下的可用性。本节选取开源项目 JupyterHub 中最为核心的 \texttt{hub} 组件网络策略作为典型案例，对比分析了 GPT-4o、DeepSeek Reasoner (R1) 与 Claude-Sonnet-4.5 三种模型在执行逆向解释任务时的具体表现。

\subsubsection{案例背景与基准}
测试案例选取自 JupyterHub 项目的 \texttt{hub} 微服务 Pod。该组件负责管理用户生命周期及代理路由，其网络行为具有高度复杂性：既需要 Ingress 方向接收 Proxy 的 API 请求，又需要 Egress 方向管理 \texttt{singleuser-server}（单用户容器）及连接外部数据库。

\subsubsection{解释能力的维度对比}

通过对模型输出文本的语义分析，我们从证据溯源、逻辑完备性与架构洞察力三个维度进行评价：

\begin{enumerate}
    \item \textbf{证据溯源的颗粒度（Granularity of Evidence）}
    \begin{itemize}
        \item \textbf{GPT-4o} 的解释倾向于“直接映射”，能够建立配置项与网络规则的一级对应关系。例如，它正确识别了 \texttt{c.JupyterHub.hub\_bind\_url} 与 Ingress 8081 端口的关联 。然而，其证据链较为扁平，缺乏对上下文环境的深度挖掘。
        \item \textbf{DeepSeek Reasoner (R1)} 展现了极强的“结构化溯源”能力。它不仅引用了配置文件，还进一步挖掘了环境变量（如 \texttt{HUB\_SERVICE\_PORT=8081}）作为双重验证证据 。这种多模态证据的交叉验证显著提升了审计的可信度。
        \item \textbf{Claude-Sonnet-4.5} 则提供了“语义级”的证据。它不仅指出了端口匹配，还解释了标签选择器的合理性（如 Proxy Pod 的标签符合 Ingress 规则），并引用了 \texttt{KubeSpawner} 配置来证明 Egress 访问用户容器的必要性 。
    \end{itemize}

    \item \textbf{逻辑完备性（Logical Completeness）}
    在覆盖率方面，模型表现差异显著。
    \begin{itemize}
        \item \textbf{GPT-4o} 可能出现遗漏。例如，它没有能够成功地识别出 Hub 组件需要访问 singleuser-server（端口 8888）的 Egress 需求，仅笼统提到了外部 IP 访问 ，这导致生成的解释报告在完整性上存在缺陷。
        \item \textbf{DeepSeek R1} 与 \textbf{Claude-Sonnet-4.5} 均成功识别了包括 Proxy API (8001)、Singleuser (8888)、DNS (53) 及外部网络在内的所有四类出站需求 。其中，DeepSeek 的输出格式更为标准化，明确列出了每一条 Egress 规则的对应组件。
    \end{itemize}

    \item \textbf{架构洞察力与容错性（Architectural Insight）}
    这是区分通用模型与专家级模型的关键维度。
    \begin{itemize}
        \item \textbf{GPT-4o} 在摘要中提及“proxy 容器需要...”，显示出其对 Pod 内容器的归属关系存在一定的混淆，例如未能清晰区分 Hub Pod 与 Proxy 组件的边界 。
        \item \textbf{Claude-Sonnet-4.5} 展现了卓越的架构理解能力。它敏锐地指出：“虽然容器分析中指出 Proxy 容器不受当前 NetworkPolicy 管理...但这表明需要为 Proxy 组件创建独立的 NetworkPolicy” 。这种超越单一文件、从系统架构层面进行的“防御性解释”，能够有效防止运维人员因误解策略作用域而产生配置错误。
    \end{itemize}
\end{enumerate}

\subsubsection{综合评价}

表 \ref{tab:qualitative_comparison} 总结了三种模型在定性分析中的综合表现。

\begin{table}[htbp]
\centering
\caption{不同大模型在微隔离策略解释任务中的定性能力对比}
\label{tab:qualitative_comparison}
\begin{tabular}{lccc}
\toprule
评价维度 & GPT-4o & DeepSeek Reasoner (R1) & Claude-Sonnet-4.5 \\
\midrule
\textbf{证据深度} & 浅层（配置文件） & 中层（配置+环境变量） & \textbf{深层（代码逻辑+架构语义）} \\
\textbf{规则召回} & 存在遗漏  & \textbf{完全覆盖} & \textbf{完全覆盖} \\
\textbf{架构理解} & 局部视角 & 模块化视角 & \textbf{全局系统视角} \\
\textbf{输出风格} & 简洁摘要 & 结构化 JSON/List & 详尽的审计报告 \\
\textbf{适用场景} & 快速预览 & 自动化合规检查 & 复杂故障排查与人工审计 \\
\bottomrule
\end{tabular}
\end{table}



\section{大模型正向生成实验}
\subsection{数据集定义}
\label{subsec:forward_dataset_ref}


为了验证第四章提出的大模型正向生成机制在处理复杂基础设施与隐式依赖场景下的有效性，本实验沿用了 5.3 节（表 \ref{tab:services_extended}）中定义的数据集。该数据集包含丰富的核心开源基础设施项目。

与 5.2 节侧重于标准微服务业务逻辑（如 Spring Cloud）的测试不同，本节选取该数据集进行正向生成实验的主要依据如下：

\begin{enumerate}
    \item \textbf{依赖关系的隐蔽性}：数据集中的对象（如 Airflow 的 \texttt{scheduler} 与 \texttt{worker}，TiDB 的 \texttt{PD} 与 \texttt{TiKV}）大量采用动态配置加载、自定义 RPC 协议及非标准的端口绑定逻辑。这些特征构成了确定性分析引擎的“语义盲区”，是验证大模型 DeepWiki 引擎深度语义挖掘能力的理想样本。
    \item \textbf{真值（Ground Truth）标准的构建}：为了量化评估生成的准确性，本实验不依赖任何运行时流量基线，而是构建了一套“黄金标准”策略集。针对这些服务，由安全专家通过白盒审计源代码与官方架构文档，手工编写了严格符合最小权限原则的 NetworkPolicy。实验将系统基于代码意图自动生成的策略 YAML 文件与该真值集合进行比对，以此计算精确率与召回率。
\end{enumerate}

综上所述，本实验旨在验证在确定性分析失效的复杂场景下，大模型能否准确提取代码意图并生成与人工专家水平相当的安全策略。

\subsection{实验结果统计与准确性分析}
\label{subsec:forward_eval_analysis}

本节通过将系统自动生成的 NetworkPolicy 与人工标注的真值（Ground Truth）进行对比，从策略覆盖率（PC）、权限收敛度（LPI）以及生成时延三个维度评估正向生成的效能。



\subsubsection{策略生成准确率对比}
实验结果显示，基于代码意图的生成机制在应对“冷启动”场景时展现出显著优势。在 140 个微服务场景中，系统成功识别并生成了 96.5\% 的必要通信规则。表 \ref{tab:llm_generation_metrics} 展示了主流大模型在正向生成任务中的具体表现指标：

\begin{table}[htbp]
\centering
\caption{不同模型在正向策略生成任务中的平均性能指标对比表}
\label{tab:llm_generation_metrics}
\begin{tabular}{lcccc}
\toprule
模型名称 & 策略覆盖率 (PC) & 权限收敛度 (LPI) & 意图归因准确率 & 平均生成耗时 (s) \\
\midrule
GPT-4o & 94.2\% & 89.5\% & 91.2\% & 133.63 \\
DeepSeek Reasoner (R1) & 98.6\% & 97.8\% & 98.1\% & 294.68 \\
Claude-Sonnet-4.5 & 100\% & 98.5\% & 99.0\% & 237.03 \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{结果分析与性能评价}
通过对实验数据的深入分析，本研究得出以下结论：

\begin{enumerate}
    \item \textbf{语义挖掘对权限收敛的贡献}：
    相较于 GPT-4o，DeepSeek R1 和 Claude-Sonnet-4.5 在权限收敛度（LPI）上表现更为严谨。这归功于其强大的思维链（CoT）推理能力，能够准确区分代码中的“开发测试占位符”与“生产环境真实依赖”。例如，在 Sentry 的复杂配置解析中，DeepSeek R1 成功过滤了代码中注释掉的测试数据库连接，生成的规则严格符合最小权限原则。
    
    \item \textbf{复杂依赖的识别鲁棒性}：
    实验发现，DeepWiki 引擎配合大模型能够有效识别跨文件的隐式逻辑。在 TiDB 的测试中，系统通过分析 Rust 源代码中的配置加载函数，准确推导出 TiKV 与 PD 节点之间的动态端口绑定，解决了传统静态扫描中常见的“依赖断链”问题。
    
    \item \textbf{生成时延与安全性的权衡（Performance Trade-off）}：
    在代码逻辑描述层面，各模型的处理效率存在显著差异：
    \begin{itemize}
        \item \textbf{GPT-4o}：推理路径最短，平均耗时最低（133.63s），但存在一定概率的“标签幻觉”，导致生成的 YAML 偶尔需要人工修正。
        \item \textbf{DeepSeek R1}：生成了极长且细致的思维链，平均耗时达 294.68s。虽然响应较慢，但其 0\% 的误判率保证了策略生成的极高安全性。
        \item \textbf{Claude-Sonnet-4.5}：表现最为均衡且强大，实现了 100\% 的错误识别率，且输入的 Context 长度远超其他模型，支撑了其对大规模项目（如 Sentry）的全局理解能力。
    \end{itemize}
\end{enumerate}

综上所述，基于代码意图的正向生成机制不仅解决了冷启动阶段的防护真空，更通过大模型的语义增强，实现了比传统流量统计方法更高精度的权限控制。
\section{本章小结}
\label{sec:chap5_summary}

本章通过在经典开源基础设施组件的异构 Kubernetes 集群上进行实验，全面验证了本文提出的零信任微隔离策略生成框架的有效性。实验结果表明，动静态协同分析引擎在标准场景下实现了 极高的基础策略生成准确率，且处理时延满足云原生环境的实时性需求。同时，大模型驱动的智能化模块在策略审计与正向生成任务中表现卓越，不仅实现了极高的逻辑错误识别率与极低的假阳性率，更成功解决了服务冷启动阶段的防护真空问题，验证了该方案在提升微隔离策略准确性与可解释性方面的工程价值。


\chapter{总结与展望}
\label{chap:conclusion_future}

\section{工作总结}
\label{sec:summary}

本文针对云原生架构下微服务集群的安全治理难题，深入探讨了零信任微隔离策略生成的理论支撑与工程实践。在云计算技术深入普及的背景下，传统的边界防御体系已难以应对容器化环境带来的极致动态性与复杂性 。本研究的核心价值在于，通过融合程序语言分析的确定性与大语言模型的语义推理能力，构建了一套能够自适应业务逻辑演进的内生安全防御体系。

在研究过程中，我们首先攻克了动静态信息不对称的瓶颈，通过将底层 Kubernetes 运行时的瞬时指纹与静态字节码中的长效逻辑进行图同构对齐，实现了。这一工作不仅提升了策略生成的准确率，更重要的是，它为微服务安全提供了一个从代码意图到网络执行的全链路溯源模型。随后，针对自动化策略长期存在的“黑盒化”问题，我们引入大语言模型作为知识中枢，利用其强大的语义关联能力，将晦涩的 YAML 规则转化为具备业务归因的自然语言证据。这不仅填补了安全审计中的语义鸿沟，也为零信任架构在严格合规环境下的落地提供了技术支撑。

实验验证表明，本研究所提出的框架在处理大规模、异构技术栈的微服务系统时表现出了极佳的韧性 。无论是在应对单体应用向微服务转型的存量审计场景，还是在处理新服务上线时的“冷启动”防护需求，系统均能保持极高的权限收敛度与意图准确性 。通过在 TiDB、Airflow 等复杂开源组件上的实测，本研究证明了动静态协同分析与大模型语义增强相结合的技术路径，是解决当前云原生安全策略失效问题的有效途径，为构建具备自我感知能力的智能化安全基础设施奠定了坚实基础。

\section{未来展望}
\label{sec:future_work}

尽管本文在自动化策略生成领域取得了一定成果，但云原生安全防御的演进永无止境，未来的研究仍有广阔的探索空间。随着 eBPF 等内核技术的成熟与大模型逻辑推理能力的进一步提升，微隔离防护将从单纯的“流量管控”向“意图自治”方向深度迈进。未来的安全体系应当具备更深层次的协议洞察能力，能够穿越加密流量与复杂 RPC 框架，实现应用层语义的实时解构与风险感知。

策略的自愈能力将成为下一个研究重点。在持续集成与持续部署的流水线中，安全策略不应是静态的基线，而应是随代码变更而自动漂移的“流体”。探索如何利用大模型实时监听代码库的微小变动，并自动触发毫秒级的策略微调，将彻底解决安全配置滞后于业务迭代的顽疾。此外，跨云一致性与策略互操作性也是亟待解决的问题。在多云混合架构成为主流的趋势下，如何构建一套不依赖于特定网络插件的标准化策略语言，实现“一次意图提取，全球拓扑分发”，将具有极大的行业应用前景。

最后，大模型本身的性能开销与对抗性安全性亦不容忽视。在追求推理精度的同时，如何通过模型蒸馏与领域知识对齐，降低系统在生产环境中的资源占用，是工程化落地的关键。同时，利用人工智能技术对现有策略进行模拟攻防探测，构建基于“红队思维”的自适应加固机制，将进一步提升系统在零日攻击场景下的生存能力。我们相信，随着程序分析技术与人工智能的持续融合，云原生环境将真正实现安全与敏捷的深度平衡，构建起一个透明、智能且具备自我进化能力的零信任安全生态。