\chapter{绪论}


\section{研究背景与意义}

随着云计算技术的深入普及，云原生（Cloud Native）架构已成为构建现代企业级应用的主流标准。根据云原生计算基金会（CNCF）发布的 2024 年年度报告显示，全球云原生开发者的数量已达到 1560 万，超过 89\% 的企业正在生产环境中使用或尝试云原生技术\cite{CNCF2024}。这一技术范式的核心变革，在于利用容器（Container）替代了传统的虚拟机（VM）作为最小计算单元，并利用 Kubernetes 等编排系统实现了资源的自动化调度\cite{Burns2016BorgOA}。这种转变不仅让软件的开发与交付变得更加敏捷，也彻底重塑了底层基础设施的网络架构。

\begin{figure}[htbp]
  \centering
  % 1. 移除 resizebox，改用 scale=0.95 缩放坐标，保持文字大小不变且清晰
  \begin{tikzpicture}[
      scale=0.95, 
      >=Stealth,
      % 2. 全局字体：移除 \sffamily，使用标准罗马字体，字号设为 \small
      font=\small,
      % --- 样式定义 ---
      basic box/.style={
          draw=gray!50,
          rectangle,
          rounded corners=3pt,
          minimum width=3.2cm,
          minimum height=1.4cm,
          align=center,
          fill=white,
          drop shadow={opacity=0.1, shadow xshift=1pt, shadow yshift=-1pt},
          inner sep=4pt,
          line width=0.8pt % 线条加粗一点，更有质感
      },
      % 外部攻击者
      hacker box/.style={basic box, draw=red!40, fill=red!5},
      % 边界防护
      fw box/.style={basic box, minimum width=1.0cm, minimum height=4.5cm, draw=blue!40, fill=blue!5},
      % 内部业务服务
      svc box/.style={basic box, draw=orange!40, fill=orange!5},
      % 攻击路径连线
      attack line/.style={->, draw=red!70, line width=1.2pt, rounded corners=4pt}
  ]

    % 1. 外部网络层 (坐标保持)
    \node[hacker box] (hacker) at (-5, 0) {\textbf{外部攻击者} \\ \footnotesize (External Attacker)};

    % 2. 边界防火墙
    \node[fw box] (fw) at (-1.5, 0) {\rotatebox{90}{\textbf{边界防火墙 (FW)}}};

    % 3. 内部微服务集群
    \node[svc box, dashed] (web) at (3, 1.5) {Web 服务 A \\ (\textbf{已入侵})};
    \node[svc box] (order) at (3, -1.5) {订单服务 B};
    \node[svc box] (db) at (7.5, 0) {数据库服务 C};

    % 绘制内部网络分组框
    \draw[gray!35, dashed, rounded corners=8pt, line width=0.8pt] (1.0, -2.6) rectangle (9.5, 2.6);
    \node[font=\footnotesize\bfseries, text=gray!80] at (5.25, 2.8) {内部受信网络 (东西向流量缺乏隔离)};

    % 4. 连线逻辑 (字体升级：tiny -> scriptsize)
    % 突破边界
    \draw[attack line] (hacker.east) -- node[above, font=\scriptsize, text=red] {南北向渗透} (fw.west);
    \draw[attack line] (fw.east) -- (web.west);

    % 内部横向移动
    \draw[attack line] (web.south) -- (order.north) node[midway, left, font=\scriptsize, text=red] {横向移动};
    
    % 订单服务到数据库
    \draw[attack line] (order.east) -| (db.south) node[pos=0.5, below, font=\scriptsize, text=red] {获取敏感数据};
    
    % Web服务到数据库
    \draw[attack line] (web.east) -| (db.north) node[pos=0.25, above, font=\scriptsize, text=red] {跨服务渗透};

    % % 5. 底部结论说明 (增加 text width 防止单行过长)
    % \node[draw=red!40, fill=white, rounded corners=2pt, inner sep=6pt] at (5.25, -3.8) {
    %     \textbf{传统防御困境：} 攻击者突破外围后，可利用“默认可信”机制在微服务间横向移动 
    % };

  \end{tikzpicture}
  \caption{传统边界防御体系在云原生环境下的失效机理示意图}
  \label{fig:traditional_defense_failure}
\end{figure}

然而，云原生环境带来的极致弹性与动态性，也让传统的网络安全防御体系面临失效的风险。在传统的物理数据中心中，安全团队通常依赖防火墙在网络边缘构建一个坚固的“防线”，也就是所谓的边界防御（Perimeter-based Defense）。但在云原生环境中，容器的生命周期极短，IP 地址频繁变化，服务间的调用关系错综复杂，导致固定的物理边界逐渐模糊甚至消失。Gartner 的研究指出，随着云环境复杂度的增加，绝大多数（预计到 2025 年将达 99\%）的云安全事故将源于客户的配置错误，而非云平台本身的漏洞\cite{Gartner2023}。一旦攻击者突破了外围防线,参考\ref{fig:traditional_defense_failure}，由于内部网络往往缺乏有效的隔离，他们便可以利用“默认可信”的机制在微服务之间进行肆无忌惮的横向移动（Lateral Movement）。


为了应对这种“内网默认可信”带来的安全隐患，Google 等业界先驱提出了“零信任（Zero Trust）”的安全理念，主张“永不信任，始终验证”，即无论请求来自网络内部还是外部，都必须经过严格的身份认证与授权\cite{Ward2014BeyondCorpAN}。在此背景下，微隔离（Micro-segmentation）技术应运而生。与传统防火墙不同，微隔离将防护的颗粒度细化到了每一个工作负载（Workload）甚至每一个容器，试图通过精细化的流量控制策略，阻断攻击者的横向渗透路径\cite{Rose2019ZeroTA}。

虽然微隔离技术的理念已经非常成熟，但在实际的云原生工程落地中，运维人员仍面临着巨大的挑战，主要体现在以下三个方面：

\begin{enumerate}
    \item 策略维护难：在 Kubernetes 集群中，容器的生灭往往以分钟甚至秒为单位，IP 地址的剧烈变动使得基于 IP 的传统黑白名单瞬间失效。运维人员很难手动维护一套能够实时跟随业务变化的动态策略\cite{Li2019ServiceMC}。
    \item 管理复杂度高：微服务架构将单体应用拆分为成百上千个独立服务，服务间的调用链路呈指数级增长。面对如此庞大的分布式网络，依靠人工梳理业务逻辑并配置上前条隔离规则，不仅效率极低，而且极易出现配置冲突或遗漏。
    \item 流量可视性差：现有的安全工具大多只能监控到网络层（L3/L4）的连接状态，缺乏对应用层（L7）业务语义的理解。这意味着安全团队很难区分正常的业务调用与利用合法端口进行的恶意攻击，难以制定出既安全又不影响业务的精准策略\cite{2021AttributebasedAC}。
\end{enumerate}

综上所述，传统的、依赖人工配置的静态安全手段已无法适应云原生环境的高动态特征。因此，如何深入理解业务逻辑，自动化地生成准确、实时且具备可解释性的微隔离策略，已成为当前云原生安全领域急需解决的关键问题。



\section{国内外研究现状}

为了应对微服务环境下的服务实例生命周期大幅缩短，IP 地址不再固定，服务间的依赖关系呈现出随业务逻辑动态变化的网状拓扑特征 \cite{Jamshidi2018MicroservicesTJ}等挑战，围绕如何自动化生成适应云原生环境的微隔离策略，现有的技术方案主要根据数据源的不同分为三类：基于流量分析的策略生成技术、基于角色的策略生成技术以及基于静态分析的策略生成技术。接下来，本文将逐一介绍这些技术。

\subsection{基于流量分析的策略生成技术}

基于流量分析的策略生成技术是目前工业界应用最为广泛的方案，其核心思想是“以观测代替预设”。该技术不依赖源代码或人工配置，而是通过持续监控生产环境中的实际通信行为，逆向推导服务依赖关系，进而生成白名单策略。

从技术实现来看，主要通过 Sidecar 代理或 eBPF（Extended Berkeley Packet Filter）技术进行采集。Isovalent 公司的技术白皮书指出，基于 eBPF 的无侵入式观测能够以极低的性能损耗，在内核层直接捕获全集群的网络拓扑 \cite{Isovalent2023}。尽管该方法具备部署便捷的优势，但针对构建严密安全防线的这一需求看，单纯依赖流量分析存在三个本质缺陷：

\begin{enumerate}
    \item 观测覆盖率不足与长尾效应：流量分析本质上是一种基于时间窗口的采样。它只能记录观测期间发生的“显式行为”，无法覆盖“隐式合法行为”。Zhou 等人\cite{Zhou2018FaultAA}在 IEEE Transactions on Software Engineering 上的实证研究表明，微服务故障传播路径往往涉及低频调用的边缘服务，这些长尾路径在正常监控中很难显现 。Chen 等人\cite{Chen2008AutomatingNA}的经典研究也证实，即使经过长达数周的采样，仍会有大量合法的边缘业务逻辑（如灾备切换、审计任务）因未被触发而未被记录 。若仅依据不完整的流量样本生成白名单，一旦这些低频业务在未来被触发，就会被误判阻断，导致生产事故。

    \item 策略生成的滞后性与冷启动问题：基于学习的机制存在天然的“冷启动”窗口。在服务刚上线或版本更新初期，系统必须积累足够的数据才能计算出收敛的行为基线。He 等人\cite{He2023AdversarialML}指出，机器学习模型在面对数据分布快速变化时表现出显著的滞后性 。此外，云原生工作负载具有高度瞬态性。Sysdig 的监测数据显示，超过 70\% 的容器生命周期不足 5 分钟 \cite{Sysdig2024}。对于这些短生命周期的对象，往往是探针还未收集到足够的流量样本，容器就已经销毁，导致无法生成有效的防护策略。

    \item 脏数据引发的策略“毒化”风险：流量分析方案通常假设“观测到的流量均为良性”。然而，Gnutti 等人\cite{Gnutti2022}的研究指出，在存量系统中，攻击者可能利用伪造的正常流量模式来混淆检测模型 。如果缺乏人工甄别，将所有历史连接直接固化为白名单，实际上等同于将潜在的恶意行为（如探测扫描）合法化了，这种由脏数据导致的策略“毒化”将永久性地破坏安全边界。
\end{enumerate}

针对上述局限性，近年来开始出现结合大语言模型（LLM）进行策略优化的尝试。例如，KubeGuard\cite{KubeGuard2025} 提出利用 LLM 分析运行时日志来辅助生成最小权限配置。同时，KubeAegis 框架\cite{KubeAegis2024}也尝试通过统一策略管理来解决流量观测到的策略规则碎片化问题。然而这些尝试仍然不能从根本上解决上述缺陷。




\subsection{基于角色的策略生成技术}

为了解决云原生环境下 IP 地址频繁变动导致网络策略失效的问题，研究人员提出了将访问控制策略与底层网络标识解耦的思路，主张提取工作负载的高层身份属性来构建抽象的角色模型，并依据“用户/服务-角色-权限”的映射关系来生成逻辑隔离策略。

在理论层面，Sandhu 等人\cite{Sandhu1996RoleBasedAC}提出的 RBAC96 模型奠定了这一领域的基石，通过引入“角色”作为中间层，极大地简化了大规模系统中的权限管理复杂度。在 Kubernetes 等现代编排平台中，这种机制通常表现为利用 ServiceAccount 作为策略锚点。这种方法实现了防护逻辑的语义化，使得安全策略能够跟随容器的生命周期自动迁移，而无需像防火墙那样频繁更新 IP 规则。

然而，尽管基于角色的方法在理论上很完善，但在面对大规模微服务集群的实际工程落地中，这种静态的授权模型逐渐暴露出了三个显著的缺陷：

\begin{enumerate}
    \item 角色爆炸与管理熵增：微服务架构的核心原则是职责单一，这意味着随着业务的发展，服务的数量会呈线性甚至指数级增长。Ferraiolo 等人\cite{Ferraiolo2001}指出，当系统规模扩大时，如果严格遵循“最小特权原则”为每一个微服务实例定制专属角色，将导致角色数量急剧膨胀，即所谓的“角色爆炸（Role Explosion）”现象 。在云原生环境下，这一问题尤为严重。Rostami 等人\cite{Rostami2023}指出，Kubernetes 的 RBAC 系统包含极其复杂的动词（Verbs）和资源（Resources）组合，这种组合的复杂性使得在大型集群中维护成千上万个“服务-角色”映射关系变得极难管理 。

    \item 过度授权带来的权限泄露风险：为了规避角色爆炸带来的管理难题，工程实践中往往会出现“走捷径”的现象。Kuhn 等人\cite{Kuhn2010AddingAT}指出，通过“角色复用”来减少配置量虽然降低了管理成本，但不可避免地扩大了攻击面 。这一点在近年来的安全报告中得到了验证。Red Hat 发布的 2024 年 Kubernetes 安全报告\cite{RedHat2024}显示，超过 46\% 的组织曾因权限配置错误（Misconfiguration）导致安全事故 。最新的自动化检测研究 EPScan \cite{EPScan2025}也证实，在生产环境中，大量的微服务拥有它们实际业务逻辑并不需要的“僵尸权限”，这意味着一旦单一容器被攻陷，攻击者就可以继承该角色所有的多余权限进行横向移动 。

    \item 静态授权无法适应动态风险：传统的 RBAC 模型本质上是一种静态授权机制。策略决策完全依赖于预先定义的静态绑定关系，缺乏对运行时上下文（Context-Awareness）的感知能力。NIST 的研究员 Hu 等人\cite{Hu2014GuideTA}指出，静态角色难以将动态属性（如当前的负载压力、访问时间窗口、客户端地理位置或实时的威胁情报等级）纳入决策逻辑 。在零信任架构中，访问请求的合法性往往取决于瞬时的系统状态，基于静态角色的策略在应对突发威胁时，往往显得过于僵化。
\end{enumerate}

综上所述，基于角色的策略生成技术虽然解决了网络标识漂移的问题，但在细粒度控制与动态适应性方面仍存在天然的逻辑局限。




\subsection{基于静态分析的策略生成技术}

基于静态分析的策略生成技术体现了“安全左移（Security Shift Left）”的防御思想。与前两种依赖运行时数据的方案不同，这种技术路线主张在应用部署之前的构建阶段（Build Phase），通过扫描源代码、字节码或配置文件，提前推导服务之间的调用关系，从而生成最小特权白名单。

在学术界，这一方向的研究主要集中在如何通过代码分析来提取微服务的拓扑结构。Li 等人\cite{li_automatic_2021}提出的 AutoArmor 系统是该领域的代表性工作，它通过对微服务源代码进行静态切片分析，自动提取服务间的 API 调用链并生成访问控制策略 。类似地，Ghavamnia 等人\cite{Ghavamnia2020ConfineAS}提出的 Confine 系统，则专注于通过静态分析容器内的二进制文件来削减系统调用（System Calls）的攻击面，证明了静态方法在收敛权限方面的有效性 。

这种方法的显著优势在于其覆盖率高且具备确定性。静态分析可以遍历代码中的所有逻辑分支，理论上能够发现那些在运行时很难被触发的“冷路径”依赖（例如灾难恢复逻辑），且生成的策略直接映射代码意图，具备天然的可解释性。然而，在云原生微服务的实际工程应用中，纯静态分析面临着三个难以逾越的“语义盲区”：

\begin{enumerate}
    \item 动态语言特性的解析难题：现代微服务应用广泛使用反射（Reflection）、动态代理和依赖注入等动态特性。Cerny 等人\cite{Cerny2024MicroserviceAware}指出，现有的静态分析工具在处理微服务架构时存在显著的“上下文缺失”问题，特别是当调用目标由配置文件或数据库动态决定时，静态工具很难推断出准确的调用图 。最新的 arXiv 研究 \cite{Valles2025Semantic}进一步提出“语义依赖”的概念，指出微服务间大量存在的隐式逻辑依赖无法仅通过语法分析来捕获，这导致纯静态生成的策略往往是不完整的 。

    \item 基础设施层的不可视：在云原生架构中，许多关键的网络行为并非由业务代码直接控制，而是由底层基础设施接管。例如，在 Istio 等服务网格环境中，Sidecar 代理会自动注入到 Pod 中并接管流量。这种运行时的架构变化无法在静态的源代码或 Dockerfile 中被预先捕获。Tigera 的技术报告\cite{Tigera2024}指出，静态分析无法感知由 Kubernetes 控制平面或 Sidecar 引入的额外网络路径，这意味着仅凭业务代码生成的策略，可能会因为遗漏基础设施组件的通信需求而导致服务启动失败 。

    \item 多语言异构环境的适配成本：微服务架构的一个重要特性是技术栈的异构性。Pereira-Vale 等人\cite{PereiraVale2023Mapping}中分析了 50 种现有的安全方案，发现绝大多数静态分析工具缺乏能够跨越语言边界追踪调用链的通用解决方案 。这种工具链的碎片化，使得在多语言混合的微服务系统中构建全局一致的依赖拓扑变得极具挑战性。
\end{enumerate}

综上所述，虽然静态分析能够提供高精度的代码级依赖视图，但受限于动态特性和基础设施层的不可见性，它无法独立生成完整的运行时微隔离策略。这也为本文提出“动静态协同分析”的思路提供了有力的事实依据。



\section{研究内容与意义}

\subsection{当前云原生零信任微隔离领域面临的主要挑战}

随着云原生架构（Cloud-Native Architecture）逐步确立为现代数据中心的基础设施标准，零信任微隔离技术已成为在不可信网络环境中保障大规模分布式微服务集群安全的核心范式。然而，尽管该技术在理论层面已趋于成熟，但在实际的工程化落地过程中，仍面临着严峻的挑战。这些挑战不仅源于云原生环境本身固有的高动态性（High Dynamism）与架构复杂性，更深层次地涉及到安全策略在技术实现、运维管理以及合规审计等多重维度的制约。

鉴于此，本节将从策略生成的准确性、异构环境的一致性、运行时防护的自愈能力以及决策逻辑的可解释性这四个关键维度展开详细剖析。通过结合国内外最新的研究成果与行业实践报告，本文旨在系统性地解构制约零信任微隔离技术发展的核心瓶颈，从而明晰当前的研究空白，为本文提出的创新性解决方案奠定立论基础。



\subsubsection{策略生成的准确性}
在云原生环境中，微服务的高频部署与容器的短生命周期特性，对零信任策略的准确性与响应速度提出了极高的要求。然而，现有的技术路线普遍陷入了“静态覆盖不足”与“动态噪声干扰”的两难境地，很难在准确性与时效性之间找到平衡点。

一方面，基于静态分析的策略生成技术虽然能从代码逻辑推导出最小权限基线，但存在显著的“检查时与使用时不一致”（Time-of-Check to Time-of-Use, TOCTOU）问题。在 Kubernetes 集群中，工作负载的动态行为——例如 Pod 的故障迁移、Sidecar 代理的热加载——往往发生在部署之后。这意味着静态预设的规则很容易与运行时真实的拓扑产生时空错位，导致短暂的权限漏洞窗口 \cite{CISA2024}。相关的行业调查显示，超过 35\% 的安全团队在实施微隔离时，因为无法动态适应应用变更而遭遇了严重的性能瓶颈与业务阻断，最终迫使运维人员不得不放宽策略粒度，牺牲安全性来换取可用性 \cite{AccuKnox2024}。

另一方面，基于流量学习的动态生成方法虽然具备实时性，但极易受环境噪声干扰而产生“过拟合”或“欠拟合”现象。Palo Alto Networks 的研究指出，在东西向流量高度复杂的微服务网格中，单纯依赖流量基线很难有效区分合法的异常波动与恶意的横向移动。在零日攻击场景下，这种方法的有效阻断率仅徘徊在 15\% 到 30\% 之间，且存在较高的误报风险 \cite{PaloAlto2024}。

此外，在多云分布式架构下，跨域策略数据的同步往往存在显著的“收敛延迟”。CISA 在其零信任成熟度模型中强调，传统策略引擎在面对云原生“瞬生灭变”的特征时，策略下发的滞后性已成为制约防御效能的主要瓶颈 \cite{CISA2024}。尽管近年来有学者尝试利用机器学习算法来优化流量聚类，但这类黑盒模型在面对对抗样本时泛化能力有限，且缺乏可解释性，很难作为关键基础设施的唯一决策依据 \cite{He2023AdversarialML}。

综上所述，单一的静态预判或动态学习均无法满足云原生微隔离的高标准要求，构建一种融合静态语义与动态行为的混合式策略生成机制势在必行。

\subsubsection{异构环境的一致性}

云原生架构的演进呈现出显著的多云混合（Multi-Cloud Hybrid）趋势，微服务往往跨越私有云（Kubernetes）、公有云托管平台（如 AWS EKS, Azure AKS）以及边缘计算节点（Edge Nodes）进行分布式部署。这种基础设施的异构性导致零信任微隔离策略在跨域迁移时面临严重的一致性挑战。

首先，底层控制平面的碎片化导致了严重的“厂商锁定”与策略孤岛。现有的微隔离方案高度依赖特定的网络插件（CNI）或服务网格实现（如 Istio 基于 Envoy 代理，Cilium 基于 eBPF 钩子）。不同技术栈之间的策略模型存在巨大的语义鸿沟，缺乏统一的标准描述语言\cite{CNCF2023}。例如，在多云架构中，将业务从私有 IDC 迁移至公有云时，往往需要将数千条 iptables 规则手动重构为云厂商特定的 Security Group 规则。这种重复劳动不仅导致运维成本指数级增长，更违背了云原生“声明式（Declarative）”与“一次编写，到处运行”的设计初衷\cite{Axiomatics2022}。

其次，“棕地（Brownfield）”集成是企业数字化转型中不可回避的痛点。现实系统中往往共存着现代化的微服务容器与遗留的单体应用（Legacy Monoliths）。这些遗留系统缺乏 Sidecar 注入能力或对现代零信任协议（如 SPIFFE/SPIRE）的支持，导致微隔离策略在实施时出现兼容性断层\cite{CSA2017}。

此外，在 5G 核心网（5G Core）与 Serverless 无服务器计算等新兴场景下，策略的执行效率与粒度平衡面临严峻考验。3GPP 在其安全架构标准中明确指出，服务化架构（SBA）中的高吞吐量信令交互要求安全策略必须具备极低的时延，然而各设备厂商对标准的不同解读与自定义实现（Proprietary Implementation），导致跨厂商设备的微隔离互操作性极差\cite{3GPP_TS33501}。特别是在 Serverless 场景下，由于底层基础设施被云厂商深度抽象，用户失去了对操作系统内核的控制权，传统的基于代理（Agent-based）的微隔离机制失效。研究表明，在无服务器环境中移植策略往往需要针对特定运行时进行繁琐的手动调整，极易引入“配置漂移（Drift）”风险，导致防护效能显著下降\cite{Li2021SecuringSC}。

权威调研报告指出，这种跨环境的策略碎片化已成为多云安全治理的最大障碍，构建一个跨平台、标准化的策略抽象层已成为行业迫切需求\cite{PaloAlto2023}。



\subsubsection{运行时防护的自愈能力}

在云原生环境中，持续集成/持续部署（CI/CD）流水线带来的灰度发布、自动扩缩容以及故障自愈机制，使得基础设施处于极度不稳定的“流体”状态。这种高频的动态变化导致预定义的静态白名单与实际通信路径之间产生显著的“时空错位”，即所谓的“运行时漂移（Runtime Drift）”*。

首先，微服务实例的“瞬态性（Ephemerality）”加剧了策略的“腐化（Decay）”速率，Datadog 的大规模测量研究也证实，Kubernetes 集群中超过三分之一的 Pod（如 Job 或 CronJob 类型）在 1 分钟内即完成销毁\cite{Datadog2024}。然而，现有的策略执行点（PEP）往往依赖于静态的 IP 地址绑定或非实时的标签同步。当新实例上线或发生故障迁移时，基于 iptables 或 IPVS 的底层规则更新往往存在分钟级的延迟，导致新实例在启动初期缺乏管控，或旧规则残留形成“幽灵策略（Ghost Policies）”，极易被攻击者利用进行持久化驻留\cite{CrowdStrike2024}。

其次，缺乏针对“概念漂移（Concept Drift）”的闭环矫正机制是当前技术的重大缺陷。在多租户与多集群场景下，业务流量模式并非一成不变，而是随着业务逻辑迭代发生动态偏移。现有的监控体系多侧重于系统指标（Metrics）而非安全语义，导致漂移检测存在严重的滞后性（Lag）。NIST 在其微服务安全标准（SP 800-204B）中指出，若缺乏对应用层语义（L7）的持续再验证，任何静态授权模型都会随着时间推移而退化为过权状态（Over-privileged）\cite{2021AttributebasedAC}。Gartner 的市场指南进一步量化了这一风险：超过 60\% 的微隔离失效并非源于初始策略的逻辑错误，而是源于策略未能跟随工作负载的变更而及时演进，最终导致运维团队被迫将防护模式回退至“监控模式”\cite{Gartner2023}。

尽管学术界尝试引入深度学习（Deep Learning）构建自适应的自愈框架，但在生产环境中部署此类“重型”模型面临严峻的“资源-精度”权衡难题。一方面，高频的流量推理抢占了业务容器宝贵的计算资源（CPU/Memory），违背了云原生轻量化的原则；另一方面，研究表明\cite{Andresini2021INSOMNIATC}，基于统计学的异常检测模型在面对非平稳分布的流量时，极易混淆正常的突发流量（Flash Crowd）与恶意攻击，高误报率（False Positive）使得自动化阻断功能在实际工程中难以落地。



\subsubsection{决策逻辑的可解释性}


在零信任微隔离的落地实践中，自动化策略生成算法往往面临着“计算高效”与“逻辑透明”的零和博弈。尽管自动化工具能够基于流量或依赖关系快速生成海量的访问控制列表（ACL），但其生成过程的“黑盒化”特征严重阻碍了在严格合规环境下的工程应用。

首先，监管法规对自动化运维系统的“可审计性（Auditability）”提出了硬性约束。我国《网络安全等级保护基本要求》（GB/T 22239-2019）明确规定，安全管理中心必须具备对安全策略配置依据的追溯与核查能力\cite{GBT22239}。欧盟《通用数据保护条例》（GDPR）亦强调了对“自动化决策（Automated Decision-Making）”的解释权。然而，现有的策略生成引擎大多仅输出最终的阻断/放行规则，缺乏对“归因链条（Attribution Chain）”的完整记录——即无法回答“某条规则是基于哪个业务意图、哪段通信历史或哪项合规基线而生成”的因果问题\cite{NIST800207}。

其次，“语义鸿沟（Semantic Gap）”与“规则爆炸”导致了认知负荷的极限挑战。大规模微服务集群往往产生数以万计的底层网络规则（L3/L4），这些规则以 IP、端口或标签为载体，彻底丢失了上层的业务语义（L7）。ACM Computing Surveys 的最新综述指出，随着微服务数量的增长，底层规则之间的“逻辑冲突（Logical Conflicts）”（如影子规则、冗余规则）呈指数级上升，且难以通过人工手段识别\cite{Yarygina2018OvercomingSC}。

此外，在多策略源并存的复杂场景下，算法内部的“冲突消解机制（Conflict Resolution）”往往是不透明的。NIST 在其属性访问控制（ABAC）标准中指出，当静态基线与动态流量推导出的规则发生逻辑互斥时，自动化系统通常基于预设的优先级（如“拒绝优先”）进行静默处理，而未向管理员暴露决策依据，导致实际生效的安全边界与预期设计严重偏离\cite{NIST800162}。

因此，构建一种具备全链路溯源能力、能够将底层规则映射回高层业务意图的“白盒化”策略生成框架，是解决信任危机的关键。



\section{解决方案及其意义}

针对上述云原生微隔离领域在策略准确性、环境一致性以及可解释性方面面临的严峻挑战，本文提出了一种基于动静态协同分析与大模型语义增强的零信任微隔离策略生成框架。该框架旨在打破传统网络层（L3/L4）与业务应用层（L7）之间的语义壁垒，构建具备全生命周期感知与自适应能力的防护体系。

本文的核心解决方案包含以下两个层面的技术创新：

\subsection{动静态深度融合的策略生成机制}

为了解决单一分析视角存在的“盲区”，本文设计了静态代码分析（Static Analysis）与动态运行时感知（Dynamic Monitoring）的双向校验机制，以实现策略生成的全覆盖与高精度。

在静态侧，系统引入了程序语言分析领域的经典工具 Soot 框架。Vallée-Rai 等人\cite{Soot1999}在 1999 年提出的 Soot 框架能够对 Java 字节码进行全程序分析（Whole-Program Analysis），构建高精度的类粒度调用图（Call Graph）。利用这一能力，系统可以预先识别代码中潜在的隐式依赖与远程调用逻辑，从而覆盖那些在测试阶段未被流量触发的“冷路径”（Cold Paths），有效解决了纯流量学习方案覆盖率不足的问题。

在动态侧，系统利用 Kubernetes 的 Informer 机制与 eBPF 技术，实时监听集群内的资源变更（如 Pod 漂移、Service 变动）及实际流量轨迹。Isovalent 的研究表明\cite{Isovalent2023}，通过内核层的 eBPF 探针可以无侵入地获取服务间的真实拓扑 。本文通过将静态分析提取的调用链路与动态采集的运行时拓扑进行图同构映射（Graph Isomorphism Mapping），既剔除掉了静态代码中未被加载的死代码（Dead Code），又补全了静态分析无法感知的动态反射调用，从而实现了策略生成的高覆盖率。

\subsection{大模型驱动的语义对齐与合规解释}

针对自动化策略生成过程中的“黑盒化”与“语义鸿沟”问题，本文引入大语言模型（LLM）作为安全知识的推理引擎，利用其强大的语义理解能力来提升策略的可解释性。

首先，系统集成了 DeepWiki 仓库级依赖挖掘技术。Du 等人\cite{Du2025DependEvalBL}在 ACL 2025 上发表的研究指出，DeepWiki 能够跨越文件边界，精准提取代码库中的深层依赖关系 。利用这一技术，系统可以将底层的 Kubernetes NetworkPolicy 规则（YAML）逆向映射回具体的业务代码片段与高层设计意图，解决策略与业务割裂的问题。

其次，系统采用了思维链（Chain-of-Thought, CoT）推理技术。Wei 等人\cite{wei2022chain}在 NeurIPS 上证明，通过引导大模型生成中间推理步骤，可以显著提升其处理复杂逻辑任务的准确性 。本文利用 CoT 技术构建了双向解释机制：一方面，将自然语言描述的安全需求自动转化为形式化的 ACL 规则；另一方面，为每一条生成的阻断策略提供符合自然语言逻辑的“归因证据”，例如指出某条规则是基于哪个业务模块的数据库访问需求而生成的。Chen 等人\cite{chen2021evaluating}的研究表明，这种基于代码语义的解释机制能够显著降低安全审计的认知门槛，使自动化策略满足合规性要求 。

\subsection{研究意义}

本研究的学术与应用意义主要体现在以下两个方面：

\begin{enumerate}
    \item 理论意义：本文提出了一种融合程序语言分析（PL）与网络安全（Security）的跨域建模方法。通过将代码级的静态语义与网络级的动态行为进行对齐，验证了利用大模型解决安全策略“语义鸿沟”的可行性，为零信任架构下细粒度访问控制的自动化研究提供了新的理论范式。

    \item 工程价值：通过自动化替代人工配置，本方案显著降低了大规模微服务集群的运维熵增（Entropy）。实测表明，该框架可将策略部署效率提升一个数量级，同时确保了在多云异构环境下的策略一致性，为企业核心业务上云提供了可落地、可审计且具备自愈能力的内生安全保障。
\end{enumerate}


\section{论文结构}

本文围绕云原生环境下微服务安全防护的核心痛点，遵循“背景分析—理论基础—系统实现—实验验证—总结展望”的逻辑脉络展开论述，全文共分为六章，各章节的具体组织结构如下：

第一章：绪论。
本章首先阐述了云原生技术范式的演进背景，剖析了在容器化与微服务架构下，传统边界防御失效、东西向流量不可视以及动态漂移等安全挑战，明晰了研究零信任微隔离技术的迫切性与工程意义。随后，系统梳理了国内外在基于流量分析、静态分析及角色访问控制等领域的最新研究进展，指出了现有方案在策略覆盖率、实时性与可解释性方面存在的局限。最后，概括了本文的主要研究内容、创新点及全篇的组织架构。

第二章：相关技术概述。
本章为后续系统的设计与实现奠定理论与技术基础。首先，详细介绍了容器核心原理（Namespace/Cgroups）与 Kubernetes 编排机制，重点解析了 NetworkPolicy 的执行流程与 Informer 事件驱动模型。其次，阐述了 Soot 静态分析框架在 Java 字节码切片与调用图构建中的应用。最后，介绍了大语言模型（LLM）的基础原理，重点探讨了 Transformer 架构、DeepWiki 仓库级依赖挖掘技术以及 LLM 在结构化输出与安全约束方面的技术路径。

第三章：动静态分析的零信任网络策略生成系统。
本章详细论述了“确定性”策略生成子系统的设计与实现。首先，介绍了基于 eBPF 与 K8s Informer 的运行时数据采集模块，涵盖 Pod、Service 及注册中心配置的多维感知。其次，深入剖析了基于 Soot 的静态分析引擎，阐述了第三方依赖过滤、自定义类提取及类/微服务粒度调用关系图（Call Graph）的构建算法 。最后，提出了从服务拓扑到 Pod 标签的映射机制，以及具备冗余消除与冲突检测能力的最小化白名单生成算法。

第四章：基于大模型代码分析的零信任微隔离策略双向智能生成。
本章重点论述了引入 LLM 进行语义增强的“智能化”子系统。首先，构建了统一的多源信息采集机制，实现了 GitHub 仓库与 Kubernetes 运行时资源的精确绑定 。在此基础上，设计了双向生成模块：一方面，实现了以 NetworkPolicy 为起点的逆向解释，利用大模型对规则合理性进行校验并生成自然语言解释；另一方面，实现了以 Pod 为起点的正向生成，结合 DeepWiki 安全知识库与代码语义理解，自动合成符合最小权限原则的微隔离策略。

第五章：实验与分析。
本章对提出的框架进行了系统性的验证。首先介绍了基于双集群 Kubernetes 的实验环境搭建方案与包含 14 个典型云原生组件（如 Airflow, TiDB）的测试数据集 。随后，定义了真阳性率（TP）与假阳性率（FP）等评价指标。最后，对比分析了不同大语言模型（如 GPT-4o 与 DeepSeek R1）在策略校验任务中的性能表现，并对自动生成的策略数量与质量进行了统计验证，证明了本方案在精确性与安全性上的优势。

第六章：总结与展望。
本章对全文的研究工作与核心成果进行了全面总结，客观分析了当前系统在极端高并发场景下的性能瓶颈与局限性，并对未来在多云异构架构支持、边缘计算场景适配等方向的研究前景进行了展望。。



\section{本章小结}
本章介绍了云原生应用对分布式系统安全带来动态威胁与碎片化挑战的课题背景，并将零信任微隔离技术分类。从基于流量分析的策略生成、基于角色的访问控制、基于静态分析的策略生成这三类防护技术分别介绍了国内外的最新研究进展。之后，本章介绍了本文所设计和实现的零信任微隔离策略生成框架，并阐述了其中的挑战，工作与意义。最后，介绍了本文的论文结构。


\chapter{相关技术}
\label{sec:related_work}

本章重点阐述支撑零信任微隔离策略生成系统的核心技术基础。首先分析容器技术的隔离机制及其在网络安全层面的局限性；其次解析Kubernetes编排系统的网络模型与事件驱动机制；随后探讨Soot静态分析框架在字节码依赖提取中的应用；最后阐述大语言模型在代码语义理解与自动化推理方面的技术原理。

\section{容器技术}
\label{subsec:container_tech}

容器技术通过操作系统级的虚拟化实现应用的轻量级封装与隔离，是云原生架构的基石。不同于传统虚拟机（Virtual Machine, VM）依赖Hypervisor模拟硬件层，容器直接运行于宿主机内核之上，具备毫秒级启动与高密度部署特性~\cite{merkel2014docker}。

\subsection{命名空间与控制组机制}
容器的隔离性主要依赖Linux内核的命名空间（Namespaces）与控制组（Cgroups）机制。命名空间负责实现资源的逻辑隔离，例如PID Namespace实现了进程视图的隔离，Network Namespace提供了独立的网络协议栈（包括网卡、路由表、防火墙规则），而Mount Namespace则通过挂载点隔离构建了独立的文件系统视图~\cite{kerrisk2013namespaces}。控制组（Cgroups）则负责对CPU、内存、磁盘I/O等物理资源进行配额限制与优先级调度，防止单一容器耗尽节点资源~\cite{menage2007cgroups}。

然而，容器的隔离本质上是共享内核的进程级隔离。相比于虚拟机的硬件级虚拟化，容器并未实现彻底的攻击面隔离。研究表明，一旦发生内核漏洞逃逸，攻击者极易突破命名空间限制获取宿主机权限~\cite{sultan2019container}，这对容器间的网络微隔离提出了更高的防护要求。

\subsection{联合文件系统}
容器镜像采用分层存储架构，通过联合文件系统（UnionFS）将不同的物理目录挂载到同一虚拟文件系统下。典型的实现如OverlayFS，利用下层（LowerDir）的只读镜像层与上层（UpperDir）的可读写容器层进行堆叠~\cite{brown2013overlayfs}。这种写时复制（Copy-on-Write, CoW）机制不仅优化了存储空间，也为静态分析提供了便利：通过解析只读镜像层的文件结构，可以在不运行容器的情况下提取应用制品（Artifacts），为后续的依赖分析提供数据源。

\subsection{容器网络接口标准}
随着容器生态的发展，容器网络接口（Container Network Interface, CNI）成为连接容器运行时与网络插件的标准规范~\cite{cncf2023cni}。CNI插件负责在容器创建时分配IP地址、配置网桥或虚拟网卡（veth pair），并负责路由表的维护。在云原生环境中，CNI插件（如Calico、Cilium）是实施微隔离策略的执行主体，它们通过拦截进出Pod的网络流量，依据预定义的策略进行放行或阻断。


\section{Kubernetes 容器编排技术}
\label{subsec:k8s_tech}

Kubernetes（K8s）作为当前云原生生态的事实标准，源于 Google 内部的 Borg 集群管理系统。它不仅是一个部署工具，更提供了一套用于构建分布式系统的声明式 API 和控制平面，为微服务的自动化治理提供了基础设施层面的支持~\cite{burns2016borg}。

\subsection{核心架构与资源抽象}
Kubernetes 采用典型的“控制平面-数据平面”解耦架构。控制平面（Control Plane）包含 API Server、Etcd、Scheduler 和 Controller Manager 等核心组件，负责维护集群的全局状态与调度决策；数据平面（Data Plane）则由运行在各工作节点上的 Kubelet 和 Kube-Proxy 组成，负责容器生命周期的具体执行与网络规则的维护。

在资源抽象层面，Kubernetes 引入了 Pod 作为最小调度单元，通过将紧密耦合的容器封装在共享的 Network 和 IPC 命名空间中，解决了微服务进程间的协同问题。Service 资源则提供了一组 Pod 的逻辑抽象与稳定的虚拟 IP（ClusterIP），利用标签选择器（Label Selector）屏蔽了后端 Pod IP 动态变化带来的寻址复杂性。这种基于标签的松耦合关联机制，是本文构建动态微隔离策略的核心依据。

\subsection{网络策略模型}
为了在扁平化的 Pod 网络中实现访问控制，Kubernetes 定义了 NetworkPolicy 资源对象。该对象本质上是一种以应用为中心的白名单防火墙规则，允许管理员通过 \texttt{podSelector} 和 \texttt{namespaceSelector} 精确界定流量边界，控制入站（Ingress）与出站（Egress）的通信权限~\cite{nist800190}。

值得注意的是，NetworkPolicy 仅定义了策略规范，其实际执行依赖于底层的 CNI 插件（如 Calico, Cilium）。虽然基于 iptables 或 IPVS 的传统实现能够满足基本的 L3/L4 隔离需求，但随着集群规模的扩大，海量规则的查找与更新面临显著的性能瓶颈。此外，原生 NetworkPolicy 缺乏对应用层协议（L7）的感知能力，无法防御基于合法端口的逻辑攻击，这为引入代码级语义分析提供了必要性。

\subsection{Informer 事件驱动机制}

\begin{figure}[htbp]
  \centering
  \resizebox{1.0\textwidth}{!}{
    \begin{tikzpicture}[
        font=\sffamily\small,
        >=Stealth,
        basic box/.style={
            draw=gray!50,
            rectangle,
            rounded corners=3pt,
            minimum width=3.8cm,
            minimum height=1.3cm,
            align=center,
            fill=white,
            drop shadow={opacity=0.1, shadow xshift=1pt, shadow yshift=-1pt},
            inner sep=4pt,
            line width=0.7pt
        },
        ext box/.style={basic box, draw=gray!60, fill=gray!5, dashed},
        core box/.style={basic box, draw=blue!40, fill=blue!5},
        store box/.style={basic box, draw=orange!40, fill=orange!5},
        handler box/.style={basic box, draw=violet!40, fill=violet!5},
        line/.style={->, draw=gray!60, thick, rounded corners=4pt},
        label font/.style={font=\scriptsize\bfseries, text=gray!80}
    ]

    % --- 坐标定义 (x, y) ---
    % 第一行
    \node[ext box] (apiserver) at (0, 0) {\textbf{API Server} \\ \scriptsize (集群状态)};
    \node[core box] (reflector) at (5, 0) {\textbf{Reflector} \\ \scriptsize (监听与同步)};
    \node[core box] (fifo) at (10, 0) {\textbf{DeltaFIFO} \\ \scriptsize (增量对象队列)};

    % 第二行 (居中分布)
    \node[store box] (indexer) at (2.5, -3) {\textbf{Indexer / Store} \\ \scriptsize (本地线程安全缓存)};
    \node[core box] (informer) at (7.5, -3) {\textbf{Informer 控制器} \\ \scriptsize (事件处理循环)};

    % 第三行
    \node[handler box] (handler) at (7.5, -5.5) {\textbf{资源事件处理器} \\ \scriptsize (新增/更新/删除回调)};

    % --- 连线逻辑 (修正标注位置以防重叠) ---
    \draw[line] (apiserver.east) -- node[above, label font] {List-Watch 监听} (reflector.west);
    \draw[line] (reflector.east) -- node[above, label font] {同步增量} (fifo.west);
    
    % FIFO -> Controller (折线)
    \draw[line] (fifo.south) -- (10, -1.5) -| (informer.north) 
          node[pos=0.2, right, label font, xshift=2pt] {弹出事件};
    
    \draw[line] (informer.west) -- node[above, label font] {更新缓存} (indexer.east);
    \draw[line] (informer.south) -- node[right, label font, xshift=2pt] {分发触发} (handler.north);

    % 业务查询虚线 (绕开文字)
    \draw[line, dashed, gray!50] (handler.west) -- (2.5, -5.5) -- (indexer.south) 
          node[pos=0.3, above, label font] {只读业务查询};

    % --- 背景分组框 (文字移动到框外避免冲突) ---
    \begin{scope}[on background layer]
      \node[draw=gray!20, dashed, fill=gray!2, rounded corners=8pt, fit=(apiserver) (fifo), inner sep=12pt] (bg_cp) {};
      % 灰字移动到上方
    %   \node[anchor=south west, font=\scriptsize\bfseries, text=gray!40] at (bg_cp.north west) {Kubernetes 控制平面 (Control Plane)};

      \node[draw=blue!10, dashed, fill=blue!2, rounded corners=8pt, fit=(indexer) (handler), inner sep=15pt] (bg_client) {};
      % 蓝字移动到下方
    %   \node[anchor=north east, font=\scriptsize\bfseries, text=blue!30] at (bg_client.south east) {Client-go Informer 框架};
    \end{scope}

    \end{tikzpicture}
  }
  \caption{Kubernetes Informer 机制组件协作与事件驱动流程示意图}
  \label{fig:k8s_informer_structure_cn}
\end{figure}

在零信任安全体系中，策略引擎需要实时感知工作负载的生灭与漂移。若采用传统的轮询（Polling）方式查询 API Server，不仅时效性差，且会给控制平面带来巨大的负载压力。Kubernetes 客户端库（client-go）为此提供了 Informer 机制，如图\ref{fig:k8s_informer_structure_cn}所示，基于 List-Watch 接口实现了高效的事件驱动模型~\cite{Shamim2022}。



Informer 的核心组件包括 Reflector 和 Indexer。Reflector 负责与 API Server 建立长连接，实时监听（Watch）资源变更事件，并将增量数据写入 DeltaFIFO 队列；Indexer 则在客户端本地维护一份线程安全的只读缓存，通过索引加速数据检索。本文提出的策略生成系统深度利用了 SharedInformer 机制，能够在毫秒级延迟内捕获 Pod 的创建、销毁及标签变更事件，从而触发微隔离策略的动态计算与下发，解决了静态策略无法适应云原生动态环境的难题。

\section{Soot 静态分析技术}
\label{subsec:soot_tech}

Soot 是 Java 语言分析领域最通用的静态分析与优化框架之一，最初由麦吉尔大学 Sable 研究组开发。它通过将 Java 字节码（Bytecode）转换为中间表示（Intermediate Representation），提供了一套用于分析和转换 Java 程序的 API。在云原生微服务场景下，Soot 能够直接处理编译后的 \texttt{.class} 文件或 JAR 包，无需源代码即可提取类结构、继承关系及成员变量定义，为构建服务间的依赖关系提供了底层技术支撑~\cite{vallee1999soot}。

\subsection{Java 字节码与类文件解析}
Java 字节码是运行在 Java 虚拟机（JVM）上的二进制指令集。根据 JVM 规范，类文件（Class File）存储了类的全限定名、父类引用、接口实现列表、字段表（Fields）及方法表（Methods）。Soot 框架首先通过 \texttt{SootResolver} 组件加载类路径下的所有类文件，将其解析为内存中的 \texttt{SootClass} 对象。这一过程能够完整保留类的元数据信息，包括修饰符（public/private）、注解（Annotations）以及泛型签名，是后续识别 AOP 切面标记或依赖注入注解的基础~\cite{lindholm2014java}。

\subsection{Jimple 中间表示}
为了克服原生字节码基于栈架构（Stack-based）难以分析的缺点，Soot 引入了 Jimple 中间表示。Jimple 是一种基于类型的三地址码（3-Address Code），它将复杂的栈操作指令转换为显式的赋值语句（如 \texttt{x = y + z}）。

Jimple 的核心优势在于简化了控制流分析。在 Jimple 中，所有的实例方法调用（Invokevirtual）和接口调用（Invokeinterface）都被显式保留，且变量的定义与使用关系（Def-Use）清晰可见。这使得分析工具能够直接通过扫描 Jimple 语句（Statement）来识别代码中的方法调用行为，而无需模拟 JVM 的操作数栈行为~\cite{vallee2010soot}。

\subsection{类层次与结构分析能力}

\begin{figure}[htbp]
  \centering
  \resizebox{0.95\textwidth}{!}{
    \begin{tikzpicture}[
        font=\sffamily\small,
        >=Stealth,
        basic box/.style={
            draw=gray!50,
            rectangle,
            rounded corners=3pt,
            minimum width=3.8cm,
            minimum height=1.3cm,
            align=center,
            fill=white,
            drop shadow={opacity=0.1, shadow xshift=1pt, shadow yshift=-1pt},
            inner sep=6pt,
            line width=0.7pt
        },
        input box/.style={basic box, draw=gray!60, fill=gray!5, dashed},
        core box/.style={basic box, draw=blue!40, fill=blue!5},
        model box/.style={basic box, draw=orange!40, fill=orange!5},
        line/.style={->, draw=gray!60, thick, rounded corners=4pt},
        label font/.style={font=\scriptsize\bfseries, text=gray!80}
    ]

    % --- 节点定义 ---
    \node[input box] (bytecode) at (0,0) {\textbf{Java 字节码} \\ \scriptsize (.class / .jar 制品)};

    \node[core box] (resolver) at (0,-2.5) {\textbf{Soot 解析器} \\ \scriptsize (元数据加载)};
    \node[core box] (hierarchy) at (5,-2.5) {\textbf{层级分析器} \\ \scriptsize (类层次快速分析)};

    \node[model box] (inherit) at (0,-5.5) {\textbf{继承关系视图} \\ \scriptsize (Extends / Implements)};
    \node[model box] (fields) at (5,-5.5) {\textbf{成员字段模型} \\ \scriptsize (类型与注解扫描)};
    \node[model box] (methods) at (10,-5.5) {\textbf{方法签名视图} \\ \scriptsize (描述符)};

    % --- 连线逻辑 (避开文字冲突) ---
    \draw[line] (bytecode.south) -- node[right, label font, xshift=2pt] {加载资产} (resolver.north);
    \draw[line] (resolver.east) -- node[above, label font] {类型解析} (hierarchy.west);

    \draw[line] (resolver.south) -- node[right, label font, xshift=2pt] {提取建模} (inherit.north);
    \draw[line] (hierarchy.south) -- (fields.north);
    
    % 使用折线连接最右侧节点
    \draw[line] (hierarchy.east) -| (methods.north) 
          node[pos=0.3, above, label font] {上下文映射};

    % % 底部反馈线
    % \draw[line, dashed, gray!50] (methods.south) -- ++(0,-0.8) -| 
    %       node[pos=0.25, below, label font] {为第三章调用图构建提供基础数据} (inherit.south);

    % --- 背景分组框 ---
    \begin{scope}[on background layer]
      \node[draw=blue!10, dashed, fill=blue!2, rounded corners=8pt, fit=(resolver) (hierarchy), inner sep=15pt] (bg_core) {};
      \node[anchor=south west, font=\scriptsize\bfseries, text=blue!30] at (bg_core.north west) {Soot 核心分析引擎};

      \node[draw=orange!10, dashed, fill=orange!2, rounded corners=8pt, fit=(inherit) (methods), inner sep=15pt] (bg_model) {};
    %   \node[anchor=north east, font=\scriptsize\bfseries, text=orange!30] at (bg_model.south east) {提取出的程序结构模型};
    \end{scope}

    \end{tikzpicture}
  }
  \caption{Soot 框架类层次分析与程序结构提取流程示意图}
  \label{fig:soot_analysis_cn}
\end{figure}


如图\ref{fig:soot_analysis_cn}所示，Soot 提供了强大的类层次分析（Class Hierarchy Analysis, CHA）与结构提取能力，这是构建类之间静态依赖关系的核心机制：

\begin{itemize}
    \item 继承与实现关系分析：Soot 维护了一个全局的类层次结构树（Hierarchy），能够快速查询任意两个类是否存在继承（Extends）或接口实现（Implements）关系。这为识别基于多态的调用链路提供了必要的类型约束信息~\cite{dean1995optimization}。
    \item 成员变量与字段分析：通过 \texttt{SootField} 对象，Soot 允许分析人员遍历类中定义的所有成员变量及其类型。这在微服务分析中尤为重要，因为许多服务依赖是通过成员变量注入（如 \texttt{@Autowired} 或 \texttt{@Resource}）建立的。Soot 能够提取字段的声明类型，从而建立当前类与字段类型之间的关联边。
    \item 方法体与切面逻辑可见性：对于采用面向切面编程（AOP）的代码，编译后的字节码中往往包含由编译器织入（Weaving）的额外调用逻辑。Soot 对字节码的分析基于最终的编译产物，因此能够“看到”并解析这些由 AOP 框架自动生成的字节码指令，从而建立起切面类与目标类之间的关联。
\end{itemize}

综上所述，Soot 不仅是一个字节码转换工具，更提供了一个包含类结构、字段定义及方法签名的完整对象模型，为静态提取微服务内部复杂的类间依赖提供了完备的视图。



\section{大语言模型技术}
\label{subsec:llm_tech}

大语言模型（Large Language Model, LLM）是近年来人工智能领域的重要进展。在云原生安全领域，LLM 不仅需要理解单文件的代码逻辑，更需要具备跨文件的仓库级理解能力，以弥合“非结构化代码逻辑”与“结构化安全策略”之间的语义鸿沟~\cite{bommasani2021opportunities}。

\subsection{Transformer 架构与代码建模}
现代大语言模型主要基于 Transformer 架构，其核心创新在于引入了自注意力（Self-Attention）机制。对于代码分析任务，Transformer 的优势在于能够捕捉长距离的依赖关系（Long-range Dependencies）。通过多头注意力（Multi-Head Attention）机制，模型能够从不同的语义子空间同时关注代码的语法结构、数据流向及控制流逻辑，从而在没有显式编译过程的情况下理解程序的业务意图~\cite{vaswani2017attention}。

然而，通用 LLM 在处理代码任务时面临着显著的上下文窗口（Context Window）限制。微服务项目通常由数百个源文件组成，直接将整个仓库（Repository）输入模型会超出长度限制或导致“迷失中间（Lost-in-the-Middle）”现象，这使得模型难以捕捉跨文件的隐式依赖。

\subsection{DeepWiki：仓库级依赖挖掘框架}
为了解决大模型在全仓库理解上的瓶颈，DeepWiki 项目提出了一种基于 LLM 的仓库级依赖挖掘新范式。DeepWiki 的核心原理是将代码仓库视为一个巨大的知识库，通过“静态索引 + 动态检索”的方式实现对跨文件依赖的精准捕获~\cite{Du2025DependEvalBL}。

DeepWiki 的技术路径主要包含两个关键步骤：
\begin{enumerate}
    \item 语义索引构建：利用静态分析工具提取代码中的实体（如类、方法、变量）及其拓扑关系（如继承、调用、引用），构建项目级的代码知识图谱（Code Knowledge Graph）。同时，利用代码大模型生成每个实体的语义摘要（Summary），将其向量化后存入向量数据库。
    \item 上下文感知检索：当需要分析某个微服务的对外调用时，DeepWiki 不再输入全部代码，而是根据当前分析的焦点（如一个 Controller 类），在知识图谱中游走检索其关联的依赖节点（如 Service 接口及其实现类）。
\end{enumerate}

这种机制使得 LLM 能够在有限的上下文窗口内，获取到跨越多个文件的完整调用链路信息，从而准确识别出微服务间隐藏的远程调用逻辑。

\subsection{思维链推理与结构化生成}
在获取了完整的代码上下文后，利用思维链（Chain-of-Thought, CoT）技术可以进一步增强模型的推理鲁棒性。CoT 引导模型在生成最终的安全策略之前，显式地生成中间推理步骤（例如：“首先定位到 \texttt{OrderController}，发现其调用了 \texttt{PaymentService} 接口，经 DeepWiki 检索该接口实现类绑定了 \texttt{/api/pay} 路径”）。这种分步推理机制显著提高了策略生成的准确率，并缓解了深度学习模型的“黑盒”不可解释问题~\cite{wei2022chain}。

\section{本章小结}
\label{sec:chap2_summary}

本章对支撑零信任微隔离策略生成系统的关键技术进行了梳理。首先，分析了容器与 Kubernetes 编排机制，指出原生网络策略在动态环境下的局限性，并确立了基于 Informer 的实时数据采集方案。其次，探讨了 Soot 静态分析框架，利用 Jimple 中间表示与类结构分析能力，为从字节码中提取确定的服务依赖提供了理论支撑。最后，介绍了大语言模型及 DeepWiki 框架，论证了其在跨文件依赖挖掘与策略语义增强方面的优势。上述技术共同构成了本文动静态协同分析框架的工程基础。





\chapter{动静态分析的零信任网络策略生成系统}
\label{chap:system_design}

本章详细阐述动静态协同分析系统的总体架构与实现细节。针对云原生环境下微服务生命周期短、安全意图识别难等挑战，本系统设计了一套纵向贯穿基础设施到策略交付、横向融合动态运行时指纹与静态字节码逻辑的技术框架。

\begin{figure}[htbp]
  \centering
  \resizebox{0.9\textwidth}{!}{
    \begin{tikzpicture}[
        font=\sffamily\small,
        >=Stealth,
        % 统一方框样式
        basic box/.style={
            draw=gray!50,
            rectangle,
            rounded corners=3pt,
            minimum width=3.8cm,
            minimum height=1.2cm,
            align=center,
            fill=white,
            drop shadow={opacity=0.1, shadow xshift=1pt, shadow yshift=-1pt},
            inner sep=4pt,
            line width=0.7pt
        },
        infra box/.style={basic box, draw=gray!60, fill=gray!5, dashed},
        dyn box/.style={basic box, draw=blue!40, fill=blue!5},
        stat box/.style={basic box, draw=green!40!gray, fill=green!5},
        core box/.style={basic box, minimum width=9.5cm, minimum height=1.4cm, draw=orange!50, fill=orange!5, line width=1.2pt},
        out box/.style={basic box, draw=violet!40, fill=violet!5},
        line/.style={->, draw=gray!60, thick, rounded corners=4pt},
        label font/.style={font=\scriptsize\bfseries, text=gray!80}
    ]

    % --- 第一层：3.1 基础设施与采集入口 ---
    \node[infra box] (k8s) at (0, 0) {\textbf{Kubernetes 集群} \\ \scriptsize (运行环境)};
    \node[infra box] (bytecode) at (6, 0) {\textbf{Java 字节码制品} \\ \scriptsize (JAR / WAR 资源)};

    % --- 第二层：3.1 & 3.2 核心分析模块 ---
    \node[dyn box] (probe) at (0, 2.2) {\textbf{运行时探针} \\ \scriptsize (eBPF / K8s Informer)};
    \node[dyn box] (fingerprint) at (0, 4.2) {\textbf{动态指纹提取} \\ \scriptsize (环境变量 / 启动参数)};

    \node[stat box] (filter) at (6, 2.2) {\textbf{冗余过滤} \\ \scriptsize (依赖剔除 / 类过滤)};
    \node[stat box] (soot) at (6, 4.2) {\textbf{Soot 分析引擎} \\ \scriptsize (调用提取 / 污点分析)};

    % --- 第三层：3.3 动静态融合引擎 (核心) ---
    \node[core box] (graph) at (3, 6.5) {
        \textbf{微服务依赖图构建引擎 (Dependency Graph Builder)} \\
        \small 融合运行时拓扑 $G_{runtime}$ 与 静态调用链 $G_{static}$
    };

    % --- 第四层：3.4 策略交付层 ---
    \node[out box] (policy) at (0, 8.8) {\textbf{策略自动化生成} \\ \scriptsize (标签映射 / 白名单合成)};
    \node[out box] (conflict) at (6, 8.8) {\textbf{策略冲突消解} \\ \scriptsize (CIDR 聚合 / 逻辑检查)};

    % --- 连线逻辑 (紧凑路径) ---
    \draw[line] (k8s) -- node[left, label font] {事件流} (probe);
    \draw[line] (bytecode) -- node[right, label font] {制品流} (filter);
    \draw[line] (probe) -- (fingerprint);
    \draw[line] (filter) -- (soot);

    % 汇总至核心引擎
    \draw[line] (fingerprint.north) -- ++(0,0.5) -| ([xshift=-2.2cm]graph.south);
    \draw[line] (soot.north) -- ++(0,0.5) -| ([xshift=2.2cm]graph.south);

    % 分发至交付层
    \draw[line] (graph.north) -- ++(0,0.5) -| (policy.south);
    \draw[line] (graph.north) -- ++(0,0.5) -| (conflict.south);

    % --- 背景分组与标签 (避开冲突) ---
    \begin{scope}[on background layer]
      \node[draw=gray!20, dashed, fill=gray!2, rounded corners=6pt, fit=(k8s) (bytecode), inner sep=10pt] (bg_infra) {};
    %   \node[anchor=north west, font=\tiny\bfseries, text=gray!40] at (bg_infra.south west) {3.1 基础设施层};

      \node[draw=blue!10, dashed, fill=blue!2, rounded corners=6pt, fit=(probe) (fingerprint), inner sep=12pt] (bg_dyn) {};
      \node[anchor=south west, font=\tiny\bfseries, text=blue!30] at (bg_dyn.north west) {运行时感知模块};

      \node[draw=green!10, dashed, fill=green!2, rounded corners=6pt, fit=(filter) (soot), inner sep=12pt] (bg_stat) {};
      \node[anchor=south east, font=\tiny\bfseries, text=green!30] at (bg_stat.north east) {字节码分析模块};

      \node[draw=violet!10, dashed, fill=violet!2, rounded corners=6pt, fit=(policy) (conflict), inner sep=12pt] (bg_policy) {};
    %   \node[anchor=south east, font=\tiny\bfseries, text=violet!30] at (bg_policy.north east) {3.4 策略交付层};
    \end{scope}

    \end{tikzpicture}
  }
  \caption{动静态协同分析的零信任策略生成系统总体架构}
  \label{fig:system_architecture_refined}
\end{figure}

如图 \ref{fig:system_architecture_refined} 所示，系统整体架构严格遵循论文的逻辑脉络，由以下四个核心层级组成：

\begin{enumerate} 
    \item 基础设施层 (Infrastructure Layer)： 位于架构底部，是整个系统的数据源头。该层涵盖了处于运行态的 Kubernetes 集群以及待分析的 Java 字节码制品 .
    \item 动态感知与静态分析模块： 承接基础设施层提供的数据流。
\begin{itemize}
    \item 动态感知模块：利用 运行时探针 (Probe) 实时捕获集群事件，并执行动态指纹提取，以获取环境变量与注册中心配置。
    \item 静态分析模块：通过 三级过滤漏斗剔除冗余依赖，随后驱动 Soot 分析引擎 对字节码进行调用提取与语义分析。
\end{itemize}

\item 微服务依赖图构建引擎 (Dependency Graph Builder)： 作为系统的核心中枢，负责将动态感知的运行拓扑 $G_{runtime}$ 与静态分析得到的调用链 $G_{static}$ 进行深度融合。该引擎消除了动静态信息之间的“语义盲区”，构建出完整的服务依赖全景图。

\item 策略交付层 (Policy Layer)：处于架构顶端，基于融合后的依赖图执行 确定性策略生成。通过标签映射与白名单合成，并结合 策略冲突消解 模块，最终输出可落地的 Kubernetes NetworkPolicy。
\end{enumerate}

本章后续小节将围绕上述模块，依次论述各关键技术的具体设计思路与算法实现。



\section{运行时数据采集}
\label{sec:runtime_collection}

零信任微隔离策略的精确生成，依赖于对云原生集群运行状态的全面、真实刻画。仅依靠静态配置或离线代码分析，往往难以覆盖动态调度、弹性伸缩以及运行期配置变更等复杂场景，进而导致策略推导结果与实际运行环境存在偏差。为弥补这一不足，本文从运行时视角出发，构建了一套面向云原生环境的状态采集机制，为后续动静态联合分析提供可靠的环境上下文支撑。

针对上述需求，本文设计并实现了一个轻量级运行时采集探针（Collector），以独立服务的形式部署于 Kubernetes 集群内部。该探针不参与业务请求处理路径，仅通过标准接口感知集群运行态信息，其整体设计遵循“无侵入、低开销、强一致”的原则，确保在不影响业务稳定性的前提下，持续获取高可信度的运行数据。

运行时采集探针主要聚焦于以下四类关键信息，这些信息共同构成零信任策略生成所需的基础输入空间：

\begin{enumerate}
    \item 编排元数据：采集 Pod、Service 等 Kubernetes 原生资源对象的生命周期状态、命名空间归属及标签信息，用于构建微服务之间的基础网络拓扑与身份映射关系；
    \item 容器运行时信息：获取容器进程的环境变量、启动参数以及文件系统挂载结构，用以还原应用实例在运行阶段的真实配置上下文；
    \item 应用资产（Artifacts）：提取运行态容器内实际加载的 Java 字节码制品（如 JAR、WAR 文件），作为后续静态依赖分析与调用关系解析的直接输入；
    \item 服务注册信息：采集 Nacos、Eureka 等注册中心维护的服务实例与地址映射数据，用于解析微服务架构中逻辑服务名到物理网络地址之间的动态对应关系。
\end{enumerate}

通过对上述多源运行态信息的统一采集与建模，系统能够在策略生成阶段获得与真实集群状态高度一致的环境视图，从而为后续的静态分析、合规性审计以及策略正向生成提供确定性的输入基础。



\subsection{Kubernetes 资源}
\label{subsec:k8s_resource_collection}

在云原生环境中，Kubernetes 作为事实上的容器编排标准，其资源对象承载了集群运行状态与服务组织结构的核心信息。Pod、Service、Deployment 等资源不仅描述了应用的部署形态，还隐含了服务实例之间的潜在通信边界与身份语义。因此，准确、持续地获取 Kubernetes 资源状态，是构建零信任网络策略的重要前提。

与传统静态配置文件不同，Kubernetes 资源具有高度动态性。服务实例可能因弹性伸缩、滚动更新或故障迁移而频繁变化，若仅在策略生成初期进行一次性资源快照采集，将难以反映真实的运行环境，进而导致生成的网络策略在时效性和准确性上存在明显不足。针对这一问题，本文从“持续一致性”的角度出发，对 Kubernetes 资源的采集机制进行了专门设计。


Kubernetes 集群中的资源对象处于高频变更状态，Pod 的扩缩容、故障迁移（Failover）以及 Service 定义的更新都会直接影响微隔离策略的有效性。为了实现对集群资源拓扑的毫秒级感知，本系统摒弃了高延迟的 API 轮询（Polling）模式，转而采用基于 Kubernetes 官方客户端库 client-go的 SharedInformer 事件驱动机制~\cite{dobies2020kubernetes}。

\subsubsection{基于 List-Watch 的增量同步机制}
为了在保证数据完整性的同时降低采集开销，本文采用 Kubernetes 提供的 List-Watch 机制，实现对资源对象的增量同步。List-Watch 是 Kubernetes API Server 提供的一种事件驱动式资源监听模型，其核心思想是通过初始全量查询（List）与后续事件订阅（Watch）的组合，持续感知资源状态的变化过程。

在系统启动阶段，采集探针首先通过 List 接口获取目标资源类型的完整快照，以建立本地的初始状态视图。该阶段确保系统在任意时间点接入集群时，均能够获得一致且完整的资源基线。随后，探针通过 Watch 接口订阅资源变更事件，包括资源的创建、更新与删除操作。每当集群中相关资源状态发生变化时，API Server 会以事件流的形式将变更信息推送至探针侧，从而避免了周期性轮询带来的额外开销。

相较于基于定时扫描的采集方式，List-Watch 机制具有以下优势：一方面，其事件驱动特性显著降低了不必要的 API 请求数量，减少了对控制面的压力；另一方面，资源状态的变化能够被近实时感知，有助于保持本地视图与集群实际状态之间的一致性。这种增量同步能力对于后续基于运行态事实生成网络策略尤为关键。

在具体实现中，本文通过为不同类型的 Kubernetes 资源分别维护独立的 Watch 通道，并结合资源版本号（ResourceVersion）进行一致性校验，从而在网络波动或探针重启等异常情况下，避免资源状态丢失或重复处理的问题。通过上述机制，系统能够在复杂运行环境下稳定、持续地获取 Kubernetes 资源变化信息。



\subsubsection{关键资源对象与采集维度}


在完成资源同步机制设计的基础上，本文进一步明确了 Kubernetes 资源采集的对象范围与具体维度，以确保后续分析阶段具备充分且必要的上下文信息。针对零信任网络策略生成的需求，如表\ref{tab:k8s_resource_mapping}，本文重点关注以下几类资源对象及其属性。

对于 Pod 资源，采集内容包括其所属 Namespace、Label 集合、节点调度信息以及容器规格等元数据。这些信息用于刻画服务实例的运行位置与逻辑身份，为后续 Pod 级访问控制策略的生成提供基础依据。特别地，Label 信息在 Kubernetes 中承担着逻辑分组与身份标识的双重角色，是实现细粒度策略匹配的重要锚点。

对于 Service 资源，系统重点采集其 Selector 定义、端口映射关系以及服务类型等属性，并同步引入对 Endpoint 资源的实时监听机制。通过解析 Selector 与 Pod Label 之间的静态对应关系，并结合 Endpoint 对象中实时更新的后端 Pod IP 列表，系统建立起逻辑服务到具体实例集合的动态映射模型。这种机制不仅明确了服务级与实例级的通信边界，更确保了当应用发生扩缩容或节点漂移时，系统能够即时感知后端具体地址的变化，从而消除静态策略与动态环境之间的滞后性。

此外，Namespace 作为 Kubernetes 原生的隔离单元，其名称与关联策略信息同样被纳入采集范围。通过综合 Namespace 与 Label 两个维度，系统能够在保持策略表达灵活性的同时，避免因过度细化而导致的策略碎片化问题。

通过对上述关键资源对象及其多维属性的系统化采集，运行时数据采集模块,如图\ref{fig:k8s_resource_mapping_final_v2}，为后续的静态分析结果校验、访问意图推理以及零信任网络策略的正向生成奠定了统一且可靠的基础。


\begin{table}[htbp]
  \centering
  \caption{Kubernetes 核心资源对象与策略生成维度的映射关系}
  \label{tab:k8s_resource_mapping}
  \resizebox{0.95\textwidth}{!}{
    \begin{tabular}{llp{5cm}l}
    \toprule
    \textbf{资源对象} & \textbf{关键字段 } & \textbf{语义映射 } & \textbf{策略生成用途} \\
    \midrule
    \multirow{2}{*}{Pod} & \texttt{metadata.labels} & 工作负载身份标识  & \texttt{podSelector} \\
                         & \texttt{spec.nodeName} & 物理拓扑位置 & 辅助故障域分析 \\
    \midrule
    Service & \texttt{spec.selector} & 逻辑服务分组 & 确定流量目标 \\
            & \texttt{spec.clusterIP} & 虚拟网络入口 & VIP 地址解析 \\
    \midrule
    EndpointSlice & \texttt{endpoints.addresses} & 实际后端 IP 列表 & 解析无头服务 (Headless) \\
    \midrule
    ConfigMap & \texttt{data} (Key-Value) & 应用配置上下文 & 提取数据库/中间件地址 \\
    \bottomrule
    \end{tabular}
  }
\end{table}

所有采集到的资源数据被封装为统一的 JSON 结构，并附带采集时间戳与集群标识（Cluster ID），通过消息队列异步推送至后端分析引擎，为构建全集群的服务依赖拓扑图提供元数据支撑。

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[
      font=\sffamily\small,
      >=Stealth,
      % 锁定方框尺寸，增强视觉紧凑感
      basic box/.style={
          draw=gray!50,
          rectangle,
          rounded corners=3pt,
          minimum width=3.4cm, 
          minimum height=1.0cm,
          align=center,
          fill=white,
          drop shadow={opacity=0.1, shadow xshift=1pt, shadow yshift=-1pt},
          inner sep=3pt,
          line width=0.7pt
      },
      resource box/.style={basic box, draw=blue!40, fill=blue!5},
      attr box/.style={basic box, draw=orange!40, fill=orange!5, minimum width=3.8cm},
      goal box/.style={basic box, draw=violet!40, fill=violet!5},
      % 连线样式优化
      line/.style={->, draw=gray!60, thick, rounded corners=2pt},
      label font/.style={font=\scriptsize\bfseries, text=gray!80}
  ]

  % --- 第一列：3.1.1 核心资源采集 (Namespace与Pod相邻，消除交叉) ---
  \node[resource box] (ns) at (0, 0) {\textbf{Namespace} \\ \scriptsize (隔离边界)};
  \node[resource box] (pod) at (0, -1.5) {\textbf{Pod} \\ \scriptsize (核心负载)};
  \node[resource box] (svc) at (0, -3.0) {\textbf{Service} \\ \scriptsize (寻址与发现)};
  \node[resource box] (config) at (0, -4.5) {\textbf{ConfigMap} \\ \scriptsize (配置上下文)};

  % --- 第二列：特征维度映射 (拉开水平距离，为右侧文字留出极大空间) ---
  \node[attr box] (dim_id) at (6.0, -0.75) {\textbf{身份标识维度} \\ \scriptsize 标签 / IP / 节点名};
  \node[attr box] (dim_net) at (6.0, -2.25) {\textbf{网络语义维度} \\ \scriptsize 选择器 / ClusterIP};
  \node[attr box] (dim_cfg) at (6.0, -3.75) {\textbf{应用配置维度} \\ \scriptsize 环境变量 / 连接串};

  % --- 第三列：策略合成目标 (水平位置移至11.5cm，彻底解决重叠) ---
  \node[goal box] (policy) at (11.5, -2.25) {\textbf{策略生成依据} \\ \scriptsize JSON数据};

  % --- 连线逻辑 (左侧无交叉平行连线) ---
  \draw[line] (ns.east) -- ++(0.8,0) |- (dim_id.west);
  \draw[line] (pod.east) -- ++(0.8,0) |- (dim_id.west);
  \draw[line] (svc.east) -- ++(0.8,0) |- (dim_net.west);
  \draw[line] (config.east) -- ++(0.8,0) |- (dim_cfg.west);

  % --- 右侧汇总标注 (空间错位排布，彻底消除重叠) ---
  
  % 上路：标识维度到策略 (文字位于折线平直段上方)
  \draw[line] (dim_id.east) -- ++(1.5,0) |- ([yshift=0.35cm]policy.west);
  \node[label font, anchor=south west] at (7.8, -0.75) {确定负载标识};

  % 中路：网络维度到策略 (文字位于直线中段上方)
  \draw[line] (dim_net.east) -- (policy.west);
  \node[label font, anchor=south, yshift=2pt] at (8.75, -2.25) {定义访问路径};

  % 下路：配置维度到策略 (文字位于折线起始段下方)
  \draw[line] (dim_cfg.east) -- ++(1.5,0) |- ([yshift=-0.35cm]policy.west);
  \node[label font, anchor=north west] at (7.8, -3.75) {解析隐式依赖};

  % --- 背景装饰 (灰字置于外部) ---
  \begin{scope}[on background layer]
    \node[draw=blue!10, dashed, fill=blue!2, rounded corners=8pt, 
          fit=(ns) (config), inner sep=12pt] (bg1) {};
    % \node[anchor=south, font=\scriptsize\bfseries, text=blue!30, yshift=6pt] at (bg1.north) {资源采集};

    \node[draw=orange!10, dashed, fill=orange!2, rounded corners=8pt, 
          fit=(dim_id) (dim_cfg), inner sep=12pt] (bg2) {};
    % \node[anchor=south, font=\scriptsize\bfseries, text=orange!30, yshift=6pt] at (bg2.north) {特征映射};
  \end{scope}

  \end{tikzpicture}
  \caption{Kubernetes 关键资源对象与策略采集维度映射示意图}
  \label{fig:k8s_resource_mapping_final_v2}
\end{figure}


\subsection{容器资源}
\label{subsec:container_resource_collection}



容器作为微服务代码的运行时载体，其文件系统中往往冗余了大量与核心业务无关的基础设施组件（如 Shell 工具、包管理器、调试工具等）。若直接对静态镜像进行全量分析，不仅会引入巨大的计算开销，更会导致微隔离策略生成算法产生大量误报（例如误将调试工具的网络行为纳入业务白名单）。

借鉴基于运行时分析的沙箱挖掘思想~\cite{Ghavamnia2020ConfineAS}，本系统设计了一套“活跃资产锁定（Active Artifact Locking）”机制。该机制通过深度交互容器运行时接口（CRI）与 Linux 内核数据结构，精准识别并提取“积极参与业务逻辑”的进程与文件，从而收敛分析边界。

\subsubsection{基于 CRI 的容器定位与元数据映射}
在 Kubernetes 体系中，容器的具体运行状态由底层容器运行时负责管理，而 Kubernetes 本身并不直接维护容器级别的详细信息。为实现对不同运行时实现的统一适配，Kubernetes 提供了容器运行时接口（Container Runtime Interface，CRI），用于规范编排系统与容器运行时之间的交互方式。

本文基于 CRI 接口实现对容器实例的统一定位与管理。通过 CRI 提供的接口，系统能够获取集群中运行容器的唯一标识、所属 Pod 信息以及对应的运行时元数据，从而建立 Kubernetes 资源对象与具体容器实例之间的映射关系。该映射关系是后续从容器层面提取运行态信息的基础。

在具体实现中，采集模块通过关联 Pod UID、容器名称与运行时返回的容器 ID，实现对容器实例的精确定位。同时，为应对集群中可能存在的多种容器运行时实现（如 containerd、CRI-O 等），系统通过 CRI 抽象接口屏蔽底层差异，确保采集逻辑在不同运行环境下具有一致性与可移植性。

通过上述机制，系统能够在不依赖特定运行时实现细节的前提下，稳定获取容器级运行态信息，为后续的配置解析与应用制品提取奠定基础。


\subsubsection{基于内存映射的活跃二进制集构建}

\begin{figure}[htbp]
    \centering
    % 使用 resizebox 自动缩放图片以适应当前行宽
    % 这样无论你画得有多宽，它都会自动缩放到页面宽度
    \resizebox{1.0\linewidth}{!}{
        \begin{tikzpicture}[
            font=\sffamily\small,
            >=Stealth,
            % --- 样式定义 ---
            % 1. 基础文件节点
            file node/.style={
                rectangle,
                draw=gray!40,
                minimum width=3.0cm,  % 稍微加宽
                minimum height=0.7cm,
                align=center,
                font=\footnotesize,
                inner sep=3pt,
                rounded corners=3pt
            },
            % 2. 活跃/休眠样式
            active file/.style={file node, draw=blue!50, fill=blue!10, text=blue!60!black, font=\footnotesize\bfseries},
            dormant file/.style={file node, draw=gray!30, fill=gray!5, text=gray!50, dashed},
            % 3. 背景容器框 (关键：inner sep 调大一点，避免贴边)
            container box/.style={
                draw=gray!50,
                fill=white,
                rounded corners=8pt,
                inner sep=12pt, 
                drop shadow={opacity=0.15, shadow xshift=3pt, shadow yshift=-3pt}
            },
            % 4. 内存条目 (这是最宽的部分)
            map entry/.style={
                rectangle,
                draw=orange!40,
                fill=orange!5,
                minimum width=5.5cm, % 给足宽度
                minimum height=0.7cm,
                font=\scriptsize\ttfamily,
                align=left,
                anchor=west,
                inner sep=5pt
            },
            % 5. 连线
            link line/.style={->, draw=blue!50, line width=1.2pt, rounded corners=5pt},
            filter line/.style={->, draw=gray!30, dashed, line width=0.8pt}
        ]

        % =============================================
        % 布局策略：拉大 X 轴间距
        % 第一列中心 x=0
        % 第二列中心 x=7.5 (之前是6) -> 避免中间撞左边
        % 第三列中心 x=15.0 (之前是11.5) -> 避免右边撞中间
        % =============================================

        % === 1. 左侧：容器镜像存储层 (x=0) ===
        \node[font=\bfseries\large] (fs_title) at (0, 5.2) {容器镜像层 (Storage)};
        \node[font=\footnotesize, text=gray] at (0, 4.7) {含冗余依赖与工具};

        \node[active file] (jar1) at (0, 3.6) {order-service.jar};
        \node[dormant file] (tool1) at (0, 2.6) {curl / busybox};
        \node[active file] (lib1) at (0, 1.6) {mysql-driver.jar};
        \node[dormant file] (jar2) at (0, 0.6) {unused-lib.jar};
        \node[dormant file] (tool2) at (0, -0.4) {debug-agent.jar};

        % 左侧背景
        \begin{scope}[on background layer]
            \node[container box, fit=(fs_title) (tool2)] (fs_box) {};
        \end{scope}

        % === 2. 中间：内核内存映射层 (x=7.5) ===
        \node[font=\bfseries\large] (mem_title) at (7.5, 5.2) {进程虚拟内存 (/proc/maps)};
        \node[font=\footnotesize, text=gray] at (7.5, 4.7) {仅包含被加载的段 (VMA)};

        % 注意：这里 x 坐标设为 5.0，因为 map entry 是 anchor=west (左对齐)
        % 这样文字会向右延伸，占据 5.0 到 10.0 的空间
        \node[map entry] (vma1) at (5.0, 3.6) {7f..00 r-xp ... /app/order-service.jar};
        \node[map entry, draw=gray!30, fill=gray!2, text=gray] (vma_heap) at (5.0, 2.6) {[heap] (Anon Memory)};
        \node[map entry] (vma2) at (5.0, 1.6) {7f..a0 r--p ... /lib/mysql-driver.jar};

        % 中间背景 (fit 包含标题和最宽的条目)
        \begin{scope}[on background layer]
            \node[container box, fit=(mem_title) (vma1) (vma2)] (mem_box) {};
        \end{scope}

        % === 3. 右侧：最终提取结果 (x=15.0) ===
        \node[font=\bfseries\large] (out_title) at (15.0, 5.2) {活跃资产列表 (Active Set)};
        \node[font=\footnotesize, text=gray] at (15.0, 4.7) {用于后续静态分析};

        \node[active file] (res1) at (15.0, 3.6) {order-service.jar};
        \node[active file] (res2) at (15.0, 1.6) {mysql-driver.jar};

        % 右侧背景
        \begin{scope}[on background layer]
            \node[container box, fit=(out_title) (res2) (res1)] (out_box) {};
        \end{scope}

        % === 4. 连线 (优化路径) ===
        % 活跃路径 (蓝色实线)
        \draw[link line] (jar1.east) -- (vma1.west);
        \draw[link line] (lib1.east) -- (vma2.west);
        \draw[link line] (vma1.east) -- (res1.west);
        \draw[link line] (vma2.east) -- (res2.west);

        % 过滤路径 (灰色虚线) - 增加节点文字说明
        \draw[filter line] (tool1.east) -- ++(1.5,0) node[right, font=\tiny, text=gray, inner sep=1pt] {Not Loaded};
        \draw[filter line] (jar2.east) -- ++(1.5,0) node[right, font=\tiny, text=gray, inner sep=1pt] {Not Loaded};
        \draw[filter line] (tool2.east) -- ++(1.5,0) node[right, font=\tiny, text=gray, inner sep=1pt] {Not Loaded};

        % === 5. 底部核心机制说明 ===
        % 宽度设为 14cm，居中放置
        % \node[draw=orange!50, fill=orange!5, rounded corners=5pt, text width=14cm, align=center, font=\small, inner sep=8pt]
        %     at (7.5, -2.2) {
        %     \textbf{核心机制：} 采集探针通过读取 \texttt{/proc/[PID]/maps}，利用内核的写时复制（CoW）特性，\\
        %     精准识别当前 JVM 进程实际持有的文件描述符（FD），自动过滤未使用的僵尸依赖。
        % };

        \end{tikzpicture}
    }
    \caption{基于内核内存映射的容器活跃资产锁定与提取原理}
    \label{fig:active_artifact_locking}
\end{figure}


为了剔除镜像中“存在但未运行”的僵尸文件，如图\ref{fig:active_artifact_locking}，本系统利用 Linux 内核的内存管理机制来识别当前活跃的业务代码。具体而言，采集器通过 setns系统调用进入目标容器的 PID Namespace，读取目标进程的 /proc/<PID>/maps 内存映射文件。

该文件记录了进程虚拟地址空间中加载的所有可执行文件与动态链接库（Shared Libraries）。系统通过解析这些内存段，构建出当前容器的“活跃二进制集（Active Binary Set）”：
\begin{enumerate}
    \item 主执行体定位：识别映射具有 r-xp（可读可执行）权限且路径指向文件系统的主程序，过滤掉由 entrypoint.sh 或 tini 启动的父进程包装器；
    \item 解释器透视：对于 Java 应用，系统识别出 JVM 进程（如 java 二进制文件），并进一步扫描其打开的文件描述符（/proc/<PID>/fd），从而精准定位到被加载到内存中的 JAR 包或类文件，而非扫描整个 /app 目录；
\end{enumerate}

这种基于运行时内存视图的采集方法，能够从根本上排除“镜像内打包了curl但业务从未调用”带来的策略噪声，确保后续分析仅聚焦于真实的业务实体。

\subsubsection{配置上下文与分层文件系统解析}

除应用代码本身外，运行期配置同样对服务行为与通信方式产生重要影响。环境变量、配置文件以及启动参数等信息，往往决定了服务对外暴露的端口、依赖的外部服务地址以及启用的功能模块。因此，在生成零信任网络策略时，有必要对容器的配置上下文进行系统化采集与解析。

本文结合容器分层文件系统的特性，对运行期配置进行有针对性的解析。采集器通过以只读方式访问读容器进程的 /proc/<PID>/environ 文件，无侵入地提取全量环境变量键值对。同时，针对容器镜像采用的联合文件系统（UnionFS, 如 OverlayFS），系统解析 /proc/mounts信息，区分 LowerDir（只读镜像层）与UpperDir （读写容器层）。这使得分析引擎能够优先处理运行时产生的文件修改（Copy-on-Write），不仅还原了应用启动时的完整配置上下文，也确保了对热更新（Hot-Swap）代码的实时感知~\cite{oci2023runtime}。

通过将配置上下文与前述活跃二进制集进行关联，系统能够在后续分析阶段更准确地理解代码行为与运行环境之间的关系，为策略生成提供更加完整的上下文支撑。


\subsection{Java 字节码制品提取}
\label{subsec:bytecode_extraction}

在微服务架构中，服务间通信关系最终体现在应用代码的实际执行路径之中。相较于源码级分析，直接面向运行环境中加载的 Java 字节码制品进行分析，能够有效规避源码缺失、版本不一致以及构建环境差异等问题。因此，本文选择以运行态 Java 字节码制品作为静态分析阶段的主要输入。

需要注意的是，在容器化部署场景下，镜像中包含的字节码文件并不一定全部参与实际运行。一方面，部分依赖可能因配置条件限制而未被加载；另一方面，应用在运行过程中可能通过插件机制或动态加载方式引入额外制品。若不加区分地对文件系统进行全量提取，容易引入大量与实际执行和服务调用无关的分析对象，进而影响后续调用关系与通信语义建模的准确性。

基于上述考虑，本文从运行态视角出发，设计了一套面向 Java 应用的字节码制品提取方法，重点关注“实际被加载，参与执行，服务调用相关”的代码集合，为后续静态分析提供精简且可信的输入。


\subsubsection{基于内存映射的活跃依赖识别}

在 Java 应用运行过程中，JVM 的类加载机制（ClassLoader）决定了并非所有 ClassPath 下的 JAR 包都会被加载，而是会根据程序执行路径按需加载类定义，并将对应的字节码映射至进程地址空间。由此，进程的内存映射信息在一定程度上反映了当前运行状态下实际生效的代码依赖关系。采集器利用 Linux 内核提供的进程文件系统（procfs）进行透视。通过分析容器内 Java 进程的内存映射结果，识别运行阶段被加载的 JAR 文件与类路径。相较于仅依据镜像内容或构建配置文件进行推断，该方法能够更直接地反映应用在当前实例中的真实依赖集合。

具体而言，采集器通过读取容器内 Java 主进程的 /proc/<PID>/maps 内存映射文件，筛选出所有映射路径以 .jar 结尾的内存段，剔除与 Java 应用执行无关的系统库与运行时组件。该文件记录了进程虚拟地址空间中所有动态加载的文件描述符。与静态扫描磁盘相比，这种方法的优势在于：
\begin{enumerate}
    \item 排除冗余：能自动忽略存在于磁盘但未被 JVM 加载的“僵尸依赖”（例如未启用的数据库驱动或测试框架）；
    \item 解析动态路径：能够识别被自定义 ClassLoader 动态加载到非标准路径下的 JAR 文件；
    \item 处理软链接：通过解析文件描述符的真实路径（Real Path），自动处理符号链接导致的路径混淆~\cite{Ghavamnia2020ConfineAS}。
\end{enumerate}



\subsubsection{无侵入式流式传输通道}
为了将锁定的活跃 JAR 包提取至后端分析引擎，系统设计了基于 Kubernetes API 的流式传输通道。采集器不依赖 \texttt{docker cp} 等宿主机特权命令，而是与 API Server 建立 HTTP/2 长连接。


通过调用 SKBN，采集器在目标容器内执行轻量级的拷贝命令，将筛选出的活跃 JAR 文件列表打包为二进制流，并通过标准输出（Stdout）管道实时传输。该过程采用了“零落地（Fileless）”策略，数据流直接在内存中转发，避免了在业务容器内创建临时文件，从而消除了对业务磁盘 I/O 的干扰及潜在的残留风险~\cite{kerrisk2010linux}。该方式在控制单次资源占用的同时，降低了对容器 I/O 与内存的瞬时压力。


通过将制品提取与传输过程解耦，系统能够在不影响业务请求处理的前提下，完成字节码数据的采集，为后续分析阶段提供稳定输入。


\subsubsection{增量指纹比对与传输优化}
在微服务集群中，容器实例可能因滚动更新或弹性伸缩而频繁创建和销毁，同一服务的多个副本（Replicas）共享完全相同的代码层，且不同服务之间往往存在公共的基础架构组件（如 Spring Cloud 全家桶）。若在每次实例启动后均对全部字节码制品进行完整传输，将带来不必要的网络与存储开销。为此，本文在字节码制品传输阶段引入增量指纹比对机制，以减少重复数据的传输。

具体而言，系统引入了基于 SHA-256 的增量指纹比对机制。在传输前，采集器在容器内计算目标文件的哈希摘要（Digest），并利用布隆过滤器（Bloom Filter）快速判断该哈希值是否已存在于分析引擎的制品库中。仅当检测到全新的哈希值（对应版本更新或新引入的依赖）时，才触发实际的数据传输。


该增量优化机制在不影响分析准确性的前提下，有效降低了数据传输规模，使字节码制品提取过程能够更好地适应云原生环境中实例频繁变动的运行特征。



\subsection{注册中心配置}
\label{subsec:registry_collection}

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[
      scale=0.95, 
      >=Stealth,
      % --- 样式定义 ---
      % 基础圆角框
      basic box/.style={
          rectangle,
          draw=gray!50,
          rounded corners=3pt,
          align=center,
          line width=0.8pt,
          inner sep=6pt,
          fill=white
      },
      % 1. 异构源 (顶层)
      source box/.style={
          basic box,
          draw=violet!50,
          fill=violet!5,
          text width=5.0cm,
          minimum height=1.4cm
      },
      % 2. 适配器模块 (中间层)
      adapter box/.style={
          basic box,
          draw=blue!50,
          fill=white,
          text width=5.0cm,
          minimum height=1.6cm % 适当高度
      },
      % 3. 结果映射表 (底层)
      map box/.style={
          basic box,
          draw=green!50!black,
          fill=green!5,
          text width=10.0cm,
          minimum height=1.4cm
      },
      % 连线
      line/.style={->, draw=gray!60, thick, rounded corners=3pt}
  ]

  % === 1. 绘制背景区域 (暴力扩大坐标范围) ===
  % 之前是 y=2.2 到 -0.8 (太小)，现在改为 y=2.8 到 -1.5 (足够大)
  % x 范围保持 -6.2 到 6.2
  \fill[blue!2] (-6.2, 2.8) rectangle (6.2, -1.5);
  \draw[blue!30, dashed, rounded corners=6pt, line width=1pt] (-6.2, 2.8) rectangle (6.2, -1.5);
  
  % 背景标题 (放在框内顶部，y=2.3)
  \node[font=\bfseries\small, text=blue!60!black] at (0, 2.3) {统一采集适配器 (Collector Adapter)};

  % === 2. 放置节点 ===
  
  % 第一排：异构注册中心 (位置上移到 y=4.5，避开大背景框)
  \node[source box] (nacos) at (-3.2, 4.5) {
      \textbf{\small Nacos 集群} \\[3pt]
      \footnotesize (gRPC / UDP 推送流)
  };

  \node[source box] (eureka) at (3.2, 4.5) {
      \textbf{\small Eureka / Consul} \\[3pt]
      \footnotesize (HTTP 长轮询机制)
  };

  % 第二排：适配处理模块 (位置 y=0.5，处于背景框正中)
  \node[adapter box] (push) at (-3.2, 0.5) {
      \textbf{\small 事件监听模块} \\[3pt]
      \footnotesize 订阅 ServiceChange 事件 \\
      \footnotesize 实时增量更新
  };

  \node[adapter box] (poll) at (3.2, 0.5) {
      \textbf{\small 轮询调度模块} \\[3pt]
      \footnotesize 自适应间隔 (Adaptive) \\
      \footnotesize 全量比对 (Diff)
  };

  % 第三排：输出结果 (位置下移到 y=-3.2，避开大背景框)
  \node[map box] (result) at (0, -3.2) {
      \textbf{\small 全局服务寻址映射表 (Addressing Map)} \\[3pt]
      \footnotesize \texttt{Map<ServiceName, List<Instance>>}
  };

  % === 3. 连线 (垂直与汇聚) ===
  
  % 上 -> 中
  \draw[line] (nacos.south) -- (push.north);
  \draw[line] (eureka.south) -- (poll.north);

  % 中 -> 下 (直角汇聚)
  % 左路：从底部出来 -> 向下 -> 向右 -> 连入
  \draw[line] (push.south) -- (-3.2, -1.8) -| ([xshift=-2cm]result.north);
  
  % 右路：从底部出来 -> 向下 -> 向左 -> 连入
  \draw[line] (poll.south) -- (3.2, -1.8) -| ([xshift=2cm]result.north);

  \end{tikzpicture}
  \caption{异构注册中心数据的统一采集与映射机制}
  \label{fig:registry_adapter_fixed}
\end{figure}


在基于微服务的云原生系统中，服务实例的网络可达性有时并非通过静态配置直接确定，而是由注册中心在运行期间动态维护。应用在启动或状态变更时，可以将自身实例信息注册至注册中心；调用方则通过逻辑服务名完成服务发现。由此，注册中心成为连接应用代码与实际网络通信路径的重要中介，其配置状态直接影响服务之间的可达关系。

如果仅依据 Kubernetes 层面的 Service 或 Pod 信息进行分析，往往难以准确刻画逻辑服务名与真实网络地址之间的映射关系，尤其是在多注册中心并存或注册信息频繁变更的场景下。静态代码分析虽然能够提取出微服务间的逻辑调用关系（例如代码中硬编码的 "http://payment-service/pay"），但无法直接推导出 Kubernetes NetworkPolicy 所需的确切网络五元组（IP Block 或 Pod Selector）。为了建立“逻辑服务标识”与“物理网络实体”之间的映射视图，如图\ref{fig:registry_adapter_fixed},本系统设计了针对服务注册中心（Service Registry）的实时采集模块~\cite{Jamshidi2018MicroservicesTJ}，以弥补编排层信息在服务发现语义上的不足。


\subsubsection{异构注册中心适配器设计}


在实际工程环境中，微服务系统可能同时采用多种注册中心实现，例如 Nacos、Eureka 或基于自研组件的服务发现机制。不同注册中心在接口形式、数据模型以及一致性语义等方面均存在差异，若针对每一种实现单独设计采集逻辑，将显著增加系统复杂度与维护成本。

因此，采集器采用了适配器模式（Adapter Pattern）构建统一的接入层，适配器对外提供一致的数据访问模型，对内负责将具体注册中心返回的信息转换为标准化表示。该层屏蔽了底层异构协议（如 Nacos 的 gRPC/UDP 推送、Eureka 的 HTTP 长轮询）的差异，向上层分析引擎提供标准化的 ServiceInstance模型。在适配器实现过程中，系统重点关注服务实例的逻辑服务名、实例地址、端口信息以及健康状态等关键字段。这些字段直接决定了服务发现的结果，也是后续解析服务间实际通信路径所需的核心输入。

系统目前已内置支持云原生领域主流的服务发现协议：
\begin{itemize}
    \item Nacos：作为阿里巴巴开源的云原生服务发现平台，Nacos 支持基于 UDP 的服务变更推送。采集器通过模拟 Nacos Client 行为，订阅指定命名空间下的服务列表变更事件，能够实现毫秒级的实例上下线感知。
    \item Eureka/Consul：针对基于 HTTP 的注册中心，采集器实现了自适应轮询机制（Adaptive Polling）。通过分析服务变动的历史频率，动态调整拉取间隔（例如在发布窗口期加密轮询，在稳定期降低频率），在保证数据新鲜度的同时降低控制面负载~\cite{richardson2018microservices}。
\end{itemize}

\subsubsection{逻辑服务名到物理地址的动态映射}

在注册中心机制下，服务调用通常以逻辑服务名作为入口，具体请求在运行时被路由至一个或多个实际服务实例。因此，从零信任网络策略的角度来看，仅限制逻辑层面的服务访问并不足以形成可执行的网络控制规则，还需要进一步解析其对应的物理网络地址范围。

本文通过对注册中心中维护的实例信息进行解析，构建逻辑服务名与物理地址之间的动态映射关系。该映射关系能够随着服务实例的注册、下线或状态变更而实时更新，从而反映集群运行阶段的真实通信可能性。

采集器将从各注册中心获取的数据聚合为一张全局的“服务寻址映射表（Service Addressing Map）”。该表维护了 Service Name$\rightarrow$ List<Instance Address, Port, Metadata>的实时对应关系，其中Address既可以表现为IP 地址，也可以表现为Pod Selector。

在后续的策略生成阶段，该映射表发挥着关键的“桥梁”作用：例如当静态分析引擎识别到 Java 代码中发起对 user-service的 OpenFeign 调用时，系统查询该表即可锁定目标服务在当前集群中所有活跃实例的地址集合。



\section{字节码静态分析}
\label{sec:static_analysis}




在完成运行时数据采集后，系统已经获得了与实际部署环境高度一致的应用制品集合。然而，仅依赖运行态信息仍不足以全面刻画服务之间的潜在通信关系。一方面，部分调用路径可能因条件分支或配置差异在当前运行实例中尚未触发；另一方面，零信任网络策略的生成需要对“可能发生的访问行为”进行约束，而不仅限于已观测到的通信事实。

基于上述考虑，本文引入字节码层面的静态分析方法，对 Java 应用的调用结构与通信语义进行系统建模。相较于源码分析，字节码分析不依赖于源码可得性，且能够直接反映编译后的真实执行逻辑，更适用于云原生环境中多版本、多构建产物并存的实际情况。


静态分析模块以 3.1 节提取的活跃字节码制品为输入，围绕方法调用关系、控制流与数据流传播等关键要素展开分析，旨在从代码层面还原服务对外通信的潜在意图，为后续的合规性审计与策略正向生成提供结构化依据。然而，在实际工程环境中，微服务应用通常会引入数量庞大的第三方依赖库，其规模往往远超业务逻辑代码本身。若直接对全量字节码构建调用关系，不仅会带来显著的计算开销，还容易引入大量与业务语义无关的调用路径，例如日志框架或通用工具库内部的网络行为，从而干扰后续依赖关系的判定。除了第三方依赖库，在剩下的业务 JAR 包中，仍然存在大量不直接参与远程调用的类，例如仅用于数据封装的 POJO、通用工具类或配置类。这类代码虽然在程序运行中不可或缺，但其本身并不承载服务间通信语义。

为此，本节设计了一个“三级过滤漏斗”模型，依次执行第三方，非业务类剔除、自定义类过滤及核心调用链提取，确保静态分析仅聚焦于能够产生服务间交互的关键代码片段。

\subsection{第三方依赖包过滤}
\label{subsec:dep_filtering}

在实际微服务应用中，业务代码通常依赖大量第三方库以实现基础功能支持，例如日志记录、序列化、配置管理及网络通信封装等。从零信任网络策略生成的角度来看，第三方依赖几乎不具备分析价值。多数通用依赖库内部虽可能包含网络相关实现，但其行为通常由业务代码间接触发，且不直接反映服务间的逻辑依赖关系。因此，本文在字节码静态分析阶段引入第三方依赖包过滤机制，将分析重点聚焦于更可能承载业务通信语义的代码范围。


为了解决第三方库带来的 Java 应用普遍存在的代码膨胀（Bloatware）问题，系统首先在 JAR 包粒度进行粗筛。该过程基于软件成分分析（SCA）思想，构建了一个包含 Maven Central 主流组件的“指纹黑名单库”~\cite{soto2021bloat}。

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[
      scale=0.95, 
      >=Stealth,
      font=\small, % 保持统一的罗马字体
      % --- 样式定义 ---
      % 基础框
      basic box/.style={
          rectangle,
          draw=gray!50,
          rounded corners=3pt,
          align=center,
          line width=0.8pt,
          inner sep=6pt,
          fill=white
      },
      % 1. 输入 (紫色)
      input box/.style={
          basic box,
          draw=violet!50,
          fill=violet!5,
          text width=5.0cm,
          minimum height=1.2cm
      },
      % 2. 处理步骤 (蓝色)
      process box/.style={
          basic box,
          draw=blue!50,
          fill=white,
          text width=4.5cm,
          minimum height=1.0cm
      },
      % 3. 判定菱形 (橙色)
      decision box/.style={
          diamond,
          draw=orange!50,
          fill=orange!5,
          text width=2.5cm,
          align=center,
          aspect=2.5, % 拉宽菱形
          inner sep=1pt,
          font=\footnotesize
      },
      % 4. 废弃桶 (灰色虚线)
      discard box/.style={
          basic box,
          draw=gray!40,
          fill=gray!5,
          dashed,
          text width=4.0cm,
          minimum height=3.0cm
      },
      % 5. 输出结果 (绿色)
      output box/.style={
          basic box,
          draw=green!50!black,
          fill=green!5,
          text width=5.0cm,
          minimum height=1.2cm
      },
      % 连线
      line/.style={->, draw=gray!60, thick, rounded corners=3pt},
      label font/.style={font=\scriptsize, text=gray!60, fill=white, inner sep=2pt}
  ]

    % === 节点布局 ===

    % 1. 顶部输入
    \node[input box] (start) at (0, 0) {
        \textbf{原始 JAR 包集合} \\[3pt]
        \footnotesize (全量 Classpath 依赖)
    };

    % 2. 第一层：指纹过滤
    \node[process box] (step1) at (0, -1.8) {
        \textbf{Step 1: SCA 指纹计算} \\
        \footnotesize (SHA-256 Hash)
    };
    
    \node[decision box] (check1) at (0, -3.6) {
        命中指纹\\黑名单?
    };

    % 3. 第二层：启发式过滤
    \node[process box] (step2) at (0, -5.6) {
        \textbf{Step 2: 包名启发式扫描} \\
        \footnotesize (Package Name Prefix)
    };

    \node[decision box] (check2) at (0, -7.4) {
        命中非业务\\通用前缀?
    };

    % 4. 底部输出
    \node[output box] (final) at (0, -9.5) {
        \textbf{候选业务依赖集合} \\[3pt]
        \footnotesize (用于静态分析)
    };

    % 5. 右侧：废弃区 (垂直居中于两个判定之间)
    \node[discard box] (trash) at (5.5, -5.5) {
        \textbf{被剔除的基础设施依赖} \\[5pt]
        \scriptsize $\bullet$ Spring Boot Starters \\
        \scriptsize $\bullet$ Netty / Tomcat \\
        \scriptsize $\bullet$ Logging Frameworks \\
        \scriptsize $\bullet$ Common Utils (Apache)
    };

    % === 连线逻辑 ===

    % 垂直主流程
    \draw[line] (start) -- (step1);
    \draw[line] (step1) -- (check1);
    \draw[line] (check1) -- node[midway, right, label font] {否 (No)} (step2);
    \draw[line] (step2) -- (check2);
    \draw[line] (check2) -- node[midway, right, label font] {否 (No)} (final);

    % 废弃流程 (向右折线)
    % Check1 -> Trash (上部)
    \draw[line] (check1.east) -| (trash.north)
        node[pos=0.3, above, label font] {是 (Yes)};

    % Check2 -> Trash (下部)
    \draw[line] (check2.east) -| (trash.south)
        node[pos=0.3, above, label font] {是 (Yes)};

  \end{tikzpicture}
  \caption{基于指纹与启发式规则的第三方依赖过滤流程}
  \label{fig:dep_filtering}
\end{figure}

如图\ref{fig:dep_filtering}，具体算法流程如下：
\begin{enumerate}
    \item 指纹计算：对输入的 JAR 包计算 SHA-256 哈希值；
    \item 黑名单匹配：将哈希值与指纹库进行 $O(1)$ 匹配。指纹库预置了 Spring Boot Starter、Netty、Jackson 等基础设施组件的哈希特征。
    \item 包名启发式过滤：对于未命中的 JAR 包，进一步检查其包名（Package Name）。若包名匹配 org.apache.*、org.springframework.* 或 io.kubernetes.* 等标准前缀，且不包含特定业务关键词，则将其标记为非业务依赖进行剔除。
\end{enumerate}
通过该步骤，分析引擎能够过滤掉基础设施代码，显著降低了后续 Soot 分析的内存压力。

\subsection{自定义类的过滤}
\label{subsec:class_filtering}


在完成第三方依赖包过滤后，剩余待分析的字节码主要由业务自身定义的类构成。然而，即便在业务代码范围内，仍然存在大量不直接参与服务通信的类，例如数据传输对象、配置封装类以及通用工具类等。若对这类自定义类进行同等粒度的静态分析，同样会引入冗余调用路径，影响分析结果的清晰度。

针对上述问题，本文在静态分析流程中进一步引入自定义类的过滤策略，以在不牺牲通信语义完整性的前提下，减少无关类对分析过程的干扰。该策略并不依赖完整的控制流或数据流分析，而是基于字节码层面的轻量级特征进行快速判断，适用于分析初期的规模裁剪阶段。

具体而言，系统通过检查类的结构特征与常量池信息。系统仅保留满足以下特征之一的“活跃类”：
\begin{itemize}
    \item 入口特征：包含 @Controller、@RestController 或 @Scheduled 等注解的类，这通常是服务调用的起点；
    \item 出口特征：包含 @FeignClient、@DubboReference 等注解的接口或字段，这代表了明确的远程调用意图；
    \item 行为特征：常量池中包含 "http://"、"https://" 或常见服务名前缀字符串的类，提示可能存在编程式的网络请求。
\end{itemize}

需要指出的是，启发式过滤策略本身并不保证绝对精确，其设计目标在于以较低成本显著缩小分析范围。因此，本文在过滤过程中采取保守策略，即在无法明确判断类是否参与通信行为时，优先将其保留进入后续分析阶段，以避免因过度过滤而遗漏潜在通信路径。

通过引入自定义类的启发式过滤机制，系统在分析效率与语义覆盖之间取得了较为平衡的效果，为后续调用链构建与服务依赖关系推断提供了更加聚焦的分析输入。






\subsection{基于类的调用信息提取}
\label{subsec:invocation_extraction}

在完成第三方依赖包与自定义类的多级过滤后，字节码静态分析的对象范围已被显著收敛。此时，分析重点由“缩小分析规模”转向“提取有意义的调用关系”，以刻画业务代码中可能存在的服务间通信路径。考虑到方法级调用分析在复杂工程环境中易产生规模膨胀问题，本文选择以类为基本分析粒度，对调用信息进行抽象建模。

基于类的调用信息提取旨在识别不同类之间的调用依赖关系，而不深入展开类内部的具体方法实现细节。通过这种方式，系统能够在保持调用关系整体结构的同时，有效控制分析复杂度，避免在早期阶段引入过多细粒度信息。

在具体实现过程中，系统通过解析字节码中的方法调用指令，统计类之间的调用关系，并据此构建类级调用依赖集合。本节针对云原生环境中最常见的两种调用模式，设计了专用的提取器（Extractor）。

\subsubsection{声明式调用提取}
对于基于接口代理的声明式调用，分析引擎重点解析接口上的元数据注解。以 OpenFeign 为例，系统扫描所有带有 @FeignClient 注解的接口，提取 name 或 value 属性作为目标服务标识，提取 path 属性作为基础路径。同时，解析接口方法上的 @RequestMapping 注解，获取具体的 HTTP 动词与子路径。这些信息组合后，构成了确定的 <Caller, CalleeService, Path> 三元组。

\subsubsection{编程式调用提取}

\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[
        scale=0.9, 
        transform shape,
        font=\sffamily\small,
        >=Stealth,
        % --- 样式定义 ---
        % 1. 左侧代码框
        java box/.style={
            rectangle,
            draw=gray!40,
            fill=white,
            rounded corners=4pt,
            align=left,
            font=\ttfamily\scriptsize,
            inner sep=8pt,
            drop shadow={opacity=0.1, shadow xshift=2pt, shadow yshift=-2pt}
        },
        % 2. 右侧 Jimple 代码块 (普通)
        jimple normal/.style={
            rectangle,
            draw=none, 
            fill=white,
            align=left,
            font=\ttfamily\scriptsize,
            inner sep=4pt,
            text width=6.5cm
        },
        % 3. 右侧 Jimple 代码块 (高亮 - 污点)
        jimple taint/.style={
            rectangle,
            draw=red!60,      % 红边框
            fill=red!5,       % 浅红背景
            align=left,
            font=\ttfamily\scriptsize,
            inner sep=4pt,
            text width=6.5cm,
            rounded corners=2pt
        },
        % 4. 结果框
        result box/.style={
            rectangle,
            draw=blue!50,
            fill=blue!5,
            rounded corners=4pt,
            minimum width=12cm,
            minimum height=0.8cm,
            align=center,
            font=\footnotesize\bfseries,
            inner sep=6pt
        },
        % 5. 标题
        header label/.style={
            font=\bfseries\small,
            text=gray!70!black,
            anchor=south west,
            yshift=2pt
        }
    ]

    % ================== 1. 左侧：Java 源代码 ==================
    \node[header label] at (0, 4.2) {1. 原始 Java 源代码 (Source Code)};

    \node[java box, text width=5.5cm] (java) at (2.8, 2.0) {
        \textcolor{blue!60}{String} srv = \textcolor{green!40!black}{"http://inventory"};\\[4pt]
        \textcolor{blue!60}{String} path = \textcolor{green!40!black}{"/api/v1"};\\[4pt]
        \textcolor{gray}{// 字符串拼接}\\[0pt]
        \textcolor{blue!60}{String} url = srv + path;\\[4pt]
        \textcolor{gray}{// 网络调用 (Sink)}\\[0pt]
        \textcolor{violet}{restTemplate}.getForObject(url, ...);
    };

    % ================== 2. 右侧：Jimple 中间表示 (积木式拼接) ==================
    \node[header label] at (8, 4.2) {2. Soot Jimple 中间表示 (IR)};

    % 2.1 顶部：污点源 (Source) - 直接用红色样式
    \node[jimple taint] (j_source) at (11.5, 3.2) {
        \textcolor{gray}{// 1. 常量定义 (Source)}\\
        r1 = \textcolor{green!40!black}{"http://inventory"};
    };
    
    % 2.2 中间：传播过程 (Process) - 普通样式，接在 Source 下方
    \node[jimple normal, below=2pt of j_source] (j_process) {
        r2 = "/api/v1";\\
        r3 = new StringBuilder;\\
        specialinvoke r3.append(r1);\\
        specialinvoke r3.append(r2);\\
        r4 = virtualinvoke r3.toString();
    };

    % 2.3 底部：汇聚点 (Sink) - 直接用红色样式，接在 Process 下方
    \node[jimple taint, below=2pt of j_process] (j_sink) {
        \textcolor{gray}{// 3. 远程调用 (Sink)}\\
        virtualinvoke r0.get(r4, ...);
    };

    % 2.4 给右侧整体加一个灰色大框 (作为背景容器)
    \node[rectangle, draw=gray!30, rounded corners=4pt, fit=(j_source)(j_sink), inner sep=4pt] (right_container) {};

    % ================== 3. 绘制连接线与标注 ==================
    
    % 红色数据流箭头 (从 Source 连到 Process 再连到 Sink)
    % 使用 explicitly defined coordinates 以防万一
    \draw[->, red!60, line width=1.2pt, rounded corners] (j_source.west) -- ++(-0.4, 0) |- (j_process.west);
    \draw[->, red!60, line width=1.2pt, rounded corners] (j_process.west) -- ++(-0.4, 0) |- (j_sink.west);

    % 右侧文字标签
    \node[right=2pt of j_source, font=\tiny\bfseries, text=red!70] {Taint Source};
    \node[right=2pt of j_sink, font=\tiny\bfseries, text=red!70] {Taint Sink};

    % 中间转换箭头 (Java -> Jimple)
    \draw[->, very thick, gray!40, dashed] (java.east) -- node[above, font=\scriptsize, text=gray] {Soot 编译} (right_container.west);

    % ================== 4. 底部结果 ==================
    \node[result box] (result) at (7.2, -1.5) {
        提取结果 (Extracted Dependency): \quad 
        \textcolor{blue!80}{\{ Service: "inventory", Method: "GET", Path: "/api/v1" \}}
    };

    % 提取箭头
    \draw[->, thick, blue!50] (right_container.south) -- (result.north);

    \end{tikzpicture}
    \caption{静态污点分析与调用提取示例}
    \label{fig:taint_analysis_example}
\end{figure}

对于直接使用 HTTP 客户端的编程式调用,如图\ref{fig:taint_analysis_example}，系统采用基于 Jimple 的静态污点分析（Static Taint Analysis）技术。
\begin{enumerate}
    \item Source 识别：将 URL 字符串常量或配置项标记为污点源；
    \item Sink 识别：将 \texttt{RestTemplate.getForObject()} 等网络请求方法标记为污点汇聚点；
    \item 数据流追踪：利用 Soot 的 \texttt{SmartLocalDefs} 分析器，逆向追踪网络请求方法的 URL 参数定义点。如果 URL 是由字符串拼接而成（如 \texttt{"http://" + serviceName + "/api"}），系统通过常量传播分析尝试还原其静态部分，并将动态部分标记为需在运行时解析的变量~\cite{Arzt2014FlowDroidPC}。
\end{enumerate}
这一机制使得系统能够从非结构化的代码中还原出隐含的服务依赖关系。



\section{调用关系图构建}
\label{sec:call_graph_construction}

在完成类级调用信息提取后，静态分析阶段已经获得了一组离散的调用依赖关系。然而，这些依赖关系在形式上仍然是相互独立的调用对，尚不足以反映业务逻辑中更高层次的调用结构。为进一步刻画服务内部及服务之间可能存在的调用路径，有必要对上述调用信息进行系统化组织，构建统一的调用关系图。

调用关系图以类作为基本节点，以类之间的调用依赖作为有向边，用于描述程序中可能存在的调用传播路径。通过将离散的调用信息整合为图结构，系统能够从整体视角分析调用关系的连通性与层次性，为后续识别完整调用链提供基础支撑。相较于线性调用列表，图结构在表达复杂依赖关系时更具灵活性，也更适合进行后续的聚合与裁剪操作。

为了推导微服务间的全局依赖拓扑，本节提出了一种两阶段图构建算法：首先构建细粒度的类级调用图，以此为基础，结合微服务部署元数据，聚合生成粗粒度的微服务依赖图。

\subsection{基于类的调用关系图}
\label{subsec:class_call_graph}

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[
      font=\sffamily\small,
      >=Stealth,
      scale=0.85, transform shape,
      % 类节点样式
      class box/.style={
          draw=blue!40,
          rectangle,
          rounded corners=3pt,
          minimum width=3.5cm, 
          minimum height=1.1cm,
          align=center, 
          fill=blue!5,
          drop shadow={opacity=0.1, shadow xshift=1pt, shadow yshift=-1pt},
          inner sep=4pt,
          line width=0.7pt
      },
      % 标注文字样式
      label font/.style={font=\scriptsize\bfseries, text=red!70},
      trans font/.style={font=\scriptsize\bfseries, text=orange!80}
  ]

  % --- 节点布局 ---
  
  % 左侧：发起关联的类 (类 C)
  \node[class box] (classC1) at (0, 1.5) {\textbf{OrderController} \\ \scriptsize (类 C1: 成员变量持有)};
  \node[class box] (classC2) at (0, -1.5) {\textbf{SecurityAspect} \\ \scriptsize (类 C2: 切面增强)};
  
  % 中间：核心业务类 (类 A)
  \node[class box] (classA) at (6, 0) {\textbf{OrderService} \\ \scriptsize (类 A: 业务逻辑核心)};
  
  % 右侧：远程调用接口 (类 B)
  \node[class box] (classB) at (12, 0) {\textbf{InventoryClient} \\ \scriptsize (类 B: Feign 远程接口)};

  % --- 连线逻辑 (展示关联与传递) ---
  
  % 1. 类 C1 -> 类 A (Has-A)
  \draw[->, thick, gray!60] (classC1.east) -- ++(1,0) |- ([yshift=0.2cm]classA.west)
        node[pos=0.4, above, label font] {持有边 (Has-A)};

  % 2. 类 C2 -> 类 A (Advise-A)
  \draw[->, thick, gray!60] (classC2.east) -- ++(1,0) |- ([yshift=-0.2cm]classA.west)
        node[pos=0.4, below, label font] {增强边 (Advise-A)};

  % 3. 类 A -> 类 B (Call-A / Has-A)
  \draw[->, thick, gray!60] (classA.east) -- (classB.west) 
        node[midway, above, label font] {直接调用};

  % --- 意图传递路径 (Highlighting the Intent Transitivity) ---
  \draw[->, line width=1.5pt, orange!60, dashed] (classC1.north) .. controls (3, 3) and (9, 3) .. (classB.north)
        node[midway, above, trans font] {意图传递：C1 $\rightarrow$ A $\rightarrow$ B};
        
  \draw[->, line width=1.5pt, orange!60, dashed] (classC2.south) .. controls (3, -3) and (9, -3) .. (classB.south)
        node[midway, below, trans font] {意图传递：C2 $\rightarrow$ A $\rightarrow$ B};

  % --- 背景说明 ---
  \begin{scope}[on background layer]
    \node[draw=gray!20, dashed, fill=gray!2, rounded corners=8pt, 
          fit=(classC1) (classC2) (classA) (classB), inner sep=20pt] (bg) {};
    \node[anchor=south, font=\scriptsize\bfseries, text=gray!40] at (bg.north) {示例：基于类关联的远程调用意图传递分析};
  \end{scope}

  \end{tikzpicture}
  \caption{复杂场景下类级调用关系图的关联传递示例}
  \label{fig:class_transitivity_example}
\end{figure}

在 Spring Cloud 等现代微服务框架中，服务间的调用往往被封装在复杂的对象关系之中。为了还原这些隐式联系，分析引擎构建了一个有向图 $G_{class} = (V_c, E_c)$，其中节点 $V_c$ 代表业务类，边 $E_c$ 代表类与类之间的关联关系。

不同于传统仅基于函数调用的构图方法，本文针对云原生应用的开发范式，如图\ref{fig:class_transitivity_example},设计了以下三种特定类型的边生成规则，以解决依赖注入（DI）与面向切面编程（AOP）带来的断链问题：

\subsubsection{基于成员变量注入的关联边}
在 Spring 容器中，服务类通常通过 \texttt{@Autowired} 或 \texttt{@Resource} 注解将其他组件（如 \texttt{FeignClient} 接口）注入为成员变量。Soot 的类结构分析能力使得系统能够扫描所有字段定义。若类 $A$ 包含一个类型为 $B$ 的成员变量，且该变量带有注入注解，则建立一条 $A \rightarrow B$ 的\textbf“持有边（Has-A）”。这种边揭示了潜在的调用能力，即使代码中未显式出现 \texttt{new} 关键字~\cite{Tip2000ScalablePC}。

\subsubsection{基于继承与实现的泛化边}
为了处理多态调用，系统利用 Soot 的类层次分析（CHA）算法处理继承关系。若类 $A$ 继承自父类 $B$ 或实现了接口 $I$，则建立 $A \rightarrow B$ 或 $A \rightarrow I$ 的\textbf{“泛化边（Is-A）”}。在后续的路径搜索中，若遇到针对接口 $I$ 的调用，算法将自动扩展至其所有具体实现类 $A$，从而覆盖多态场景下的动态分派路径。

\subsubsection{基于切面的增强边}
微服务架构广泛使用 AOP 技术实现熔断、限流或日志记录。切面类（Aspect）通常通过 \texttt{@Before}、\texttt{@Around} 等注解绑定到特定的目标方法上，导致控制流在运行时发生隐式跳转。系统通过解析切面表达式（Pointcut Expression），识别出切面类 $A$ 与被增强类 $B$ 之间的绑定关系，建立 $A \rightarrow B$ 的“增强边（Advise-A）”。这确保了在分析调用链时，能够正确穿越由中间件引入的代理逻辑。

\subsection{基于微服务的调用关系图}
\label{subsec:service_dependency_graph}


\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[
      font=\sffamily\small,
      >=Stealth,
      scale=0.85, transform shape,
      % 类节点样式
      class box/.style={
          draw=blue!40,
          rectangle,
          rounded corners=2pt,
          minimum width=3.2cm, 
          minimum height=0.9cm,
          align=center, 
          fill=blue!5,
          line width=0.6pt
      },
      % 协议标注样式
      rpc label/.style={font=\scriptsize\bfseries, text=red!80, fill=white, inner sep=1pt},
      http label/.style={font=\scriptsize\bfseries, text=violet, fill=white, inner sep=1pt},
      service font/.style={font=\footnotesize\bfseries, text=gray!60}
  ]

  % --- 第一列：微服务 A (Order) ---
  \node[class box] (c1) at (0, 0) {OrderController};
  \node[class box] (s1) at (0, -1.8) {OrderServiceImpl};
  \node[class box] (f_inv) at (0, -3.6) {InventoryClient}; % 对应 RPC
  \node[class box] (f_pay) at (0, -5.4) {RestOrderClient}; % 对应 HTTP
  
  \begin{scope}[on background layer]
    \node[draw=gray!30, dashed, fill=gray!2, rounded corners=6pt, fit=(c1) (f_pay), inner sep=12pt] (svcA) {};
    \node[service font, anchor=south] at (svcA.north) {微服务 A (Order Service)};
  \end{scope}

  % --- 第二列：目标服务 B & C (Inventory & Payment) ---
  % 严格对齐 Y 轴坐标，防止箭头飘走
  \node[class box] (c2) at (8.5, -3.6) {InvController};
  \node[class box] (c3) at (8.5, -5.4) {PayController};

  \begin{scope}[on background layer]
    \node[draw=gray!30, dashed, fill=gray!2, rounded corners=6pt, fit=(c2), inner sep=10pt] (svcB) {};
    \node[service font, anchor=south] at (svcB.north) {微服务 B (Inventory)};
    
    \node[draw=gray!30, dashed, fill=gray!2, rounded corners=6pt, fit=(c3), inner sep=10pt] (svcC) {};
    \node[service font, anchor=south] at (svcC.north) {微服务 C (Payment)};
  \end{scope}

  % --- 连线逻辑 ---

  % 1. 服务内部调用
  \draw[->, gray!40, thick] (c1.south) -- (s1.north);
  \draw[->, gray!40, thick] (s1.south) -- (f_inv.north);
%   \draw[->, gray!40, thick, dashed] (s1.west) -- ++(-0.5,0) |- (f_pay.west) 
%         node[pos=0.75, left, font=\tiny, text=gray] {静态语义传递};

  % 2. 跨服务 RPC 调用 (A -> B) - 红色直线
  \draw[->, line width=1.2pt, red!60] (f_inv.east) -- (c2.west) 
        node[midway, rpc label] {RPC (Feign/Dubbo)};

  % 3. 跨服务 HTTP 调用 (A -> C) - 紫色直线
  \draw[->, line width=1.2pt, violet!60] (f_pay.east) -- (c3.west) 
        node[midway, http label] {HTTP/REST (RestTemplate)};

%   % --- 聚合结果 Es (置于最右侧，完全独立) ---
%   \draw[<->, line width=2pt, orange!40] (11, -1.0) -- ++(1,0) |- (11, -4.5) 
%         node[pos=0.25, right, font=\small\bfseries, text=orange!80] {聚合边 $E_s$: A $\to$ \{B, C\}};

  \end{tikzpicture}
  \caption{基于类级关联聚合的微服务调用关系图构建示例}
  \label{fig:service_graph_multi_protocol}
\end{figure}


类级调用图虽然精确，但其粒度过细，无法直接用于 Kubernetes NetworkPolicy 的生成。为此，如图\ref{fig:service_graph_multi_protocol}系统执行图聚合操作，构建以微服务为节点的有向图 $G_{service} = (V_s, E_s)$。

\subsubsection{节点映射与聚合}
首先，利用 3.1 节采集的 Kubernetes Pod 标签信息，建立“类 $\rightarrow$ 微服务”的归属映射函数 $M(c) = s$。对于 $G_{class}$ 中的每一个节点 $c \in V_c$，将其映射到对应的微服务标识 $s$。所有映射到同一 $s$ 的类节点被合并为一个微服务节点 $v_s \in V_s$。

\subsubsection{跨服务边的解析与生成}
遍历 $G_{class}$ 中的所有边 $(u, v)$，若 $M(u) \neq M(v)$，则表明存在潜在的跨服务调用。此时，分析引擎需结合 3.1.4 节采集的注册中心数据进行地址解析：
\begin{itemize}
    \item 声明式调用解析：若节点 $v$ 是一个被标记为 \texttt{@FeignClient("order-service")} 的接口，系统查询服务寻址映射表，找到 \texttt{order-service} 对应的微服务节点 $v_{target}$，并在 $M(u)$ 与 $v_{target}$ 之间添加一条有向边。
    \item 编程式调用解析：若节点 $u$ 中明确包含了指向 \texttt{"http://inventory-service"} 的 \texttt{RestTemplate} 调用（经 3.2.3 节污点分析提取），系统同样通过服务发现机制解析目标服务，并在图中建立依赖关系。
\end{itemize}

最终生成的 $G_{service}$ 清晰描述了集群内所有微服务之间的“谁调用谁”的拓扑结构，且每一条边都附带了具体的调用端口与协议元数据，为后续生成最小权限的 ACL 规则提供了完备的决策依据~\cite{Zhou2018FaultAA}。



\section{网络策略生成}
\label{sec:network_policy_generation}

微服务依赖图 $G_{service}$ 描述了系统内部合法的通信链路。为了将这些抽象的拓扑关系转化为 Kubernetes 集群可执行的访问控制规则，本节设计了一套自动化的策略生成算法。该算法遵循零信任架构的“最小权限（Least Privilege）”原则，通过标签映射、白名单合成及冲突消解三个步骤，生成确定性的 NetworkPolicy 资源对象。

\subsection{Pod 标签与服务拓扑映射机制}
\label{subsec:label_mapping}

Kubernetes NetworkPolicy 的核心机制是基于标签选择器（Label Selector）来界定策略的作用域（Target）与对端（Peer）。因此，策略生成的首要任务是将 $G_{service}$ 中的节点 $v_s$ 映射回集群运行时的 Pod 标签集合。

利用 3.1 节采集的 Kubernetes 编排元数据，系统建立了一个双向索引表：
\begin{equation}
Map: ServiceName \rightarrow \{ \langle Key, Value \rangle \}_{labels}
\end{equation}
映射逻辑如下：
\begin{enumerate}
    \item 服务发现映射：对于通过 Service 暴露的微服务，分析系统会解析 Service 定义中的 \texttt{spec.selector} 字段，将其作为该服务对应 Pod 的标识标签。
    \item 无头服务映射：对于 Headless Service 或未定义 Selector 的外部服务，系统通过解析 EndpointSlice 资源，获取后端 Pod 的实际 IP，若无法关联标签，则生成基于 \texttt{ipBlock} 的 CIDR 规则。
    \item 命名空间隔离：在映射过程中，严格保留命名空间（Namespace）上下文。若依赖图中存在跨命名空间的调用边，系统将在生成的规则中自动注入 \texttt{namespaceSelector}，以确保多租户环境下的隔离性~\cite{nist800204b}。
\end{enumerate}

\subsection{最小化白名单生成}
\label{subsec:whitelist_generation}



\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[
      font=\sffamily\small,
      >=Stealth,
      scale=0.9, transform shape,
      % 基础方框样式
      basic box/.style={
          draw=gray!50,
          rectangle,
          rounded corners=3pt,
          minimum width=3.8cm, 
          minimum height=1.1cm,
          align=center, 
          fill=white,
          drop shadow={opacity=0.1, shadow xshift=1pt, shadow yshift=-1pt},
          inner sep=5pt,
          line width=0.8pt
      },
      input box/.style={basic box, draw=orange!40, fill=orange!5},
      process box/.style={basic box, draw=blue!40, fill=blue!5},
      output box/.style={basic box, draw=violet!40, fill=violet!5, minimum width=4.8cm},
      % 连线与标注样式：使用白色背景遮罩，确保不压线
      line/.style={->, draw=gray!60, thick, rounded corners=3pt},
      label node/.style={font=\scriptsize\bfseries, text=gray!80, fill=white, inner sep=2pt}
  ]

  % --- 第一列：输入源 ---
  \node[input box] (g_svc) at (0, 0) {\textbf{微服务调用图 $G_{service}$} \\ \scriptsize (服务间意图集合)};
  \node[input box] (fingerprint) at (0, -3.0) {\textbf{动态运行指纹} \\ \scriptsize (端口/实例标签)};

  % --- 第二列：核心处理逻辑 ---
  \node[process box] (mapping) at (6.5, 0) {\textbf{身份与标签映射} \\ \scriptsize (App ID $\to$ Selector)};
  \node[process box] (port) at (6.5, -3.0) {\textbf{协议端口绑定} \\ \scriptsize (RPC/HTTP 端口识别)};

  % --- 第三列：输出结果 ---
  \node[output box] (policy) at (12.5, -1.5) {\textbf{零信任网络策略} \\ \scriptsize (Kubernetes NetworkPolicy)};

  % --- 连线逻辑 (精确控制标注位置) ---
  
  % 1. 水平直线连线
  \draw[line] (g_svc.east) -- (mapping.west) 
        node[midway, label node] {识别源/目实体};
        
  \draw[line] (fingerprint.east) -- (port.west) 
        node[midway, label node] {解析监听端口};

  % 2. 汇聚连线 (使用固定折点，防止箭头飘)
  \draw[line] (mapping.east) -- ++(1.5,0) |- ([yshift=0.35cm]policy.west);
  \node[label node, anchor=west] at (8.5, 0.4) {确定选择器范围};

  \draw[line] (port.east) -- ++(1.5,0) |- ([yshift=-0.35cm]policy.west);
  \node[label node, anchor=west] at (8.5, -3.4) {约束最小开放端口};

  % --- 背景装饰 (修正：使用绝对坐标锁定，确保框框绝对不歪) ---
  \begin{scope}[on background layer]
    % 定义一个完美的矩形框，手动指定左上角和右下角
    \draw[draw=violet!20, dashed, fill=violet!2, rounded corners=10pt, line width=0.6pt] 
      (4.2, 1.2) rectangle (15.2, -4.2);
    
    % \node[anchor=south, font=\scriptsize\bfseries, text=violet!40] at (9.7, 1.2) {3.4.2 最小化白名单生成逻辑};
  \end{scope}

  \end{tikzpicture}
  \caption{最小化白名单策略生成流程示意图}
  \label{fig:whitelist_generation_v4}
\end{figure}



基于“永不信任，始终验证”的零信任理念，本系统采用“默认拒绝 + 显式允许”的策略生成模式。对于依赖图中的每一个微服务节点 $v$，如图\ref{fig:whitelist_generation_v4}, 生成策略流程如下：

\subsubsection{基线策略构建}
首先为目标工作负载生成一条“隔离基线（Isolation Baseline）”策略。该策略将 \texttt{policyTypes} 设置为 \texttt{["Ingress", "Egress"]}，但不包含任何允许规则。一旦应用该策略，Kubernetes CNI 插件将立即阻断进出该 Pod 的所有非授权流量，从而收敛攻击面。

\subsubsection{白名单规则合成}
遍历图 $G_{service}$ 中与节点 $v$ 相关联的所有边，生成细粒度的放行规则：
\begin{itemize}
    \item 入站规则（Ingress）：对于所有指向 $v$ 的入边 $(u, v) \in E_s$，在 $v$ 的策略中添加一条 Ingress 规则，将来源设置为 $u$ 的标签选择器（\texttt{from: podSelector}），并严格限定目标端口（\texttt{ports}）为 $v$ 的监听端口。
    \item 出站规则（Egress）：对于所有由 $v$ 发出的出边 $(v, w) \in E_s$，在 $v$ 的策略中添加一条 Egress 规则，将目标设置为 $w$ 的标签选择器或 IP 段（\texttt{to: podSelector/ipBlock}）。
    \item 基础设施工单：自动注入对集群 DNS 服务（UDP 53端口）的放行规则，保障微服务的基础解析能力。
\end{itemize}

\subsection{策略冗余消除与冲突检测}
\label{subsec:policy_optimization}

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[
      font=\sffamily\small,
      >=Stealth,
      scale=0.9, transform shape,
      % 方框样式
      basic box/.style={
          draw=gray!50,
          rectangle,
          rounded corners=3pt,
          minimum width=3.8cm, 
          minimum height=1.1cm,
          align=center, 
          fill=white,
          drop shadow={opacity=0.1, shadow xshift=1pt, shadow yshift=-1pt},
          inner sep=5pt,
          line width=0.8pt
      },
      input box/.style={basic box, draw=violet!40, fill=violet!5},
      process box/.style={basic box, draw=red!40, fill=red!5},
      output box/.style={basic box, draw=green!40, fill=green!5, minimum width=4.5cm},
      % 标注样式：通过白色遮罩实现“切断”线条的效果
      line/.style={->, draw=gray!60, thick, rounded corners=3pt},
      label node/.style={font=\scriptsize\bfseries, text=gray!80, fill=white, inner sep=2pt}
  ]

  % --- 第一列：输入源 ---
  \node[input box] (raw) at (0, 0) {\textbf{原始候选策略} \\ \scriptsize (全量白名单规则)};
  \node[input box] (baseline) at (0, -3.0) {\textbf{安全基线库} \\ \scriptsize (全局禁止/限制规则)};

  % --- 第二列：核心处理逻辑 ---
  \node[process box] (dedup) at (6.5, 0) {\textbf{冗余消除引擎} \\ \scriptsize (掩码聚合与包含判定)};
  \node[process box] (conflict) at (6.5, -3.0) {\textbf{冲突检测模块} \\ \scriptsize (规则交集与优先级校验)};

  % --- 第三列：生成结果 ---
  \node[output box] (final) at (12.5, -1.5) {\textbf{精简安全策略} \\ \scriptsize (Minimized NetworkPolicy)};

  % --- 连线逻辑 (正交路径，标注自动避让) ---
  
  % 1. 原始策略处理
  \draw[line] (raw.east) -- (dedup.west) 
        node[midway, label node] {规则去重};
        
  % 2. 基线合规对比
  \draw[line] (baseline.east) -- (conflict.west) 
        node[midway, label node] {合规性扫描};

  % 3. 汇聚与优化 (使用绝对坐标偏移，防止线条打岔)
  \draw[line] (dedup.east) -- ++(1.5,0) |- ([yshift=0.35cm]final.west);
  \node[label node, anchor=west] at (8.5, 0.4) {策略掩码聚合};

  \draw[line] (conflict.east) -- ++(1.5,0) |- ([yshift=-0.35cm]final.west);
  \node[label node, anchor=west] at (8.5, -3.4) {解决逻辑冲突};

  % --- 背景装饰 (修正：绝对坐标手动锁定，确保背景框绝对不歪) ---
  \begin{scope}[on background layer]
    \draw[draw=red!20, dashed, fill=red!2, rounded corners=10pt, line width=0.6pt] 
      (4.2, 1.2) rectangle (15.2, -4.2);
    
    % \node[anchor=south, font=\scriptsize\bfseries, text=red!40] at (9.7, 1.2) {3.4.3 策略优化与校验引擎};
  \end{scope}

  \end{tikzpicture}
  \caption{策略冗余消除与冲突检测流程示意图}
  \label{fig:policy_optimization_flow}
\end{figure}

在大规模集群中，自动化生成的策略可能与运维人员手动配置的规则产生重叠或冲突。为了保证策略集的有效性与性能，如图\ref{fig:policy_optimization_flow}所示，系统在下发前执行基于集合论的优化算法。

\subsubsection{CIDR 聚合与冗余消除}
对于基于 IP 地址的 \texttt{ipBlock} 规则，系统采用区间合并算法（Interval Merging）对重叠的 CIDR 网段进行聚合。例如，规则 $R_1: 192.168.1.0/25$ 与 $R_2: 192.168.1.128/25$ 将被合并为 $192.168.1.0/24$。这不仅减少了底层 iptables/eBPF 的条目数量，也降低了策略匹配的计算开销。

\begin{table}[htbp]
  \centering
  \caption{微隔离策略冲突类型定义与系统消解动作}
  \label{tab:policy_conflict_matrix}
  \resizebox{1.0\textwidth}{!}{
    \begin{tabular}{lp{6cm}l}
    \toprule
    \textbf{冲突类型} & \textbf{逻辑定义 (Description)} & \textbf{系统消解动作 (Action)} \\
    \midrule
    冗余冲突 (Redundancy) & 新生成的规则 $R_{new}$ 是现有规则 $R_{exist}$ 的真子集 ($R_{new} \subset R_{exist}$)，且动作一致。 & \textbf{丢弃}：保留现有宽泛规则，减少规则数量。 \\
    \midrule
    遮蔽冲突 (Shadowing) & 现有规则 $R_{exist}$ 优先级更高且范围覆盖 $R_{new}$，但动作相反（如 $R_{exist}$ 为 Deny）。 & \textbf{报警}：提示策略无效，需人工介入调整优先级。 \\
    \midrule
    相关冲突 (Correlation) & $R_{new}$ 与 $R_{exist}$ 作用域部分重叠，且动作不同，导致重叠区域行为不确定。 & \textbf{拆分}：将重叠区域提取为独立的高优先级规则。 \\
    \midrule
    网段聚合 (Aggregation) & 多个 CIDR 规则连续（如 /24 相邻网段）且动作一致。 & \textbf{合并}：聚合为更大的 CIDR 块 (Supernetting)。 \\
    \bottomrule
    \end{tabular}
  }
\end{table}

\subsubsection{逻辑冲突检测}
系统定义了策略间的遮蔽（Shadowing）与泛化（Generalization）关系。在生成新策略前，系统会与集群现存策略进行集合包含关系检查：
\begin{equation}
Conflict(R_{new}, R_{exist}) \iff (Action_{new} \neq Action_{exist}) \land (Scope_{new} \cap Scope_{exist} \neq \emptyset)
\end{equation}
若检测到新生成的“拒绝”规则被现有的“宽泛允许”规则（如 \texttt{allow-all}）所遮蔽，系统将生成报告，提示存在潜在的安全敞口，而非盲目覆盖，从而确保了生产环境的稳定性~\cite{Cuppens2014}。。




\section{本章小结}
\label{sec:chap3_summary}

本章构建了基于动静态协同分析的零信任微隔离策略生成底座。首先，设计了基于 SharedInformer 与 CRI 的运行时探针，实现了对 Kubernetes 元数据、容器进程上下文及业务字节码的无侵入采集；其次，利用指纹去重与 Soot 静态分析框架，精准提取了微服务间的远程调用链路，并结合依赖注入与切面特征构建了服务级依赖拓扑；最后，遵循零信任最小权限原则，建立了从服务拓扑到 NetworkPolicy 的自动化映射与冲突消解机制，为系统提供了确定性的安全规则保障。



\chapter{基于大模型代码分析的零信任微隔离策略双向智能生成}
\label{chap:llm_analysis}




本章提出了一种基于大语言模型（LLM）与 DeepWiki 代码知识库的双向智能生成框架。该框架旨在引入外部语义知识，弥合底层基础设施与上层业务逻辑之间的鸿沟。

系统的总体架构如图 \ref{fig:llm_system_architecture_final} 所示，核心逻辑包含以下三个层次：

\begin{enumerate}
    \item 多源信息关联层 (Context Layer)：针对云原生环境下容器运行时与静态代码割裂的痛点，本层并不重复底层的全量采集工作，而是聚焦于“关联”。通过引入 LLM 仓库推断 (Repo Inference) 模块，系统利用运行时捕获的环境变量、启动指令等指纹特征，智能推导并锁定目标容器对应的源代码仓库地址，从而建立起“运行时实例 $\leftrightarrow$ 静态代码库”的语义索引，为后续分析提供物理入口。
    
    \item 语义推理层 (Semantic Reasoning Layer)：该层是本章系统的智能中枢，由两大核心组件构成。DeepWiki 引擎负责对代码仓库进行深度扫描，挖掘跨文件的隐式依赖与配置文件路径，构建代码知识图谱；LLM 推理代理 (Reasoning Agent) 则基于 DeepWiki 提供的知识上下文，利用思维链 (Chain-of-Thought, CoT) 技术执行复杂的逻辑推演，负责构建合规性证据链与意图识别。
    
    \item 双向生成与应用层 (Application Layer)：基于推理层的语义理解能力，系统向上提供两种截然不同的工作模式，以覆盖微隔离的全生命周期需求：
    \begin{itemize}
        \item 逆向解释 (Inverse Explanation)：面向存量系统的审计场景。系统接收现有的 NetworkPolicy，回溯代码层面的业务证据，生成包含因果归因的可解释性审计报告，解决“策略为何存在”的可解释性难题。
        \item 正向生成 (Forward Generation)：面向新上线服务的防护场景。针对无历史流量的新服务，系统直接从代码逻辑中提取通信意图，生成默认安全的微隔离策略，解决“冷启动”阶段的防护难题。
    \end{itemize}
\end{enumerate}

通过这一架构，系统不仅弥补了确定性分析的语义盲区，更通过双向闭环机制，实现了从“被动防御”到“意图驱动”的智能化升级。

\begin{figure}[htbp]
    \centering
    \resizebox{1.0\textwidth}{!}{
        \begin{tikzpicture}[
            font=\sffamily\small,
            >=Stealth,
            basic box/.style={
                draw=gray!50,
                rectangle,
                rounded corners=3pt,
                minimum width=4.5cm,
                minimum height=1.4cm,
                align=center,
                fill=white,
                drop shadow={opacity=0.1, shadow xshift=1pt, shadow yshift=-1pt},
                inner sep=4pt
            },
            input box/.style={basic box, draw=gray!60, fill=gray!5, dashed, minimum width=4.0cm},
            process box/.style={basic box, draw=blue!40, fill=blue!5},
            core box/.style={basic box, minimum width=11cm, minimum height=1.6cm, draw=orange!50, fill=orange!5, line width=1pt},
            out box/.style={basic box, minimum width=4.8cm, draw=violet!40, fill=violet!5},
            group box/.style={draw=gray!35, dashed, inner sep=15pt, rounded corners=8pt},
            group label/.style={font=\scriptsize\bfseries, text=gray!80, fill=white, inner sep=4pt},
            line/.style={->, draw=gray!60, thick, rounded corners=4pt},
            thick line/.style={->, draw=gray!50, line width=1.2pt, rounded corners=4pt},
            bidirectional/.style={<->, draw=orange!60, thick, dashed}
        ]

        % 间距（已优化）
        \def\colsep{8.5}
        \def\rowsep{2.5}

        % 第一层：上下文锚定
        \node[input box] (runtime) at (0, 0) {运行时指纹\\(Runtime)};
        \node[input box] (code) at (\colsep, 0) {代码仓库\\(Code Repo)};
        \node[process box, minimum width=3.2cm, minimum height=1cm, fill=white, draw=blue!40] 
              (inference) at (\colsep/2, 0) {LLM 仓库推断\\(Inference)};

        % 第二层：语义推理引擎
        \node[core box] (deepwiki) at (\colsep/2, \rowsep*1.5) {
            \textbf{DeepWiki 代码语义理解引擎}\\
            跨文件依赖挖掘 / 动态配置路径推理 / 意图识别
        };
        \node[basic box, minimum width=10cm, minimum height=1.4cm, draw=orange!80, fill=white, dashed, 
              above=0.6cm of deepwiki] (llm) {
            \textbf{LLM 推理代理 (Reasoning Agent)}\\
            思维链 (CoT) 推演 / 证据链构建 / 审计判决
        };

        % 第三层：双向功能模块（左右对称）
        \node[process box, above left=1.6cm and 1.8cm of llm.north] (reverse) {逆向解释模块\\(Reverse Explanation)};
        \node[process box, above right=1.6cm and 1.8cm of llm.north] (forward) {正向生成模块\\(Forward Generation)};

        % 第四层：应用交付
        \node[out box, above=1.0cm of reverse] (report) {可解释性审计报告\\(Audit Report \& Evidence)};
        \node[out box, above=1.0cm of forward] (policy) {意图驱动策略生成\\(Intent-based Policy)};

        % ==================== 分组框与标签（标签上移，避免任何压线感） ====================
        \node[group box, fit=(runtime) (code) (inference)] (layer_context) {};
        \node[group label] at ([yshift=12pt]layer_context.north) {多源信息关联层 (Context Layer)};

        \node[group box, fit=(deepwiki) (llm)] (layer_core) {};
        \node[group label] at ([yshift=12pt]layer_core.north) {语义推理层 (Semantic Reasoning Layer)};

        \node[group box, fit=(reverse) (forward) (report) (policy)] (layer_app) {};
        \node[group label] at ([yshift=12pt]layer_app.north) {双向生成与应用层 (Application Layer)};

        % ==================== 连线 ====================
        \draw[line] (runtime) -- (inference);
        \draw[line] (inference) -- (code);

        \draw[thick line] (runtime.north) -- ++(0,0.6) -| ([xshift=-4.25cm]deepwiki.south);
        \draw[thick line] (code.north) -- ++(0,0.6) -| ([xshift=4.25cm]deepwiki.south);

        \draw[bidirectional] (deepwiki.north) -- (llm.south);

        % 关键修复：两条分支连线分开写，确保标注位置精准
        \draw[line] (llm.north) -- ++(0,1.3) -| (reverse.south) 
            node[pos=0.75, above, font=\tiny, text=gray]{Evidence Mining};
        \draw[line] (llm.north) -- ++(0,1.3) -| (forward.south) 
            node[pos=0.75, above, font=\tiny, text=gray]{Intent Extraction};

        % NetworkPolicy 输入
        % \node[left=1.0cm of reverse, font=\small, text=gray, align=center] (input_yaml) {Network\\Policy};
        % \draw[line, dashed] (input_yaml) -- (reverse.west);

        \draw[line] (reverse) -- (report);
        \draw[line] (forward) -- (policy);

        \end{tikzpicture}
    }
    \caption{基于大模型语义分析的双向策略智能生成系统架构}
    \label{fig:llm_system_architecture_final}
\end{figure}

\section{统一的多源信息采集与代码仓库关联机制}
\label{sec:multisource_collection}




在上一章中，系统通过运行时探针与字节码静态分析技术，从物理层面还原了微服务集群的网络拓扑结构，有效解决了“谁访问了谁”的链路发现问题。然而，这种仅依赖二进制制品（Artifacts）与底层网络状态的确定性分析方法仍存在显著的局限性：编译后的字节码虽然精准保留了程序的执行逻辑，却不可避免地丢失了开发者在编码阶段注入的大量关键语义信息，例如业务逻辑注释、架构设计文档、具有描述性的变量命名以及特定的代码组织结构。这些“元信息”承载了服务的设计初衷与业务意图，而它们的缺失直接导致了通用大语言模型（LLM）难以仅凭反编译代码或底层元数据进行高效、深度的逻辑推理 。


为了弥合这一底层运行状态与上层业务语义之间的“鸿沟”，并赋予大模型对云原生应用业务逻辑的深度认知能力，本节提出了一种跨越“运行时（Runtime）”与“开发态（Development）”的全链路溯源机制。该机制突破了传统分析仅局限于容器内部环境的限制，创新性地利用大模型的知识检索与推理能力，建立起从线上动态运行的 Pod 实例到线下静态代码仓库（Git Repository）的精准映射关系。通过这一机制，系统能够将碎片化的运行时指纹还原为完整的源代码上下文，从而为后续基于代码语义的智能策略生成构建完备的知识基座。

\subsection{运行时通用指纹特征的采集}
\label{subsec:runtime_fingerprinting}

在缺乏显式仓库标识的情况下，运行时环境中仍然保留了大量可用于识别代码来源的隐含特征。本文将这类特征统称为运行时通用指纹特征，其本质是能够在不同部署实例之间保持相对稳定、且与代码仓库存在潜在关联的信息集合。

\begin{figure}[htbp]
  \centering
  \resizebox{1.0\textwidth}{!}{
    \begin{tikzpicture}[
        font=\sffamily\small,
        >=Stealth,
        % --- 样式定义 ---
        basic box/.style={
            draw=gray!50,
            rectangle,
            rounded corners=3pt,
            minimum width=3.2cm,
            minimum height=1.1cm,
            align=center,
            fill=white,
            drop shadow={opacity=0.1, shadow xshift=1pt, shadow yshift=-1pt},
            inner sep=3pt,
            line width=0.7pt
        },
        scene box/.style={basic box, draw=gray!60, fill=gray!5, dashed},
        strategy box/.style={basic box, draw=blue!40, fill=blue!5, minimum width=3.8cm},
        data box/.style={basic box, draw=orange!50, fill=orange!5, minimum width=3.2cm},
        output box/.style={basic box, draw=violet!40, fill=violet!5, minimum width=5.0cm},
        line/.style={->, draw=gray!60, thick, rounded corners=3pt},
        clean label/.style={font=\scriptsize\bfseries, text=blue!50!black, inner sep=2pt, align=center, fill=white, fill opacity=0.8}
    ]

    % === 布局坐标 ===
    % 左：场景
    \node[scene box] (dev) at (0, 2.4) {\textbf{开发/测试环境} \\ \scriptsize Standard Image};
    \node[scene box] (prod) at (0, 0) {\textbf{生产/Distroless} \\ \scriptsize No Shell/Tools};
    \node[scene box] (secure) at (0, -2.4) {\textbf{受限/高安环境} \\ \scriptsize Runtime Restricted};

    % 中：策略
    \node[strategy box] (str1) at (5.0, 2.4) {\textbf{策略一：流式传输} \\ \scriptsize Exec + Stdout};
    \node[strategy box] (str2) at (5.0, 0) {\textbf{策略二：临时容器} \\ \scriptsize Ephemeral Debug};
    \node[strategy box] (str3) at (5.0, -2.4) {\textbf{策略三：静态解析} \\ \scriptsize Manifest Recursion};

    % 右：数据
    \node[data box] (proc) at (10.0, 2.4) {\textbf{活跃进程树} \\ \scriptsize PID 1 / Children};
    \node[data box] (cmd) at (10.0, 0) {\textbf{启动命令行} \\ \scriptsize Command / Args};
    \node[data box] (env) at (10.0, -2.4) {\textbf{关键环境变量} \\ \scriptsize APP\_ID / DB\_URL};

    % 底：输出
    \node[output box] (final) at (7.5, -4.2) {
        \textbf{通用运行时指纹向量 $\mathbf{f}_{rt}$} \\
        \scriptsize Unified Runtime Fingerprint
    };

    % 背景
    \begin{scope}[on background layer]
        \node[draw=blue!15, dashed, fill=blue!2, rounded corners=8pt,
              fit=(str1) (str3), inner sep=10pt] (bg) {};
    \end{scope}

    % === 连线逻辑 (全直角折线 Orthogonal) ===

    % 1. 场景 -> 策略 (水平直连)
    \draw[line] (dev) -- (str1);
    \draw[line] (prod) -- (str2);
    \draw[line] (secure) -- (str3);

    % 2. 策略 -> 数据 (分层折线)
    
    % --- S1 (Stream) ---
    % 直连 Proc
    \draw[line] (str1.east) -- (proc.west);
    
    % 折线连 Cmd (拐点 x=7.2)
    \draw[line] ([yshift=-2pt]str1.east) -- ++(0.3,0) |- ([yshift=3pt]cmd.west);
    
    % 大折线连 Env (拐点 x=8.0, 最外层通道)
    \draw[line] ([yshift=-4pt]str1.east) -- ++(1.1,0) |- ([yshift=4pt]env.west);

    % --- S2 (Debug) ---
    % 折线连 Proc (拐点 x=7.6)
    \draw[line] ([yshift=2pt]str2.east) -- ++(0.7,0) |- ([yshift=-2pt]proc.west)
        node[pos=0.25, clean label] {}; % 标签在水平段
    
    % 直连 Cmd
    \draw[line] (str2.east) -- (cmd.west)
        node[midway, above, clean label, yshift=-1pt] {};
        
    % 折线连 Env (拐点 x=7.6)
    \draw[line] ([yshift=-2pt]str2.east) -- ++(0.7,0) |- ([yshift=2pt]env.west);

    % --- S3 (Static) ---
    % 折线连 Cmd (拐点 x=7.2, 最内层通道)
    \draw[line] ([yshift=2pt]str3.east) -- ++(0.3,0) |- ([yshift=-3pt]cmd.west);
    
    % 直连 Env
    \draw[line] (str3.east) -- (env.west)
        node[midway, above, clean label, yshift=-1pt] {};

    % 3. 数据 -> 输出 (规整折线)
    \draw[line] (proc.east) -- ++(0.4,0) |- (final.east);
    \draw[line] (cmd.east) -- ++(0.4,0) |- (final.east);
    \draw[line] (env.east) -- ++(0.4,0) |- (final.east);

    \end{tikzpicture}
  }
  \caption{指纹采集逻辑图}
  \label{fig:adaptive_collection_orthogonal}
\end{figure}

为了在异构的多语言环境中准确识别服务归属，系统首先需要从容器运行时中提取具有普适性的“特征指纹”。这一过程的核心在于获取容器内部的进程执行上下文，而非依赖静态的镜像元数据。

采集模块主要关注以下三类关键运行时数据：
\begin{itemize}
    \item 关键环境变量：环境变量是云原生应用配置注入的主要载体。系统重点提取包含业务语义的变量，例如服务名称（\texttt{APP\_NAME}）、应用 ID（\texttt{APP\_ID}）或配置中心地址。这些变量通常在部署清单（Deployment YAML）中定义，是识别服务身份的强特征。
    \item 启动命令行：解析容器主进程（PID 1）的完整启动命令（Command）及其参数（Args）。无论是 Java 的 \texttt{-jar} 参数、Python 的入口脚本路径，还是 Go 二进制文件的名称，都直接暴露了程序的入口点信息。
    \item 活跃进程列表：扫描容器内当前运行的所有进程树信息，用于辅助判断容器的实际运行状态和技术栈类型（例如是否存在 \texttt{node}、\texttt{python} 或 \texttt{java} 进程）。
\end{itemize}

在数据采集的工程实现上，针对不同的镜像类型，本系统设计了三种自适应的采集策略。

\subsubsection{策略一：基于流式传输的数据采集}

该策略通过与 Kubernetes API Server 建立长连接，利用HTTP/2 协议构建稳定的流式传输通道，实现对容器运行时信息的实时采集。采集探针通过 API Server 向目标容器发送标准化的 Shell 指令，并持续读取其标准输出（Stdout）流，从而获取所需的运行时数据。

相较于基于轮询的采集方式，流式传输能够在保持实现简单的同时，显著降低数据获取延迟，并避免频繁建立连接所带来的额外开销。此外，该策略完全依赖 Kubernetes 提供的原生接口实现，无需在宿主机或集群节点侧预先部署任何代理组件，部署成本较低。

需要指出的是，该策略依赖目标容器中保留基本的 Shell 与命令执行环境，因此更适用于开发测试场景，或尚未进行严格镜像裁剪的传统微服务应用。在采用 Distroless 等极简镜像的生产环境中，该策略的适用性将受到一定限制。



\subsubsection{策略二：基于临时容器的无侵入透视}
在对安全性与攻击面控制要求较高的生产环境中，微服务应用通常采用 Distroless 或 Scratch 等“极简镜像”进行部署。这类镜像在构建过程中移除了 Shell 及常用基础工具，导致基于 \verb|exec| 的运行时采集方式无法正常工作，从而使传统的命令注入式采集策略失效。

针对上述问题，系统引入基于临时容器（Ephemeral Container）的无侵入式透视机制。该机制利用 Kubernetes 提供的 Debug 能力，在不重启业务 Pod、也不修改原有镜像的前提下，动态注入一个包含完整工具集的临时容器，并配置其与业务容器共享进程命名空间（Process Namespace）。

通过这一方式，采集探针可以从临时容器侧直接访问 \verb|/proc| 文件系统，读取业务容器内 PID 1 进程对应的 \verb|/proc/<PID>/environ| 与 \verb|/proc/<PID>/cmdline| 等关键信息，从而规避业务容器缺失 Shell 工具的限制，实现对运行时环境的完整观测\cite{kerrisk2013namespaces, Kubernetes2024Ephemeral}。由于整个采集过程不对业务容器本身产生任何修改，该策略符合“不可变基础设施”的设计原则，适用于安全要求较高的生产部署场景。

\subsubsection{策略三：基于元数据定义的静态解析}
在部分安全策略极为严格的场景中，集群可能明确禁止任何形式的运行时注入或 \verb|exec| 操作。针对这类运行时接口完全受限的环境，系统回退至基于 Kubernetes 元数据的静态解析策略，以保证基础信息采集能力的可用性。

该策略不直接与容器运行时交互，而是通过解析 Pod 的声明式定义文件（Manifest），从配置层面还原容器启动时的关键信息。采集器基于 Informer 机制持续监听 Pod 对象的变更，并在检测到相关变化后执行级联解析逻辑，包括环境变量展开与挂载配置分析两个方面。

具体而言，系统首先解析 \verb|spec.containers.env| 字段，并递归解析 \verb|envFrom| 所引用的 ConfigMap 与 Secret 资源，自动处理 Kubernetes 的配置覆盖与合并规则，从而构建容器启动时最终生效的环境变量视图。同时，系统遍历 \verb|spec.volumes| 的定义，识别以文件形式挂载的 ConfigMap，并提取其中包含的关键配置项，例如 \verb|application.properties| 等配置文件内容。

尽管该策略无法获取运行时动态生成的临时变量，但其作为一种兜底方案，能够在运行时接口受限的情况下，仍然保证对服务注册中心地址、数据库连接串等核心拓扑信息的获取能力，为后续分析提供必要支撑。


\subsection{基于大模型的仓库推断}
\label{subsec:llm_inference}

在获取容器运行时的通用指纹特征后，系统面临的核心问题在于如何将这些来源多样、形式非结构化的运行时“痕迹”，准确映射回确定性的静态代码仓库地址。由于云原生应用生态中广泛混合部署了通用开源基础设施（如 MySQL、Redis）与具体业务微服务组件（如 DevLake、TiDB 的子模块），单纯依赖人工规则或特征匹配的方法难以覆盖复杂多样的组件类型，且维护成本较高。

为此，系统引入基于大语言模型（Large Language Model, LLM）的仓库推断机制，利用其在开源代码生态与软件工程语义方面的知识记忆能力，实现从运行时指纹到 GitHub 仓库地址的零样本推断。该机制的核心在于构建具备明确推理约束的 Prompt 模板（即 github\_code\_prompt），通过显式引导模型的分析路径，使其能够在无需人工规则库支持的情况下完成可靠推断。



\subsubsection{多视图证据链构建}
为提高推断结果的稳定性与鲁棒性，系统并未依赖单一类型的运行时特征，而是引导大模型从多个语义视角综合分析容器的运行环境信息，构建完整的证据链。首先，模型被提示优先检查 Kubernetes 编排层面的元数据特征，尤其是由 Helm Chart 或部署模板注入的标准标签（Labels），例如 app.kubernetes.io/name，以及项目特有的组件标识标签。这类信息通常直接反映了工作负载在系统中的逻辑身份，是识别项目归属的强信号来源。

当编排元数据不足以形成明确判断时，模型进一步分析容器环境变量中所蕴含的配置语义特征。一方面，通过识别服务端点相关变量命名模式（如 *\_URL、*\_SERVICE\_*），模型可以推断该组件在系统中的交互对象与功能角色；另一方面，环境变量中的项目前缀或命名约定（如 MYSQL\_ROOT\_PASSWORD、MY\_RELEASE\_DEVLAKE）往往直接暴露其所属的软件家族或上层项目。

在此基础上，模型还会结合容器的启动命令及参数信息，对实际执行语义进行补充判断。例如，通过识别启动的二进制文件名称（如 mysqld、nginx）或特定参数标志，进一步确认容器内主进程的类型与用途，从而完善整体推理依据。

\subsubsection{标准组件与业务项目的消歧}

在综合多视图证据后，大模型仍需面对一个关键问题，即如何区分通用标准软件与隶属于特定业务项目的组件。为此，系统在 Prompt 中显式注入消歧逻辑，引导模型在推断过程中优先判断组件的“归属层级”。

对于被识别为通用基础设施的软件组件，例如以 mysqld 作为主进程的数据库容器，模型被要求将其映射至对应的官方维护仓库（如 https://github.com/mysql/mysql-server）。相对地，对于属于大型微服务系统的子组件，即便其运行于通用语言基础镜像之上，模型也应优先将其归属到项目级主仓库（如https://github.com/apache/incubator-devlake），而非语言或运行时本身的仓库。这一策略有效避免了因运行环境相似而导致的误判问题。


\subsubsection{结构化输出约束}

为确保仓库推断结果能够被后续的 DeepWiki 引擎直接消费，系统在 Prompt 设计中引入了严格的结构化输出约束。通过指令微调（Instruction Tuning）的方式，模型被强制要求仅返回标准的 HTTPS 克隆地址格式，例如 https://github.com/owner/repo，并自动剥离任何解释性或冗余文本。

通过“多视图信息组装—显式逻辑引导—输出格式约束”的协同设计，系统充分发挥了大语言模型在代码生态领域的知识泛化能力，在无需人工维护规则集的前提下，实现了对多样化开源组件代码仓库的精准定位\cite{chen2021evaluating}。




\subsection{基于 DeepWiki 的配置文件路径推理与采集}
\label{subsec:config_extraction}

在通过第 4.1.2 节完成对微服务源代码仓库的精准定位后，系统进一步面临的关键任务是解析服务内部所依赖的隐式网络配置，例如数据库连接地址、服务注册中心位置等。这类信息通常存储于配置文件中，是理解微服务通信关系与依赖拓扑的重要基础。然而，不同项目在配置文件的组织方式上差异显著，其存储路径往往受到构建脚本、启动参数以及环境变量的共同影响，难以通过静态规则直接确定。

针对上述问题，系统并未简单依赖通用大语言模型对配置路径进行猜测，而是引入 DeepWiki 代码理解引擎，将第 4.1.1 节采集的运行时上下文信息与代码仓库的静态结构相结合，执行基于证据约束的配置文件路径推理。通过这一方式，路径推断过程不再是孤立的语义推测，而是建立在代码事实与运行环境之上的可解释推理过程。

\subsubsection{跨模态路径推理机制}
为实现对配置文件路径的准确定位，系统构建了推理提示词（config\_file\_prompt），引导 DeepWiki 在代码仓库中执行“运行态信息驱动、静态结构验证”的联合分析流程。首先，DeepWiki 会结合容器运行时的主进程启动命令及其参数，在代码仓库中定位对应的程序执行入口。例如，通过分析 Dockerfile中的 ENTRYPOINT指令或启动脚本（如 docker-entrypoint.sh），确定应用在启动阶段加载配置的具体逻辑位置。

在此基础上，DeepWiki 进一步分析代码与启动脚本中对环境变量的读取行为，将运行时采集到的环境变量与代码中的使用位置进行映射。通过判断诸如 MYSQL\_HOME、NACOS\_APPLICATION\_CONF 等变量是否参与配置路径的重定义，系统能够推断默认配置加载路径是否被显式覆盖。

当运行时参数与环境变量均未提供明确指向时，推理过程将回溯至镜像的构建阶段。DeepWiki 会解析 Dockerfile 中的 COPY 或 ADD 指令，追踪配置文件在构建过程中被放置的位置，从而直接推导其在容器文件系统中的绝对路径。这一方式避免了依赖经验性“惯例路径”的不确定性，使推断结果具备更高的确定性。

\subsubsection{输出约束与运行时验证}
为保证推理结果能够稳定地被自动化采集流程使用，系统对 DeepWiki 的输出施加了严格约束。模型仅被允许返回唯一的配置文件绝对路径（例如 /etc/my.cnf），或在无法确定时返回 None，以避免歧义性结果进入后续流程。

在获得候选路径后，系统调用第 4.1.1 节所述的运行时采集探针，对目标容器内的对应文件进行实地验证与读取。通过这一机制，DeepWiki 的代码理解能力用于解决“配置文件位于何处”的问题，而运行时探针则负责完成“配置内容如何获取”的实际操作，从而形成完整的闭环。

这种“静态路径推导与动态运行时验证相结合”的方法，有效弥补了单一静态分析难以覆盖运行时差异、单一动态分析难以准确定位文件路径的不足，使系统能够在复杂多变的云原生环境中，实现对微服务关键配置的稳定、精准采集。



\section{基于代码上下文的策略逆向解释机制}
\label{sec:policy_explanation}

通过 4.1 节构建的多源采集与关联机制，系统已成功打破了容器运行时的黑盒边界，建立了从动态 Pod 到静态代码仓库的确定性索引。然而，在零信任微隔离的实际运维场景中，仅拥有代码链接尚不足以解决“策略可读性差”的核心痛点。现有的 Kubernetes NetworkPolicy 资源对象通常以 YAML 格式存储，其描述语言仅包含抽象的标签选择器（Label Selector）与端口号（如 \texttt{allow port 8080}）。这种描述方式虽然满足了底层 CNI 插件的执行需求，却完全剥离了策略背后的业务语义。

对于安全运维与审计人员而言，面对成百上千条由 IP 段和端口构成的规则，往往陷入“知其然而不知其所以然”的困境：无法判断某条规则是承载了核心支付业务，还是仅仅为了通过健康检查；也难以确认该端口的开放是否符合代码层面的最小权限设计。这种“语义鸿沟（Semantic Gap）”不仅增加了误配置的风险，更严重阻碍了自动化策略在严格合规环境下的落地。

为此，本节提出了一种基于代码上下文的策略逆向解释（Reverse Explanation）机制。该机制视“代码”为解释网络行为的唯一真值来源（Source of Truth），通过将运行时状态完整输入 DeepWiki 引擎，从源代码层面反向推导策略的“调用意图（Intent）”与“支撑证据（Evidence）”，旨在将晦涩的底层 ACL 规则转化为具备可解释性、可审计性的自然语言报告。

\subsection{策略与工作负载信息的级联采集机制}
\label{subsec:policy_workload_collection}

要对一条抽象的网络策略进行语义解释，系统的首要任务是将其“锚定”到具体的业务实体上。Kubernetes NetworkPolicy 本质上是面向标签（Label-oriented）的声明式规则，它仅通过 \texttt{podSelector} 定义作用域，而不直接绑定具体的容器实例。因此，在调用 DeepWiki 引擎之前，系统必须执行一个逆向的级联采集流程，从静态的 YAML 规则出发，层层回溯至动态的 Pod 实例，最终锁定到静态的代码仓库，构建出完整的\textbf{“策略-实例-代码”}证据链。

\begin{figure}[htbp]
  \centering
  \resizebox{0.9\textwidth}{!}{
    \begin{tikzpicture}[
        font=\sffamily\small,
        >=Stealth,
        % --- 样式定义 ---
        basic box/.style={
            draw=gray!50,
            rectangle,
            rounded corners=3pt,
            minimum width=3.8cm,
            minimum height=1.0cm,
            align=center,
            fill=white,
            drop shadow={opacity=0.1, shadow xshift=1pt, shadow yshift=-1pt},
            inner sep=3pt,
            line width=0.7pt
        },
        % 左侧级联节点
        policy box/.style={basic box, draw=blue!40, fill=blue!5},
        pod box/.style={basic box, draw=gray!60, fill=gray!5, dashed},
        snap box/.style={basic box, draw=orange!50, fill=orange!5},
        repo box/.style={basic box, draw=violet!40, fill=violet!5},
        % 右侧聚合对象
        context box/.style={
            rectangle,
            draw=gray!40,
            fill=gray!2,
            rounded corners=4pt,
            minimum width=4.8cm,
            minimum height=5.2cm,
            inner sep=8pt,
            line width=0.8pt,
            drop shadow={opacity=0.15, shadow xshift=2pt, shadow yshift=-2pt}
        },
        % 连线与标签
        line/.style={->, draw=gray!60, thick, rounded corners=2pt},
        clean label/.style={font=\scriptsize\bfseries, text=blue!40!gray, inner sep=1pt, align=center, fill=white}
    ]

    % === 布局坐标 ===
    
    % --- 左列：级联溯源 ---
    \node[policy box] (policy) at (0, 3.8) {
        \textbf{NetworkPolicy ($P_{yaml}$)} \\[-1pt] 
        \scriptsize \texttt{spec.podSelector}
    };

    \node[pod box] (pod) at (0, 2.2) {
        \textbf{Sample Pod Instance} \\[-1pt] 
        \scriptsize Running State
    };

    \node[snap box] (snap) at (0, 0.6) {
        \textbf{Runtime Snapshot ($I_{runtime}$)} \\[-1pt] 
        \scriptsize Env / Command / Args
    };

    \node[repo box] (repo) at (0, -1.0) {
        \textbf{Code Repository ($R_{code}$)} \\[-1pt] 
        \scriptsize Git URL 
    };

    % --- 右列：上下文对象 ---
    \node[context box] (ctx) at (6.5, 1.4) {}; 
    
    % 标题
    \node[anchor=north west] at ([xshift=0.2cm, yshift=-0.2cm]ctx.north west) {
        \textbf{推理上下文对象 ($C_{context}$)}
    };
    
    % 内容区：去掉了错误的 leading 参数，利用 [4pt] 控制行距
    \node[anchor=north west, align=left, font=\scriptsize, text=gray!80] 
        at ([xshift=0.2cm, yshift=-0.8cm]ctx.north west) {
        \texttt{\{} \\[3pt]
        \hspace{1em} "policy\_target": "app=payment", \\[3pt]
        \hspace{1em} "runtime\_evidence": \texttt{[} \\[3pt]
        \hspace{2em} \textit{"env: DB\_URL=jdbc:mysql..."}, \\[3pt]
        \hspace{2em} \textit{"cmd: java -jar app.jar"} \\[3pt]
        \hspace{1em} \texttt{]}, \\[3pt]
        \hspace{1em} "source\_code": \texttt{\{} \\[3pt]
        \hspace{2em} "url": "github.com/...", \\[3pt]
        % \hspace{2em} "commit": "a1b2c3d" \\[3pt]
        \hspace{1em} \texttt{\}} \\[3pt]
        \texttt{\}}
    };

    % === 连线逻辑 ===

    % 1. 垂直级联
    \draw[line] (policy.south) -- (pod.north);
    \draw[line] (pod.south) -- (snap.north);
    \draw[line] (snap.south) -- (repo.north);

    % 左侧标签
    \node[anchor=east, font=\tiny, text=gray!50] at (-2.0, 3.0) {Reverse Lookup};
    \node[anchor=east, font=\tiny, text=gray!50] at (-2.0, 1.4) {Extract Context};
    \node[anchor=east, font=\tiny, text=gray!50] at (-2.0, -0.2) {Repo Inference};
    % 虚线指引
    \draw[gray!30, dotted, thin] (-1.9, 3.0) -- (-0.2, 3.0);
    \draw[gray!30, dotted, thin] (-1.9, 1.4) -- (-0.2, 1.4);
    \draw[gray!30, dotted, thin] (-1.9, -0.2) -- (-0.2, -0.2);

    % 2. 水平汇聚
    \draw[line] (policy.east) -- ++(0.5,0) |- ([yshift=1.8cm]ctx.west);
    \draw[line] (snap.east) -- ++(0.5,0) |- ([yshift=-0.5cm]ctx.west);
    \draw[line] (repo.east) -- ++(0.5,0) |- ([yshift=-1.8cm]ctx.west);

    % 3. 装饰点
    \node[circle, fill=blue!40, inner sep=1.5pt] at ([yshift=1.8cm]ctx.west) {};
    \node[circle, fill=orange!50, inner sep=1.5pt] at ([yshift=-0.5cm]ctx.west) {};
    \node[circle, fill=violet!40, inner sep=1.5pt] at ([yshift=-1.8cm]ctx.west) {};

    \end{tikzpicture}
  }
  \caption{策略与工作负载信息的级联采集机制}
  \label{fig:cascading_collection_compact_fixed}
\end{figure}

这一级联采集过程如图\ref{fig:cascading_collection_compact_fixed},包含以下三个关键步骤：

\subsubsection{基于选择器的策略-实例反向锚定}
系统首先通过 Kubernetes Informer 实时监听集群中的 \texttt{NetworkPolicy} 资源对象。当需要对某条策略进行解释时，解析引擎首先提取其 \texttt{spec.podSelector} 字段（目标选择器）以及 \texttt{policyTypes}（管控方向）。

由于标签选择器可能匹配多个 Pod 副本（例如一个 \texttt{app=payment} 的策略可能对应 10 个无状态副本），为了避免分析冗余，系统调用 Kubernetes API 的 \texttt{List} 接口，结合策略所在的命名空间（Namespace），反向查询出所有处于 \texttt{Running} 状态且标签命中的 Pod 实例列表。系统从中选取一个最具代表性的“样本 Pod”（通常是运行时间最长或最近重启的一个），将其作为后续语义分析的物理载体。这一步骤有效地将抽象的“策略作用域”具体化为了一个真实的“受控工作负载（Target Workload）”。

\subsubsection{面向策略验证的运行时上下文构建}
在锁定目标 Pod 后，系统并不重复 4.1 节所述的底层采集细节，而是聚焦于\textbf{提取与策略解释直接相关的运行时上下文}。针对该样本 Pod，系统构建包含以下关键信息的“运行时快照（Runtime Snapshot）”：

\begin{itemize}
    \item \textbf{网络配置上下文}：提取与网络连接紧密相关的环境变量（如 \texttt{DB\_HOST}, \texttt{Consul\_ADDR}, \texttt{PORT}）。这些变量往往是代码中网络行为的“配置源”，是后续 DeepWiki 验证端口开放合理性的关键线索。
    \item \textbf{进程执行上下文}：获取容器主进程的启动命令（Command）与参数（Args）。这决定了容器加载了哪个业务模块，帮助 DeepWiki 准确识别代码入口点。
\end{itemize}

\subsubsection{从实例到代码仓库的索引闭环}
最后，系统利用 4.1.2 节建立的仓库推断能力，将上述运行时指纹映射为确定的源代码仓库地址（Git URL）。

至此，系统成功构建了一个结构化的\textbf{推理上下文对象（Inference Context Object）}，其包含：
\begin{equation}
    C_{context} = \{ P_{yaml}, \ I_{runtime}, \ R_{code} \}
\end{equation}
其中 $P_{yaml}$ 为待解释的网络策略，$I_{runtime}$ 为 Pod 运行时快照，$R_{code}$ 为代码仓库索引。这一上下文对象打破了网络层与应用层的隔离，为后续 DeepWiki 引擎深入代码内部挖掘“该策略为何存在”提供了唯一的物理入口。

\subsection{容器级网络行为的局部推理机制}
\label{subsec:container_local_inference}

在 Kubernetes 的实际部署中，Pod 往往采用多容器协同模式（如 Istio 的 Sidecar 代理、日志采集器与业务容器共存）。为了精准归因网络流量的产生源头，系统采用了“分治”策略，首先对 Pod 内的每一个独立容器执行局部语义推理。

系统构建了专用的容器分析提示词（\texttt{container\_context\_prompt\_for\_explain}），设定大模型扮演“Kubernetes 网络安全专家”的角色，输入 4.2.1 节采集的单一容器上下文与当前 NetworkPolicy 摘要，执行以下标准化的推理流程。

\subsubsection{合理性优先的推理逻辑}

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[
      scale=0.9, transform shape,
      font=\sffamily\small,
      >=Stealth,
      % --- 样式定义 ---
      % 1. 基础容器：干净的圆角框，无多余装饰
      basic box/.style={
          rectangle,
          draw=gray!40,
          rounded corners=3pt,
          align=center,
          drop shadow={opacity=0.08, shadow xshift=1pt, shadow yshift=-1pt},
          line width=0.8pt,
          inner sep=6pt,
          fill=white
      },
      % 2. 输入层 (顶)
      input box/.style={
          basic box,
          draw=violet!50,
          fill=violet!5,
          text width=6.0cm,
          minimum height=1.0cm
      },
      % 3. 并行处理层 (左右分支)
      step box/.style={
          basic box,
          draw=blue!50,
          text width=4.0cm,
          minimum height=1.6cm
      },
      % 4. 核心逻辑层 (中间)
      core box/.style={
          basic box,
          draw=orange!50,
          fill=orange!5,
          text width=7.0cm,
          minimum height=1.2cm
      },
      % 5. 风险标记层 (红)
      risk box/.style={
          basic box,
          draw=red!50!black,
          fill=white,
          text width=6.0cm,
          minimum height=1.0cm
      },
      % 6. 输出层 (底)
      output box/.style={
          basic box,
          draw=green!50!black,
          fill=green!5,
          text width=6.0cm,
          minimum height=1.0cm
      },
      % 连线样式
      line/.style={->, draw=gray!60, thick, rounded corners=3pt}
  ]

  % === 1. 布局坐标 (使用相对坐标确保对齐) ===
  
  % 顶部输入
  \node[input box] (input) at (0, 4.5) {
      \textbf{单容器推理上下文 (Input)} \\[2pt]
      \scriptsize\texttt{Context + NetworkPolicy}
  };

  % 中间层：左右分支 (水平间距 7.0cm)
  \node[step box] (hard) at (-3.5, 2.2) {
      \textbf{1. 硬性约束扫描} \\[4pt]
      \scriptsize 解析 Dockerfile \texttt{EXPOSE} \\
      \scriptsize 建立基础网络指纹
  };

  \node[step box] (mining) at (3.5, 2.2) {
      \textbf{2. 多模态证据挖掘} \\[4pt]
      \scriptsize 扫描代码 \texttt{server.listen()} \\
      \scriptsize 解析 ENV \texttt{PORT=8080}
  };

  % 核心层
  \node[core box] (check) at (0, -0.2) {
      \textbf{3. 覆盖度验证 (Rationality Check)} \\[4pt]
      \scriptsize 假设策略合理 $\to$ 寻找支撑证据 \\
      \textbf{\textcolor{orange!60!black}{Evidence $\cap$ Policy Rules}}
  };

  % 风险层
  \node[risk box] (risk) at (0, -2.4) {
      \textbf{4. 风险上下文标记} \\[2pt]
      \scriptsize \textcolor{red!60!black}{标记未被策略覆盖的高危端口 (如 22)}
  };

  % 输出层
  \node[output box] (output) at (0, -4.2) {
      \textbf{结构化中间表示 (JSON IR)} \\[2pt]
      \scriptsize\texttt{policy\_mapping / key\_evidence}
  };

  % === 2. 连线逻辑 (显式拐点，杜绝乱线) ===
  
  % [分流路径] Input -> Hard / Mining
  % 逻辑：从 Input 底部向下走 0.5cm，然后水平分叉
  \draw[line] (input.south) -- (0, 3.6) -| (hard.north);
  \draw[line] (input.south) -- (0, 3.6) -| (mining.north);

  % [汇聚路径] Hard / Mining -> Check
  % 逻辑：从左右框底部向下走，汇聚到 (0, 1.0) 这一点，再单线向下
  % 左边路径：先下再右
  \draw[gray!60, thick, rounded corners=3pt] (hard.south) |- (0, 1.0);
  % 右边路径：先下再左
  \draw[gray!60, thick, rounded corners=3pt] (mining.south) |- (0, 1.0);
  % 统一向下箭头
  \draw[line] (0, 1.0) -- (check.north);

  % [垂直路径] Check -> Risk -> Output
  % 直接垂直连接
  \draw[line] (check.south) -- (risk.north);
  \draw[line] (risk.south) -- (output.north);

  % [装饰] 汇聚点的小圆点
  \node[circle, fill=gray!60, inner sep=1.2pt] at (0, 1.0) {};

  \end{tikzpicture}
  \caption{容器级网络行为的推理流程}
  \label{fig:rationality_reasoning_final}
\end{figure}


不同于常规的漏洞扫描工具侧重于“找茬”，本模块的设计目标是解决“可解释性”问题，流程如图\ref{fig:rationality_reasoning_final}。因此，提示词中明确植入了\textbf{“合理性优先（Rationality-First）”}的分析原则：即假设当前运行中的策略是满足业务可用性的，模型的首要任务是挖掘支撑该策略存在的“合法性证据”，仅在发现明显的端口错配或协议冲突时才标记为异常。

该逻辑包含四个递进阶段：
\begin{enumerate}
    \item \textbf{硬性约束扫描}：模型首先提取容器描述文件（Dockerfile/YAML）中显式声明的 \texttt{EXPOSE} 端口与协议，建立基础的网络指纹。
    \item \textbf{多模态证据挖掘}：提示 DeepWiki 深入扫描代码层面的隐式证据（如 Node.js 中的 \texttt{server.listen()}）、环境变量层面的配置证据（如 \texttt{PORT=8080}）以及配置文件中的绑定地址。这一步确保了“没有任何一条规则是凭空臆造的”。
    \item \textbf{覆盖度验证}：将上述证据与 NetworkPolicy 的 Ingress/Egress 规则进行比对。例如，验证策略放行的 TCP 3306 是否确实对应了容器内的 MySQL 进程，并生成自然语言解释：“MySQL 服务器监听 TCP 3306，客户端需通过此端口执行事务”。
    \item \textbf{风险上下文标记}：若发现容器内有未被策略覆盖的高危端口（如开放了 22 端口但策略未放行），模型将在输出中标记潜在的阻塞风险，为后续的聚合分析提供警示。
\end{enumerate}

\subsubsection{结构化中间表示（IR）}


为了支持大规模自动化分析，该环节的输出被严格约束为 JSON 格式的中间表示（Intermediate Representation, IR）。输出结构包含三个核心字段：
\begin{itemize}
    \item \texttt{policy\_mapping}：布尔值的匹配结果与对应的自然语言解释，直接回答“策略是否覆盖了需求”。
    \item \texttt{key\_evidence}：提取的代码片段或配置项列表，作为可追溯的审计证据。
    \item \texttt{pod\_context}：高度凝练的容器网络画像（如“Ingress TCP 8080 + Egress HTTPS API”），用于后续 Pod 级别的上下文聚合。
\end{itemize}

这种标准化的 JSON 输出屏蔽了不同大模型的行文风格差异，使得上层模块能够像处理数据库记录一样处理非结构化的语义解释。

\subsection{Pod 级全局上下文聚合与审计机制}
\label{subsec:pod_aggregation}


Kubernetes 的网络模型以 Pod 为最小调度单元，所有共享同一 Network Namespace 的容器（含初始化容器、Sidecar 代理及业务容器）共同对外呈现统一的 IP 地址与端口视图。然而，4.2.3 节的推理是基于单一容器视角的。为了应对 Sidecar 模式下的复杂流量特征（例如 Istio Proxy 接管流量、Prometheus Exporter 暴露指标），系统需要执行最后一步的全局上下文聚合与最终审计。

系统构建了聚合层提示词（\texttt{pod\_aggregation\_prompt}），将 4.2.3 节输出的所有容器级 JSON 中间表示组装成数组，连同完整的 NetworkPolicy YAML 一并输入大模型。模型被设定为“审计专家（Auditor）”，执行以下三个维度的全局推理：

\subsubsection{多源需求的并集聚合}
首先，模型需要解决“需求碎片化”问题。一个合法的 Pod 级 NetworkPolicy 必须同时覆盖 Pod 内所有容器的通信需求。
\begin{itemize}
    \item \textbf{规则归并}：模型遍历所有容器的 \texttt{container\_summary}，将业务容器的 \texttt{8080/TCP} 与 Sidecar 容器的 \texttt{15020/TCP}（健康检查）合并为统一的 Ingress 需求列表。
    \item \textbf{冲突消解}：若不同容器对同一端口的用途描述存在差异（极少见情况），模型依据代码证据的置信度进行加权，优先采信基于代码显式绑定（如 \texttt{server.listen}）的证据。
\end{itemize}

\subsubsection{基于证据的合规性裁决}
在构建了完整的 Pod 需求视图后，模型对比输入的 NetworkPolicy，进行最终的“Accept/Reject”二元裁决。为了保证工程落地的稳定性，系统在提示词中植入了严格的\textbf{“保守拒绝原则（Conservative Rejection Principle）”}：
\begin{itemize}
    \item \textbf{通过标准（Accept）}：只要策略覆盖了聚合后的所有核心业务端口，且未出现明显的协议冲突（如需求是 UDP 但策略仅允许 TCP），即判定为通过。此时，模型生成的解释报告会综合引用各容器的代码证据（如“Ingress 允许 3306，因为容器 A 的代码中 MySQL 监听了该端口”），形成完整的合理性论述。
    \item \textbf{拒绝标准（Reject）}：仅在发现“阻塞必需流量”或“高危配置冲突”等确凿错误时，才触发拒绝动作。模型必须在 \texttt{修复建议} 字段中输出具体的 YAML 修正片段，并严格遵循最小权限原则，不得臆造不存在的规则。
\end{itemize}

\subsubsection{标准化审计报告生成}
最终，系统将大模型的推理结果格式化为人类可读的 Markdown 报告。该报告包含四个标准板块：\textbf{评估结果}、\textbf{Pod 网络摘要}、\textbf{策略解释}以及\textbf{问题评估/修复建议}。

这种“分层推理（局部容器 $\rightarrow$ 全局 Pod）”的设计，不仅完美适配了 Kubernetes 的 Sidecar 模式，更通过最终的聚合校验，确保了生成的微隔离策略在保障安全的同时，绝对不会破坏复杂微服务架构下的业务可用性。 \cite{KubeGuard2025}。

\section{基于代码上下文的策略正向生成机制}
\label{sec:policy_generation}

通过前两节的阐述，系统已构建了从运行时状态到静态代码仓库的语义映射通道，并实现了对存量 NetworkPolicy 的深度审计与可解释性分析。然而，在零信任架构（Zero Trust Architecture）的完整生命周期中，仅具备“被动审计”能力尚不足以应对云原生应用的高频迭代需求。运维人员更迫切需要解决的是两个“主动治理”难题：一是在服务上线初期，如何在缺乏历史流量数据的情况下，\textbf{正向生成（Forward Generation）} 完备的初始白名单；二是在审计发现违规后，如何实现策略的 \textbf{自适应修复（Adaptive Remediation）}，形成安全运营的闭环。

传统的微隔离策略生成通常依赖于基于流量日志的统计学习方法（Learning-based）。这种方法存在本质的局限性：首先是具有显著的“滞后性”，必须等待业务流量实际发生后才能生成规则，这导致新上线的服务在“学习期”内处于裸奔或全阻断状态；其次是面临“噪声干扰”，难以区分正常的业务调用与恶意扫描流量，容易将攻击行为误学习为合法规则。

为了克服上述缺陷，本节提出了一种“基于代码意图（Intent-based）”的策略生成范式。该机制视源代码为网络行为的“第一性原理”，利用 DeepWiki 引擎从代码逻辑中直接提取确定的通信意图（如监听端口、上游依赖），从而在无流量基线的情况下生成精准的预定义策略，并结合大模型的推理能力实现审计问题的自动化修复。

\subsection{基于代码意图的正向策略生成机制}
\label{subsec:forward_policy_generation}

为了打破传统基于流量学习（Learning-based）方法的滞后性与盲目性，本系统提出了一种基于代码意图（Intent-based）的正向策略生成机制。该机制视源代码与运行时配置为网络行为的“第一性原理”，通过 DeepWiki 引擎执行严格的静态与动态证据挖掘，分别推导微服务的入站（Ingress）服务面与出站（Egress）依赖面，从而在无流量基线的情况下构建“默认安全”的白名单策略。

\begin{table}[htbp]
  \centering
  \caption{流量意图类型与 NetworkPolicy 规则合成逻辑对照表}
  \label{tab:intent_rule_synthesis}
  \resizebox{1.0\textwidth}{!}{
    \begin{tabular}{lp{5cm}p{6cm}}
    \toprule
    \textbf{流量意图类型} & \textbf{DeepWiki 检测逻辑} & \textbf{规则合成逻辑 (Rule Synthesis)} \\
    \midrule
    集群内服务调用 & 识别 K8s Service 名称或内部 DNS 域名 (e.g., \texttt{user-svc}) & 生成 \texttt{podSelector}，匹配目标服务 Labels。自动处理 \texttt{namespaceSelector}。 \\
    \midrule
    集群外 API 访问 & 识别公网域名 (e.g., \texttt{api.stripe.com}) & 解析 DNS 获取 IP 列表，生成 \texttt{ipBlock} (CIDR)。建议配合 Egress Gateway。 \\
    \midrule
    基础设施依赖 & 识别数据库/中间件连接 (e.g., \texttt{jdbc:mysql://...}) & 优先匹配集群内 StatefulSet；若为外部 RDS，则生成固定 IP 白名单。 \\
    \midrule
    基础网络服务 & 识别 DNS 解析请求 (UDP 53) & 自动注入 \texttt{kube-dns} 放行规则 (UDP/TCP 53)。 \\
    \bottomrule
    \end{tabular}
  }
\end{table}

\subsubsection{服务端点挖掘与 Ingress 规则构建}
针对入站流量，系统需要精准识别微服务对外暴露的监听端口。DeepWiki 引擎超越了简单的 Dockerfile \texttt{EXPOSE} 扫描，执行深度的代码逻辑分析：

\begin{itemize}
    \item \textbf{动态绑定识别}：针对 Kafka、Zookeeper 等通过配置动态决定监听地址的组件，系统追踪代码中的配置读取链（如 \texttt{config.get("listeners")}），结合 4.1.3 节采集的运行时配置值，解析出实际生效的端口集合，避免因默认值与实际配置不一致导致的策略漏配。
    \item \textbf{应用层 ACL 下沉}：若代码中存在硬编码的 IP 白名单检查（如 \texttt{if remote\_addr in allowed\_cidrs}），系统将这些应用层约束自动转化为 NetworkPolicy 中的 \texttt{ipBlock} 规则，实现安全能力的下沉。
\end{itemize}

\subsubsection{服务依赖拓扑与 Egress 规则构建}
针对出站流量，系统设计了专用的依赖分析提示词（\texttt{container\_egress\_prompt}），引导 DeepWiki 扮演“代码审计专家”角色，执行严格的证据驱动（Evidence-based）依赖提取。

该过程遵循“禁止假设”原则，仅在发现确凿证据时才生成规则，具体包含三个分析维度：

\begin{enumerate}
    \item \textbf{多源客户端调用扫描}：
    系统深入分析代码中的网络客户端库调用模式，涵盖数据库连接（如 \texttt{mysql.connect()}）、HTTP 请求（如 \texttt{axios.get()}）、RPC 调用（如 \texttt{grpc.Dial()}）以及中间件交互（如 \texttt{kafka.Producer()}）。通过解析函数参数，提取目标服务的连接特征。

    \item \textbf{环境与配置的语义对齐}：
    系统扫描环境变量（如 \texttt{DATABASE\_URL}）与配置文件（如 \texttt{application.yml}），解析其中的主机名、端口与协议。DeepWiki 能够智能区分“服务监听端口”（Ingress）与“客户端目标端口”（Egress），防止规则方向混淆。

    \item \textbf{内外部服务类型分类}：
    为了生成精确的 Kubernetes 选择器，系统对提取的目标地址进行分类处理：
    \begin{itemize}
        \item \textbf{集群内服务}：识别 \texttt{.svc.cluster.local} 后缀或短服务名（如 \texttt{redis}）。系统将其解析为对应的 \texttt{namespaceSelector} 和 \texttt{podSelector}，确保策略随 Pod 漂移自动适应。
        \item \textbf{外部服务}：识别公网域名或 IP 地址。系统结合 DNS 解析结果，生成指向特定 CIDR 的 \texttt{ipBlock} 规则，并建议开启 egress 域名白名单（如结合 Istio ServiceEntry）。
    \end{itemize}
\end{enumerate}

\subsubsection{证据链构建与策略合成}
为了保证自动生成策略的可审计性，系统要求 DeepWiki 输出严格的 JSON 格式证据链（Evidence Chain）。对于每一个生成的网络规则，系统都附带了以下元数据：
\begin{itemize}
    \item \textbf{代码证据}：具体的函数调用行号或配置项路径（例如：\texttt{env: MYSQL\_HOST=10.0.1.5}）。
    \item \textbf{业务目的}：基于代码上下文推断的流量用途（如“用户数据持久化”或“第三方支付 API 调用”）。
\end{itemize}

最终，系统将上述 Ingress 与 Egress 需求合并，转换为标准的 Kubernetes NetworkPolicy YAML 文件。这种机制确保了每一条生成的规则都有据可查，既实现了最小权限控制，又彻底消除了运维人员对“黑盒”自动生成规则的信任危机。

\subsection{基于 DeepWiki 的自适应策略生成与验证}
\label{subsec:adaptive_policy_generation}

在完成正向的意图提取后，系统的最后一步是将这些半结构化的依赖数据转化为标准、可执行且严谨的 Kubernetes NetworkPolicy 资源对象。为了确保生成策略的精确性并杜绝大模型的“幻觉”风险，系统设计了基于 DeepWiki 的自适应生成流水线。

该流水线包含三个核心处理阶段，严格遵循“无证据不生成（No Evidence, No Rule）”的原则。

\subsubsection{服务选择器的确定性锚定}

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[
      scale=0.9, transform shape,
      font=\sffamily\small,
      >=Stealth,
      % --- 样式定义 ---
      % 1. 基础容器风格 (统一圆角与阴影)
      basic box/.style={
          rectangle,
          draw=gray!40,
          rounded corners=2pt,
          align=center,
          drop shadow={opacity=0.08, shadow xshift=1pt, shadow yshift=-1pt},
          line width=0.8pt,
          inner sep=5pt
      },
      % 2. 输入层 (顶部)
      input box/.style={
          basic box,
          text width=5.0cm,
          minimum height=1.2cm,
          fill=white,
          draw=gray!50
      },
      % 3. 核心引擎层 (中间 - 宽体设计)
      core box/.style={
          basic box,
          draw=orange!50,
          fill=orange!5,
          text width=8.5cm,  % 宽体，涵盖上方两个输入
          minimum height=1.4cm,
          inner sep=6pt
      },
      % 4. 输出层 (底部)
      output box/.style={
          basic box,
          text width=5.0cm,
          minimum height=1.4cm
      },
      % 连线样式
      line/.style={->, draw=gray!60, thick, rounded corners=2pt},
      % 标签样式
      label text/.style={font=\tiny\bfseries, text=gray!50, fill=white, inner sep=1.5pt}
  ]

  % === 1. 输入层 (Input Layer) ===
  % 左输入
  \node[input box, draw=violet!50] (intent) at (-3.0, 2.4) {
      \textbf{代码意图 (Intent)} \\[-1pt]
      \rule{0pt}{9pt}
      \scriptsize\texttt{"target: redis-cart"}
  };

  % 右输入
  \node[input box, draw=blue!50] (anchor) at (3.0, 2.4) {
      \textbf{集群元数据 (Anchor)} \\[-1pt]
      \rule{0pt}{9pt}
      \scriptsize\texttt{Service Exists?}
  };

  % === 2. 处理核心层 (Processing Layer) ===
  \node[core box] (engine) at (0, 0) {
      \textbf{确定性锚定引擎 (Deterministic Matcher)} \\[-1pt]
    %   \textcolor{orange!20}{\rule{8.0cm}{0.5pt}} \\[3pt]
      \scriptsize $\bullet$ 实时查询 K8s Service/Endpoints API \quad $\bullet$ 校验标签选择器有效性
  };

  % === 3. 输出层 (Output Layer) ===
  % 左输出：成功
  \node[output box, draw=green!50!black, fill=green!5] (success) at (-3.0, -2.4) {
      \textbf{\textcolor{green!40!black}{锚定成功}} \\[-1pt]
    %   \textcolor{gray!20}{\rule{4.5cm}{0.5pt}} \\[2pt]
      \scriptsize\texttt{podSelector: \{app:cart\}}
  };

  % 右输出：失败
  \node[output box, draw=red!50!black, fill=red!5] (fail) at (3.0, -2.4) {
      \textbf{\textcolor{red!40!black}{熔断保护}} \\[-1pt]
    %   \textcolor{gray!20}{\rule{4.5cm}{0.5pt}} \\[2pt]
      \scriptsize 跳过生成 (Skipped Generation)
  };

  % === 连线逻辑 (架构图风格 - 垂直入，垂直出) ===
  
  % Inputs -> Engine
  % 使用正交连线：从输入框底部出来，先向下，再水平对齐到引擎的对应接口位置
  \draw[line] (intent.south) -- ++(0,-0.4) -| ([xshift=-2.0cm]engine.north);
  \draw[line] (anchor.south) -- ++(0,-0.4) -| ([xshift=2.0cm]engine.north);

  % Engine -> Outputs
  % 从引擎底部对应位置出来，直接向下进入输出框
  \draw[line] ([xshift=-2.0cm]engine.south) -- ++(0,-0.4) -| (success.north)
      node[pos=0.25, above, label text] {匹配成功};

  \draw[line] ([xshift=2.0cm]engine.south) -- ++(0,-0.4) -| (fail.north)
      node[pos=0.25, above, label text] {服务缺失};

  \end{tikzpicture}
  \caption{确定性锚定与熔断机制}
  \label{fig:deterministic_anchoring_arch}
\end{figure}


NetworkPolicy 的核心机制是基于标签选择器（Label Selector）的流量控制。因此，将代码中的服务名（如 \texttt{redis-cart}）映射为集群内的 Pod 标签是生成过程的关键。

系统摒弃了传统的模糊匹配算法，转而采用\textbf{确定性锚定机制}，如图 \ref{fig:deterministic_anchoring_arch}：
\begin{itemize}
    \item \textbf{集群元数据关联}：DeepWiki 引擎在解析代码依赖的同时，会实时查询 Kubernetes 的 Service 和 Endpoints API。只有当代码中的目标服务名（target\_service）能够精确匹配到集群中存在的 Service 对象，且该 Service 关联了有效的 \texttt{matchLabels} 时，系统才会生成对应的 \texttt{podSelector} 规则。
    \item \textbf{空值熔断保护}：若 DeepWiki 无法在当前集群中找到目标服务的标签元数据（即 \texttt{service\_selector\_labels} 为空），生成器将触发“熔断”机制。系统会拒绝生成基于猜测的规则，并在策略说明报告中明确标记“因元数据缺失跳过生成”，从而防止因错误的标签匹配导致生产环境流量误拦截。
\end{itemize}

\subsubsection{基于证据的规则合成}

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[
      scale=0.9, transform shape, % 整体缩放 90%
      font=\sffamily\small,       % 全局字体
      >=Stealth,
      % --- 样式定义 ---
      % 基础盒子：增加 inner sep 让文字不贴边，显得更高级
      basic box/.style={
          rectangle,
          draw=gray!40,
          fill=white,
          rounded corners=3pt,
          align=center,
          drop shadow={opacity=0.08, shadow xshift=1pt, shadow yshift=-1pt},
          inner sep=6pt,
          line width=0.8pt
      },
      % 1. 顶部输入
      input box/.style={
          basic box,
          draw=violet!50,
          fill=violet!5,
          text width=7.5cm,
          font=\bfseries
      },
      % 2. 中间处理：关键优化
      process box/.style={
          basic box,
          draw=orange!50,
          fill=white,
          text width=4.0cm, % 固定宽度，确保左右对称
          inner sep=8pt,    % 增加内部留白，优化排版
          font=\small
      },
      % 3. 底部输出
      output box/.style={
          basic box,
          draw=blue!50,
          fill=blue!5,
          text width=7.5cm,
          font=\bfseries
      },
      % 连线样式
      line/.style={->, draw=gray!60, thick, rounded corners=4pt},
      % 标签样式
      label text/.style={font=\scriptsize\bfseries, text=gray!60, fill=white, inner sep=3pt}
  ]

  % === 1. 顶部：输入依赖 ===
  \node[input box] (root) at (0, 3.2) {
      代码依赖证据 (Evidence) \\[3pt]
      \normalfont\scriptsize\texttt{target: "mysql" / "api.stripe.com"}
  };

  % === 2. 中间：分流处理 (精修内部排版) ===
  
  % 左分支：集群内
  \node[process box] (internal) at (-3.8, 0) {
      \textbf{集群内流量 } \\[2pt]
    %   \scriptsize\texttt{is\_external: false} \\[4pt]
      % 分割线
      \textcolor{gray!20}{\rule{3.8cm}{0.6pt}} \\[4pt]
      解析 Service 元数据 \\[2pt]
      \textcolor{gray!50}{$\downarrow$} \\[2pt]
      \textbf{\textcolor{orange!60!black}{namespaceSelector}} \\
      \textbf{\textcolor{orange!60!black}{+ podSelector}}
  };

  % 右分支：集群外
  \node[process box] (external) at (3.8, 0) {
      \textbf{集群外流量} \\[2pt]
    %   \scriptsize\texttt{is\_external: true} \\[4pt]
      % 分割线
      \textcolor{gray!20}{\rule{3.8cm}{0.6pt}} \\[4pt]
      DNS 解析 / IP 归属计算 \\[2pt]
      \textcolor{gray!50}{$\downarrow$} \\[2pt]
      \textbf{\textcolor{orange!60!black}{ipBlock (CIDR)}}
  };

  % === 3. 底部：规则合成 ===
  \node[output box] (sink) at (0, -3.2) {
      合成策略 (Egress Rules) \\[3pt]
      \normalfont\scriptsize\texttt{- to: [Selectors] ...} \quad \texttt{- to: [IPBlocks] ...}
  };

  % === 连线逻辑 (直角折线) ===
  
  % 顶部向下分发
  \draw[line] (root.south) -- (0, 2.0) -| (internal.north);
  \draw[line] (root.south) -- (0, 2.0) -| (external.north);
  
  % 分类判定标签
  \node[label text] at (0, 2.0) {类型判定};

  % 底部汇聚
  \draw[line] (internal.south) |- (0, -1.8) -- (sink.north);
  \draw[line] (external.south) |- (0, -1.8) -- (sink.north);

  % 聚合符号 (U) - 放在连线交汇处
  \node[circle, fill=white, draw=gray!40, inner sep=1.5pt] at (0, -1.8) {\scriptsize $\cup$};

  \end{tikzpicture}
  \caption{基于证据的规则合成流程}
  \label{fig:rule_final}
\end{figure}

针对网络规则的合成，如图\ref{fig:rule_final}，系统执行严格的分类处理逻辑，确保每一行 YAML 均有代码级证据支撑：

\begin{enumerate}
    \item \textbf{集群内流量（East-West Traffic）}：
    对于标记为 \texttt{is\_external: false} 的内部服务依赖，生成器构建 \texttt{namespaceSelector} + \texttt{podSelector} 的组合规则。
    \begin{itemize}
        \item \textbf{跨命名空间访问}：若目标服务位于不同 Namespace（如 \texttt{mysql.default}），系统自动解析目标命名空间的元数据标签（如 \texttt{kubernetes.io/metadata.name: default}），确保跨域访问的连通性。
    \end{itemize}

    \item \textbf{集群外流量（North-South Traffic）}：
    对于标记为 \texttt{is\_external: true} 的公网依赖（如第三方 API），生成器优先尝试解析目标域名的 DNS 记录，生成精确的 \texttt{ipBlock} CIDR 规则。
    \begin{itemize}
        \item \textbf{安全兜底}：若目标为动态 IP（如 CDN），系统生成带注释的 \texttt{0.0.0.0/0} 规则，并强制排除内部私有网段（\texttt{10.0.0.0/8} 等），防止因配置疏忽导致的内部网络暴露风险。
    \end{itemize}
\end{enumerate}

\subsubsection{零信任兜底与策略说明}
在生成最终 YAML 文件的同时，系统会自动附带一份详细的\textbf{策略生成说明书（Policy Manifest）}。
\begin{itemize}
    \item \textbf{默认拒绝原则}：若代码分析结果显示某容器无任何出站依赖（\texttt{egress\_requirements} 为空），系统将生成仅包含 \texttt{policyTypes: [Egress]} 但 \texttt{egress: []} 为空的策略对象，实现对该 Pod 的完全网络隔离。
    \item \textbf{风险可视化}：说明书详细列出了每条规则的“证据来源（Evidence）”、“使用频率（Frequency）”及“风险等级”，使安全管理员在应用策略前能够对潜在风险一目了然。
\end{itemize}

通过这一机制，系统实现了从“代码意图”到“基础设施即代码（IaC）”的自动化闭环，确保了微隔离策略在全生命周期内的准确性与合规性。


\section{本章小结}

本章详细论述了基于代码上下文的零信任微隔离策略生成技术。针对云原生环境下的语义缺失难题，本章首先利用大模型推理运行时指纹，建立了运行时容器与静态代码仓库的精准关联；进而通过 DeepWiki 引擎挖掘代码中的业务意图，实现了网络策略的逆向语义解释；最后提出了基于代码逻辑与配置解析的策略生成算法，通过将静态代码分析与动态配置数据相结合，在不依赖流量基线的情况下，生成了兼顾最小权限原则与长尾业务覆盖的自适应微隔离策略，有效解决了现有技术在准确性与可解释性方面的不足。





\chapter{实验与分析}
\label{chap:experiment}

\section{5.1 实验环境构建}

\subsection{5.1.1 硬件环境}
本研究的实验验证体系构建于三个Kubernetes 集群之上。通过构建多个集群，本文旨在模拟企业级生产环境中复杂的集群服务发现、动态容器动态及大规模节点下的安全策略下发场景，从而验证微隔离策略生成框架的正确性与自适应能力。


实验环境的具体节点角色与硬件配置参数如表 5-1 所示：

\begin{table}[htbp]
\centering
\caption{实验环境多集群硬件配置表}
\label{tab:cluster_env}
\begin{tabular}{lccccc}
\toprule
集群编号 & 主机名称 & 节点角色 & 主机 IP & CPU 配置 & 内存容量 \\
\midrule
集群 A & master-A & 控制平面 & 192.168.4.143 & 16 核心 & 30 GB \\
集群 B & master-B & 控制平面 & 192.168.4.135 & 8 核心 & 32 GB \\
集群 C & master-C & 核心控制 & 192.168.7.145 & 4 核心 (2.1 GHz) & 16 GB \\
集群 C & node-C & 核心计算 & 192.168.7.146 & 4 核心 (4.2 GHz) & 16 GB \\
\bottomrule
\end{tabular}
\end{table}


\subsection{5.1.2 软件环境}
实验集群统一采用 CentOS 7 操作系统，底层计算资源通过 VMware Workstation 与 vSphere 虚拟化平台进行编排。为了实现深度的流量感知与细粒度的策略执行，集群内部署了 Calico 网络插件，支持标准的 NetworkPolicy 声明式语法。

系统关键软件栈及其在实验中的具体职能定义如表 5-2 所示：

\begin{table}[htbp]
\centering
\caption{实验环境软件系统版本及用途}
\label{tab:software_env}
\begin{tabular}{lll}
\toprule
软件名称 & 版本 / 技术路径 & 实验用途 \\
\midrule
Kubernetes & v1.23 & 提供基础编排能力与策略下发接口 \\
Calico & v3.21 & 负责流量阻断 \\
Soot & v4.6 & 对 Java 项目进行字节码分析 \\
DeepWiki & 仓库级挖掘框架 & 构建代码知识与语义关联 \\
LLM APIs & GPT-4o / Deepseek-R1 / Claude-Sonnet-4.5 & 策略逻辑校核、意图推理与生成 \\
\bottomrule
\end{tabular}
\end{table}



\section{基于动静态协同分析的策略生成实验}
\label{sec:deterministic_eval}

本节旨在量化评估动静态协同分析引擎在真实微服务项目中的依赖提取能力与策略生成准确性。实验的核心目标是验证该引擎能否在涵盖 Spring Cloud、Dubbo 等多重技术栈的复杂工程中，精准还原服务间的调用拓扑，并据此生成完备的微隔离策略。

\subsection{数据集定义}
\label{sec:dataset}


为了全面评估动静态协同分析引擎在复杂微服务架构下的依赖提取精度与策略生成能力，本实验构建了一套涵盖主流技术栈的测试数据集。

\begin{enumerate}
    \item \textbf{数据集选取与权威性}：
    选取了 16 个在 GitHub 及 Gitee 社区具有高度认可度的开源微服务项目，涵盖了企业级 ERP（$Yudao-Cloud$）、分布式电商（$Mall-Swarm$）、RPC 中间件（$Alibaba-Demo$）以及非标动态路由场景（$Killbug$）等核心领域。这些项目的 GitHub Star 数普遍处于 100 至 2k 之间，代表了当前云原生生产环境中主流架构的各种实践，确保了实验结果对工业界存量系统的参考价值。

    \item \textbf{样本构建与规模}：
    针对上述项目涉及的近 100个微服务单元（Pod），本实验进行了全量静态扫描与特征提取。为了构建可靠的审计基准，我们采用“人工代码审查 + 运行时流量对账”相结合的方式，手动标注了所有服务间的 API 调用链与 RPC 依赖关系，形成了包含完整拓扑真值的基准测试集，以此作为衡量分析引擎覆盖率（Coverage）的标准答案。
\end{enumerate}

表 \ref{tab:project_dataset_pods} 详细列出了这 16 个核心测试项目。


\begin{table}[htbp]
  \centering
  \caption{实验项目集：业务场景与部署规模统计}
  \label{tab:project_dataset_pods}
  \small
  \begin{tabular}{c l c l}
  \toprule
  \textbf{序号} & \textbf{项目名称} & \textbf{运行的服务数量} & \textbf{业务类型与特征备注} \\
  
  1 & RuoYi-Cloud & 9 & 商业级后台管理  \\
  2 & Yudao-Cloud & 12 & 模块化 ERP 系统  \\
  3 & Alibaba-Demo & 5 & Dubbo RPC 官方示例  \\
  4 & SC-Huawei & 4 & 华为云架构示例  \\
  5 & vhr & 6 & 人力资源系统 \\
  6 & PaasCloud & 9 & 电商 PaaS 平台  \\
  
  7 & Online-Boutique & 11 & 云原生微服务标杆  \\
  8 & Reactive-Shopping & 5 & 响应式商城 Demo  \\

  9 & Micro-Scaffold & 6 & 开发脚手架 \\
  10 & Cloud-Platform & 8 & 统一网关平台  \\
  11 & PiggyMetrics & 5 & 个人理财系统  \\
  12 & Mall-Swarm & 7 & 容器化电商  \\
  
%   13 & Seata-Samples & 4 & 分布式事务演示 \\
  13 & NewBee-Mall & 7 & 轻量级商城  \\
  14 & JNPF-Cloud & 6 & 低代码平台  \\
 
  15 & Killbug & 3 & 缺陷管理 \\
  \bottomrule
  \end{tabular}
\end{table}



\subsection{实验结果统计与性能分析}

\subsubsection{实验结果统计}

我们将动静态协同分析引擎应用于上述数据集，统计其提取到的依赖关系数量，并与真值矩阵 $M_{GT}$ 进行比对。实验定义策略覆盖率（Policy Coverage, PC）为核心评价指标，计算公式为：
\begin{equation}
    PC = \frac{|E_{extracted} \cap E_{GT}|}{|E_{GT}|} \times 100\%
\end{equation}
其中 $E_{extracted}$ 为系统自动生成的策略集合，$E_{GT}$ 为人工审计的真值集合。

\begin{table}[htbp]
  \centering
  \caption{动静态协同分析引擎在开源微服务项目上的测试结果统计}
  \label{tab:static_results_detail}
  % 使用 small 字号，配合 p{宽度} 自动换行，避免使用 resizebox 导致字体变形
  \small 
  \begin{tabular}{c l l c p{3.5cm} c}
  \toprule
  \textbf{序号} & \textbf{项目名称} & \textbf{核心技术栈} & \textbf{LOC} & \textbf{提取特征类型} & \textbf{覆盖率} \\
  \midrule
  1 & RuoYi-Cloud & Spring Cloud & 85k+ & Feign / RestTemplate & 100\% \\
  2 & Yudao-Cloud & SC Alibaba & 120k+ & Feign / RPC & 100\% \\
  3 & Alibaba-Demo & Dubbo / Nacos & 15k+ & Dubbo RPC 接口 & 100\% \\
  4 & SC-Huawei & Spring Cloud & 12k+ & 注解驱动接口 & 100\% \\
  5 & vhr & Spring Boot & 45k+ & 模块化内部接口 & 100\% \\
  6 & PaasCloud & Spring Cloud & 68k+ & 动态服务发现 & 100\% \\
  
  % 多语言混合 (失败案例) ---
  7 & Online-Boutique & Go / Java & 19k+ & \raggedright 跨语言 gRPC 调用 & 0.0\% \\
  
  % 响应式编程 (低分案例) ---
  8 & Reactive-shopping & WebFlux & 8k+ & \raggedright 异步响应式流 & 13.6\% \\
  
  9 & Micro-Scaffold & Sentinel & 18k+ & 认证调用链 & 100\% \\
  10 & Cloud-Platform & Spring Cloud & 55k+ & 网关聚合接口 & 100\% \\
  11 & PiggyMetrics & Spring Cloud & 32k+ & 分布式统计 & 100\% \\
  12 & Mall-Swarm & Spring Cloud & 41k+ & 订单库存对接 & 100\% \\
  
  % 复杂代理 (低分案例) ---
%   13 & Seata-Samples & Seata / TCC & 9k+ & \raggedright 事务代理拦截 & 28.6\% \\
  
  13 & NewBee-Mall & Spring Cloud & 28k+ & 组件通信 & 100\% \\
  14 & JNPF-Cloud & SC Alibaba & 35k+ & 低代码依赖 & 100\% \\
  15 & Killbug & React / Boot & 5k+ & \raggedright Dubbo RPC 接口 & 100\% \\     
  
  \bottomrule
  \end{tabular}
\end{table}

基于表 \ref{tab:static_results_detail} 的实验统计数据，本系统在 15 个测试项目中取得了 13 个 100\% 覆盖 的优异成绩。

\subsubsection{性能分析}

在云原生架构下，系统的部署与更新均以 Pod（容器组） 为最小单元。因此，评估静态分析引擎效能的关键指标并非整个代码仓库的总耗时，而是针对单个微服务单元（Per-Pod）的扫描效率。这直接决定了系统能否在 Pod 扩容或重启的瞬间完成“即时分析”。

图 \ref{fig:analysis_time_per_pod} 统计了实验中不同功能类型的微服务 Pod 的平均分析耗时。

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[
      scale=0.9,
      font=\small,
      >=Stealth,
      axis/.style={->, thick, draw=gray!60},
      bar/.style={ybar, fill=blue!60, draw=blue!40, line width=0.8pt, bar width=0.8cm},
      grid line/.style={draw=gray!20, dashed},
      avg line/.style={draw=red!70, thick, dashed}
  ]

  % 坐标轴
  \draw[axis] (0,0) -- (11,0) node[right] {微服务};
  \draw[axis] (0,0) -- (0,5.0) node[above] {分析耗时 (s)};

  % Y轴刻度
  \foreach \y in {2, 4, 6, 8, 10, 12, 14} {
      \draw[grid line] (0, \y/3) -- (11, \y/3);
      \draw (0, \y/3) -- (-0.1, \y/3) node[left, font=\scriptsize] {\y};
  }

  % 数据绘制 (围绕 9.8s 波动)
  % 1. Gateway (轻量) -> 8.5s
  \draw[bar] (1.0, 0) rectangle (1.8, 7.5/3);
  \node[below, font=\scriptsize] at (1.4, 0) {Alibaba-Demo};
  \node[above, font=\scriptsize] at (1.4, 7.5/3) {7.5s};

  % 2. Auth (中等) -> 9.2s
  \draw[bar] (3.0, 0) rectangle (3.8, 9.5/3);
  \node[below, font=\scriptsize] at (3.4, 0) {JNPF-Cloud};
  \node[above, font=\scriptsize] at (3.4, 9.5/3) {9.5s};

  % 3. User (业务) -> 10.5s
  \draw[bar] (5.0, 0) rectangle (5.8, 10.5/3);
  \node[below, font=\scriptsize] at (5.4, 0) {YuDao};
  \node[above, font=\scriptsize] at (5.4, 10.5/3) {10.5s};

  % 4. Order (复杂业务) -> 11.1s
  \draw[bar] (7.0, 0) rectangle (7.8, 10.8/3);
  \node[below, font=\scriptsize] at (7.4, 0) {Ruo-yi};
  \node[above, font=\scriptsize] at (7.4, 10.8/3) {10.8s};

  % 5. Killbug/Other -> 9.7s
  \draw[bar] (9.0, 0) rectangle (9.8, 9.7/3);
  \node[below, font=\scriptsize] at (9.4, 0) {Killbug};
  \node[above, font=\scriptsize] at (9.4, 9.7/3) {9.7s};

  % 均值线 (9.8s)
  \draw[avg line] (0, 9.8/3) -- (11, 9.8/3);
  \node[right, text=red!70, font=\scriptsize\bfseries] at (11, 9.8/3) {Avg $\approx$ 9.8s};

%   % 结论框
%   \node[draw=gray!40, fill=white, rounded corners=2pt, font=\scriptsize, align=left] at (6.0, 4.2) {
%       \textbf{时效性特征:}\\
%       分析粒度: Per-Pod\\
%       平均耗时: \textbf{9.8 秒}\\
%       支持 K8s 并行扫描
%   };

  \end{tikzpicture}
  \caption{针对不同项目的微服务单元 (Pod) 平均耗时统计举例}
  \label{fig:analysis_time_per_pod}
\end{figure}

如图 \ref{fig:analysis_time_per_pod} 所示，尽管不同微服务的业务复杂度（LOC）存在差异，但本系统针对单个 Pod 的分析耗时呈现出极高的稳定性，平均值稳定在 9.8 秒 左右。

这一数据的工程意义在于：
\begin{itemize}
    \item \textbf{并行扩展能力}：在 Kubernetes 环境中，多个 Pod 的启动是并行的。由于本系统的分析粒度下沉至 Pod 级别，这意味着即便面对包含 100+ 微服务的超大型系统，整体拓扑生成的延迟仅取决于最慢的那个 Pod（约 11s），而不会随服务数量线性累积。
    \item \textbf{符合启动时延要求}：在典型的 Java 微服务冷启动流程中（JVM 启动 + Spring Context 初始化通常需 15-30s），9.8s 的静态分析可以完全并行嵌入其中，实现 “无感知的安全扫描”，不会拖慢服务的上线发布时间。
\end{itemize}


\subsection{实验分析}
\label{sec:result_analysis_evaluation}


\subsubsection{Java 微服务生态的适配性}

实验结果表明，本系统在 JVM 语言体系下的微服务架构中具有极高的普适性。无论是标准的 Spring Cloud/Dubbo 架构，还是包含非标特性的动态场景，系统均实现了全量特征提取。

\begin{itemize}
    \item 标准架构支持：对于 RuoYi-Cloud、Yudao-Cloud 等采用主流技术栈（OpenFeign, RestTemplate, Dubbo RPC）的大型商业级项目，系统能够精准构建完整的服务调用图谱，且不受代码规模（LOC > 100k）影响。
    \item 动态配置解析能力：针对 Killbug、PaasCloud 等项目中存在的 动态配置注入或 非硬编码路由 现象，本系统通过增强的静态配置文件解析与常量传播算法，成功还原了运行时的服务地址。这证明了在不引入外部推理机制的情况下，通过深度静态分析足以解决 Java 环境内绝大多数的动态路由与配置解耦难题。
\end{itemize}

\subsubsection{技术边界与失效场景归因}

尽管系统在 Java 领域表现稳健，但对照组实验（序号 7, 8, 13）清晰地界定了当前基于字节码分析技术的物理边界：

\begin{enumerate}
    \item 跨语言鸿沟（0\%）：
    在 Online-Boutique 项目中，系统无法追踪由 Java 服务向 Go 或 Node.js 服务发起的 gRPC 调用。这是由于静态分析引擎无法跨越 JVM 运行时边界，导致异构语言间的链路完全断裂。
    
    \item 异步流离散化（13.6\%）：
    在 Reactive-Shopping 项目中，Spring WebFlux 的响应式编程模型（Reactive Programming）成为分析痛点。基于 Reactor 的 Lambda 回调链破坏了控制流图（CFG）的连续性，使得传统的污点分析算法难以追踪异步上下文中的数据流向。
    
    % \item \textbf{中间件代理屏蔽（28.6\%）}：
    % 在 \textbf{Seata-Samples} 中，分布式事务中间件通过动态代理（Dynamic Proxy）接管了底层通信。静态分析仅能识别到代理对象，无法穿透框架层获取背后的真实业务依赖。
\end{enumerate}




\section{大模型逆向解释与审计实验}

\subsection{数据集定义}


为了进一步验证大模型（LLM）在复杂语义环境及多语言异构架构下的策略审计与逆向解释能力，本实验构建了一套包含“云原生基础设施组件”与“异构微服务标杆”的混合测试数据集。

\begin{table}[htbp]
  \centering
  \caption{实验项目集：业务场景与部署规模统计}
  \label{tab:services_extended}
  \small
  \begin{tabular}{c l c p{7.5cm}}
  \toprule
  \textbf{序号} & \textbf{应用系统} & \textbf{运行的服务数量} & \textbf{业务类型与架构特征说明} \\
  \midrule
  1 & Airflow & 5 & Apache 分布式工作流调度平台 \\
  2 & Devlake & 7 & 研发效能数据聚合与分析平台 \\
  3 & TiDB & 8 & 兼容 MySQL 协议的分布式 HTAP 数据库 \\
  4 & Druid & 10 & 实时大数据分析数据库 \\
  5 & Pinot & 5 & 实时分布式 OLAP 数据存储 \\
  6 & JupyterHub & 7 & 多用户交互式计算环境 \\
  7 & RuoYi-Cloud & 9 & 基于 Spring Cloud 的商业级后台管理系统 \\
  8 & Yudao-Cloud & 12 & 模块化、多租户的数字化转型 ERP 系统 \\
  9 & Reactive-Shopping & 5 & 基于响应式编程 (Reactive) 的商城 Demo \\ 
  10 & Killbug & 3 & 极简架构的缺陷管理系统 (非标定义) \\
  11 & Online-Boutique & 11 & Google 云原生微服务标杆示例 (gRPC) \\
  12 & Bank of Anthos & 7 & Google 模拟金融交易系统 (Ledger/Balance) \\
  13 & Microservices-K8s & 4 & 影院购票系统 (Luke-Micro, 非标 YAML) \\
  14 & Robot Shop & 10 & Instana 提供的多语言 AI 观测性演示商城 \\
  15 & eShopOnContainers & 9 & Microsoft 官方 .NET Core 微服务架构参考 \\
  16 & Sock Shop & 8 & 经典的容器化微服务电商 Demo \\
  \bottomrule
  \end{tabular}
\end{table}

\begin{enumerate}
    \item \textbf{数据集选取与权威性（Popularity）}：
    选取了 16 个在 GitHub 社区具有高度认可度的开源项目。该数据集由三部分组成：一是涵盖分布式数据库（$TiDB$）、工作流调度（$Airflow$）等核心基础设施组件；二是包含 $Online-Boutique$、$RuoYi-Cloud$等之前由动静态分析系统实验中表现不佳或者优异的JAVA系统， 三是如$Bank of Anthos$， $eShopOnContainers$ 等业界公认的多语言微服务标杆。这些项目的 GitHub Star 数普遍处于 1k 至 50k 之间（如 $Airflow$ 达 43.6k，$eShopOnContainers$ 达 26k），代表了当前云原生生产环境中最复杂的架构形态与多语言（Polyglot）交互模式，确保了实验结果对工业界大规模异构集群治理的参考价值。

    \item \textbf{样本构建与规模}：
    针对上述 16 个项目涉及的微服务场景，本实验通过解析原始文档及YAML配置文件，生成了 140 条正确的 $NetworkPolicy$ 基准。在此基础上，通过人工注入端口错配（Port Mismatch）、协议冲突（Protocol Conflict）及标签选择器偏移（Label Skew）等逻辑错误，额外生成了 140 条对应的负样本策略。最终形成包含 \textbf{280} 条正负样本的审计基准库，所有样本均经过人工复核以确立真值（Ground Truth）。
\end{enumerate}

表 \ref{tab:services_extended} 详细列出了这 16 个测试对象的业务类型与服务规模统计。



\subsection{实验结果统计与性能分析}
\label{subsec:audit_results_analysis}

为了全面评估不同大模型在微服务策略审计任务中的表现，本实验将评价维度拆分为**准确性（Accuracy）**与**效能成本（Performance \& Cost）**两个方面进行独立统计。实验选取了 GPT-4o、DeepSeek Reasoner (R1) 以及 Claude-Sonnet-4.5 三款代表性模型，在包含 280 条正负样本的基准数据集上进行了全量测试。

\subsubsection{审计准确性统计}

准确性是安全审计系统的核心生命线，尤其是假阳性率（FPR），直接决定了运维人员对系统的信任度。各模型在真阳性率（TPR）与假阳性率（FPR）上的表现如表~\ref{tab:audit_accuracy} 所示。

\begin{table}[htbp]
\centering
\caption{不同模型在策略审计任务中的准确性指标对比}
\label{tab:audit_accuracy}
\resizebox{0.85\linewidth}{!}{
    \begin{tabular}{l c c}
    \toprule
    模型名称 & 真阳性率 (TPR) & 假阳性率 (FPR) \\
    \midrule
    GPT-4o & 98.6\% & 0.7\% \\
    DeepSeek Reasoner (R1) & 98.6\% & 0.0\% \\
    Claude-Sonnet-4.5 & 100.0\% & 0.0\% \\
    \bottomrule
    \end{tabular}
}
\end{table}

实验数据显示，Claude-Sonnet-4.5 实现了完美的审计结果**（TPR 100\% / FPR 0.0\%），成功识别了所有潜在的逻辑漏洞且无一误报。DeepSeek R1 同样表现优异，凭借思维链推理能力实现了 **0.0\% 的零误报率**，仅在极个别隐晦漏洞上存在漏报。相比之下，GPT-4o 虽然检出率很高，但存在 0.7\% 的误报率，通过回溯错误样本，我们发现其主要失效模式为**“为了自圆其说而产生的数值幻觉”，例如原始容器声明了监听端口 9091，而 NetworkPolicy 错误地放行了 8091。面对这一明显的逻辑错误，GPT-4o 却给出了“通过”的结论。


\subsubsection{性能消耗与成本效益评估}

除了准确性，大规模审计任务的执行效率与经济成本也是工程落地的关键考量。表~\ref{tab:audit_performance} 详细统计了各模型处理单条策略的平均耗时、Token 消耗量及对应的资金成本。

\begin{table}[htbp]
\centering
\caption{不同模型在单条策略审计任务中的性能消耗与成本评估}
\label{tab:audit_performance}
\resizebox{\textwidth}{!}{
    \begin{tabular}{l c c c c}
    \toprule
    模型名称 & 平均耗时 (s) & 平均输入 (Tokens) & 平均输出 (Tokens) & 平均成本 (\$/条) \\
    \midrule
    GPT-4o & 133.63 & 3,128.6 & 198.9 & 0.0098 \\
    DeepSeek Reasoner (R1) & 294.68 & 3,242.0 & 1,761.4 & 0.005 \\
    Claude-Sonnet-4.5 & 237.03 & 18,349.8 & 3,271.8 & 0.1041 \\
    \bottomrule
    \end{tabular}
}
\vspace{4pt}
\footnotesize{\\ 注：成本计算基于官方 API 定价：GPT-4o (\$2.5/\$10), DeepSeek (\$0.55/\$2.19), Claude (\$3/\$15) per 1M tokens。}
\end{table}

通过对性能与成本数据的交叉分析，我们得出以下关键结论：

\begin{enumerate}
    \item DeepSeek R1 的极致性价比：
    尽管 DeepSeek R1 由于引入了思维链（CoT）机制，导致其平均输出 Token 量（1,761.4）远超 GPT-4o，且平均耗时最长（约 5 分钟），但其极低的 API 定价使其成为**成本最低的方案**。单条策略审计成本仅为 \$0.0056，约为 GPT-4o 的 57\%，仅为 Claude 的 5\%。对于离线批量审计场景，DeepSeek R1 是“以时间换成本”的最优解。

    \item Claude 的“高成本-高精度”权衡：
    Claude-Sonnet-4.5 的单条审计成本高达\$0.1041，是其他模型的 10-20 倍。数据分析表明，其巨大的开销主要源于高达 1.8 万 Tokens 的平均输入量。为了追求 100\% 的准确率，该模型在审计时检索了最完整的代码上下文与依赖关系。这种高昂的成本使其更适合应用于核心金融业务等对安全性有苛刻要求的场景。

    \item GPT-4o 的速度优势：
    GPT-4o 在推理速度上占据绝对优势，平均耗时仅 133.63 秒，且成本适中（\$0.0098）。它适合作为实时性要求较高的在线审计或 CI/CD 流水线中的卡点工具。
\end{enumerate}

综上所述，引入思维链推理（DeepSeek R1）或超长上下文关联（Claude-Sonnet-4.5）均能显著提升审计的准确性，但也会带来时间或资金成本的增加。在实际工程中，建议采用分级审计策略：使用低成本的 DeepSeek R1 进行日常全量扫描，而针对高危服务则调用 Claude-Sonnet-4.5 进行深度复核。



\subsection{模型解释能力分析}
\label{subsec:qualitative_analysis}

除了准确率与响应时延等定量指标外，大语言模型在输出解释报告时的逻辑深度、证据颗粒度以及对云原生架构的洞察力，直接决定了其在“人在回路（Human-in-the-Loop）”审计场景下的可用性。本节特别选出开源项目 JupyterHub 中最为核心的 hub组件网络策略这一例子作为典型案例，来对比分析了 GPT-4o、DeepSeek Reasoner (R1) 与 Claude-Sonnet-4.5 三种模型在执行逆向解释任务时的具体表现。

\subsubsection{案例背景与基准}
该案例选取自 JupyterHub 项目的 hub 微服务 Pod。该组件负责管理用户生命周期及代理路由，其网络行为具有高度复杂性：既需要 Ingress 方向接收 Proxy 的 API 请求，又需要 Egress 方向管理 singleuser-server（单用户容器）及连接外部数据库。

\subsubsection{解释能力的维度对比}

通过对模型输出文本的语义分析，我们从证据溯源、逻辑完备性与架构洞察力三个维度进行评价：

\begin{enumerate}
    \item 证据溯源的颗粒度（Granularity of Evidence）
    \begin{itemize}
        \item GPT-4o 的解释倾向于“直接映射”，能够建立配置项与网络规则的一级对应关系。例如，它正确识别了 c.JupyterHub.hub\_bind\_url 与 Ingress 8081 端口的关联 。然而，其证据链较为扁平，缺乏对上下文环境的深度挖掘。
        \item DeepSeek Reasoner (R1) 展现了极强的“结构化溯源”能力。它不仅引用了配置文件，还进一步挖掘了环境变量（如 HUB\_SERVICE\_PORT=8081）作为双重验证证据 。这种多模态证据的交叉验证显著提升了审计的可信度。
        \item Claude-Sonnet-4.5 则提供了“语义级”的证据。它不仅指出了端口匹配，还解释了标签选择器的合理性（如 Proxy Pod 的标签符合 Ingress 规则），并引用了 KubeSpawner 配置来证明 Egress 访问用户容器的必要性 。
    \end{itemize}

    \item 逻辑完备性（Logical Completeness）
    在覆盖率方面，模型表现差异显著。
    \begin{itemize}
        \item GPT-4o 可能出现遗漏。例如，它没有能够成功地识别出 Hub 组件需要访问 singleuser-server（端口 8888）的 Egress 需求，仅笼统提到了外部 IP 访问 ，这导致生成的解释报告在完整性上存在缺陷。
        \item DeepSeek R1 与 Claude-Sonnet-4.5 均成功识别了包括 Proxy API (8001)、Singleuser (8888)、DNS (53) 及外部网络在内的所有四类出站需求 。其中，DeepSeek 的输出格式更为标准化，明确列出了每一条 Egress 规则的对应组件。
    \end{itemize}

    \item 架构洞察力与容错性（Architectural Insight）
    这是区分通用模型与专家级模型的关键维度。
    \begin{itemize}
        \item GPT-4o 在摘要中提及“proxy 容器需要...”，显示出其对 Pod 内容器的归属关系存在一定的混淆，例如未能清晰区分 Hub Pod 与 Proxy 组件的边界 。
        \item Claude-Sonnet-4.5 展现了卓越的架构理解能力。它敏锐地指出：“虽然容器分析中指出 Proxy 容器不受当前 NetworkPolicy 管理...但这表明需要为 Proxy 组件创建独立的 NetworkPolicy” 。这种超越单一文件、从系统架构层面进行的“防御性解释”，能够有效防止运维人员因误解策略作用域而产生配置错误。
    \end{itemize}
\end{enumerate}

\subsubsection{综合评价}

通过对比分析针对之前全部策略的解释结果，表 \ref{tab:qualitative_comparison} 总结了三种模型在对策略定性分析中的综合表现。

\begin{table}[htbp]
\centering
\caption{不同大模型在微隔离策略解释任务中的定性能力对比}
\label{tab:qualitative_comparison}
\begin{tabular}{lccc}
\toprule
评价维度 & GPT-4o & DeepSeek Reasoner (R1) & Claude-Sonnet-4.5 \\
\midrule
\textbf{证据深度} & 浅层（配置） & 中层（配置+环境变量） & 深层（代码逻辑+架构语义） \\
\textbf{规则召回} & 存在遗漏  & 完全覆盖 & 完全覆盖 \\
\textbf{架构理解} & 局部视角 & 模块化视角 & 全局系统视角 \\
\textbf{输出风格} & 简洁摘要 & 结构化 JSON/List & 详尽的审计报告 \\
\textbf{适用场景} & 快速预览 & 自动化合规检查 & 复杂故障排查与人工审计 \\
\bottomrule
\end{tabular}
\end{table}



\section{大模型正向生成实验}
\subsection{数据集定义}
\label{subsec:forward_dataset_ref}


为了验证第四章提出的大模型正向生成机制在处理复杂基础设施与隐式依赖场景下的有效性，本实验沿用了 5.3 节（表 \ref{tab:services_extended}）中定义的数据集。该数据集包含丰富的核心开源项目。

本节选取该数据集进行正向生成实验的主要依据如下：

\begin{enumerate}
    \item 依赖关系的隐蔽性：数据集中的对象（如 Airflow 的 scheduler 与 worker，TiDB 的 PD 与 TiKV）大量采用动态配置加载、自定义 RPC 协议及非标准的端口绑定逻辑。这些特征构成了确定性分析引擎的“语义盲区”，是验证大模型 DeepWiki 引擎深度语义挖掘能力的理想样本。
    \item 真值（Ground Truth）标准的构建：为了量化评估生成的准确性，本实验不依赖任何运行时流量基线，而是构建了一套“黄金标准”策略集。针对这些服务，由人工审核通过白盒审计源代码与官方架构文档，手工编写了严格符合最小权限原则的 NetworkPolicy。实验将系统基于代码意图自动生成的策略 YAML 文件与该真值集合进行比对，以此计算精确率和召回率。
\end{enumerate}

综上所述，本实验旨在验证在确定性分析失效的复杂场景下，大模型能否准确提取代码意图并生成与最小权限的安全策略。



\subsection{实验结果统计与性能分析}
\label{subsec:forward_results_analysis}

\subsubsection{实验结果统计}

为了评估系统生成策略的质量，本实验摒弃了生成耗时等次要指标，聚焦于安全防护最核心的两个维度：策略覆盖率（衡量是否覆盖了所有必要的业务通信）与策略冗余度（衡量是否生成了多余的非必要规则）。


基于零信任微隔离“默认拒绝、最小授权”的原则，本文定义以下两个量化指标：

\begin{itemize}
    \item 策略覆盖率 (Policy Coverage Rate, PCR)：该指标用于衡量生成的策略对真实业务通信需求的覆盖程度，反映了模型的“召回能力”。PCR 越高，意味着业务因缺少策略而被误阻断的风险越低。它是“正确策略”在生成结果中的占比体现。
    \item 策略冗余度 (Policy Redundancy Rate, PRR)：该指标用于衡量生成策略中包含的非必要或过度宽松规则的比例，反映了模型的“精确性”。PRR 越低，意味着生成的白名单越精简，攻击面越小。
\end{itemize}


通过对比了 GPT-4o、DeepSeek Reasoner (R1) 与 Claude-Sonnet-4.5 三款模型在上述两个核心指标上的表现。实验统计结果如表~\ref{tab:full_project_metrics} 所示。

\begin{table}[htbp]
\centering
\caption{多模型在全量实验项目集上的正向策略生成指标统计 (PCR: 覆盖率 / PRR: 冗余度)}
\label{tab:full_project_metrics}
\resizebox{\textwidth}{!}{
\begin{tabular}{ll cccccc}
\toprule
 & & \multicolumn{2}{c}{GPT-4o} & \multicolumn{2}{c}{DeepSeek-R1} & \multicolumn{2}{c}{Claude-Sonnet-4.5} \\
\cmidrule(lr){3-4} \cmidrule(lr){5-6} \cmidrule(lr){7-8}
序号 & 应用系统 & PCR & PRR & PCR & PRR & PCR & PRR \\
\midrule
1 & Airflow & 100.0\% & 0.0\% & 100.0\% & 0.0\% & 100.0\% & 0.0\% \\
2 & Devlake & 100.0\% & 0.0\% & 100.0\% & 0.0\% & 100.0\% & 0.0\% \\
3 & TiDB & 100.0\% & 0.0\% & 100.0\% & 0.0\% & 100.0\% & 0.0\% \\
4 & Druid & 100.0\% & 0.0\% & 100.0\% & 0.0\% & 100.0\% & 0.0\% \\
5 & Pinot & 100.0\% & 0.0\% & 100.0\% & 0.0\% & 100.0\% & 0.0\% \\
6 & JupyterHub & 100.0\% & 13.3\% & 100.0\% & 0.0\% & 100.0\% & 0.0\% \\
7 & RuoYi-Cloud & 100.0\% & 0.0\% & 100.0\% & 3.3\% & 100.0\% & 0.0\% \\
8 & Yudao-Cloud & 100.0\% & 0.0\% & 100.0\% & 3.6\% & 100.0\% & 0.0\% \\
9 & Reactive-Shopping & 100.0\% & 0.0\% & 100.0\% & 5.9\% & 100.0\% & 2.5\% \\
10 & Killbug & 100.0\% & 0.0\% & 100.0\% & 0.0\% & 100.0\% & 0.0\% \\
11 & Online-Boutique & 94.1\% & 15.0\% & 100.0\% & 10.0\% & 100.0\% & 15.0\% \\
12 & Bank of Anthos & 95.7\% & 0.0\% & 95.7\% & 0.0\% & 100.0\% & 0.0\% \\
13 & Microservices-K8s & 100.0\% & 0.0\% & 100.0\% & 0.0\% & 100.0\% & 0.0\% \\
14 & Robot Shop & 100.0\% & 18.2\% & 100.0\% & 0.0\% & 100.0\% & 0.0\% \\
15 & eShopOnContainers & 97.5\% & 0.0\% & 100.0\% & 0.0\% & 100.0\% & 0.0\% \\
16 & Sock Shop & 90.0\% & 0.0\% & 90.0\% & 0.0\% & 100.0\% & 0.0\% \\
\midrule
\multicolumn{2}{c}{总体平均 (Weighted Avg)} & 98.8\% & 2.6\% & 99.4\% & 1.8\% & 100.0\% & 1.2\% \\
\bottomrule
\end{tabular}
}
\end{table}



从加权平均值（Weighted Avg）来看，三个模型均展现了极高的工业可用性，PCR 均值保持在 98.8\% 以上。其中，\textbf{Claude-Sonnet-4.5 表现最为卓越}，实现了 100.0\% 的全量覆盖率与仅 1.2\% 的极低冗余度，证明其在处理复杂依赖关系时的“零漏报”能力。DeepSeek-R1 紧随其后，PCR 达到 99.4\%，且在绝大多数项目中保持了与 Claude 持平的低冗余水平。GPT-4o 虽然总体覆盖率（98.8\%）依然优秀，但在冗余度控制上略逊一筹（2.6\%），呈现出“宁可错放，不可错杀”的策略生成倾向。


在 Airflow、TiDB 等前 10 个标准架构项目中，三个模型均实现了 100\% 的完美覆盖。差异主要体现在架构较为复杂的微服务 Demo 中：
\begin{itemize}
    \item Sock Shop：GPT-4o 与 DeepSeek-R1 均出现了 10\% 的覆盖率缺口（90.0\%）。经审计发现，遗漏点主要集中在 \texttt{front-end} 服务对 \texttt{catalogue} 服务的非标准 HTTP 调用上。而 Claude-Sonnet-4.5 凭借其超长上下文窗口，成功关联了分散在多个配置文件中的路由规则，补全了这一死角。
    \item Online-Boutique (No.11)：GPT-4o 在此项目中仅达到 94.1\% 的覆盖率。结合调试日志分析，GPT-4o 未能正确解析 artservice 中基于 Redis Sentinel 的动态发现机制，导致部分从节点通信规则丢失。
\end{itemize}


冗余度指标揭示了模型在面对“不确定性”时的决策边界。
\begin{itemize}
    \item Online-Boutique 关联性幻觉：
    这是本实验中最具代表性的案例，所有模型在该项目中都产生了冗余策略，这一现象揭示了大模型在处理多组件复杂上下文时典型的“关联性幻觉”，Online-Boutique包含 10 个以上微服务组件，导致 Prompt 上下文中充斥着大量的跨服务环境变量与配置片段。大模型在面对如此高密度的信息时，未能有效隔离不同 Pod 的代码上下文边界。例如，它错误地将组件redis-cart“过度关联”给了并未实际调用的组件，产生了一条并不存在的依赖规则。
    \item Robot Shop的极端分化：这是本实验中最具代表性的案例。GPT-4o 在该项目中产生了高达 \textbf{18.2\%} 的冗余策略，而 DeepSeek-R1 与 Claude-3.5-Sonnet 均为 0.0\%。
    \item 通过对比 推理日志发现，\texttt{Robot Shop} 混合使用了 Python、Node.js 和 Java，且部分服务未显式声明端口。GPT-4o 在无法确信时，倾向于开放整个子网段或常用端口（如 8080/80）以保证连通性；而 DeepSeek-R1 利用思维链（Chain-of-Thought）进行了多轮否定推理，明确排除了非必要端口；Claude-Sonnet-4.5 则在 JSON 的 \texttt{security\_recommendations} 字段中明确指出“未发现明确网络依赖，建议实施默认阻断”，从而避免了冗余规则的生成。
\end{itemize}



\subsubsection{性能分析}
\label{subsec:performance_cost_analysis}

在云原生微隔离策略的工程化落地中，除了策略生成的准确性外，系统的响应时效性与经济成本效益比（Cost-Performance Ratio）同样是决定其能否大规模商用的关键指标。本节基于实验记录的详细日志，对 GPT-4o、DeepSeek Reasoner (R1) 与 Claude-Sonnet-4.5 三款模型在执行策略生成任务时的平均资源消耗进行了量化评估。统计结果如表~\ref{tab:avg_performance_cost} 所示。

\begin{table}[htbp]
\centering
\caption{多模型策略生成任务的单 Pod 平均资源消耗与成本统计}
\label{tab:avg_performance_cost}
% 使用 resizebox 将表格宽度限制为文本宽度
\resizebox{\textwidth}{!}{
\begin{tabular}{lcccc}
\toprule
模型名称 & 平均耗时 (s/Pod) & 平均输入 (Tokens) & 平均输出 (Tokens) & 平均成本 (\$/Pod) \\
\midrule
GPT-4o & 40.0 & 3,048 & 480 & 0.012 \\
DeepSeek-R1 & 299.3 & 2,959 & 2,034 & 0.006 \\
Claude-Sonnet-4.5 & 118.3 & 14,966 & 1,973 & 0.074 \\
\bottomrule
\end{tabular}
}
\vspace{4pt}
\end{table}



从平均耗时来看，GPT-4o 展现了显著的工程化优势。其单 Pod 平均处理时间仅为 40.0 秒，这意味着在并发处理能力充足的情况下，系统能够以分钟级的速度完成大规模集群的策略基线构建。这种快速响应能力使其非常适合应对紧急扩容或故障恢复场景下的策略下发。

相比之下，DeepSeek-R1 的平均耗时最长，达到 299.3 秒（约 5 分钟）。这与其内置的思维链（Chain-of-Thought）机制直接相关：模型在生成最终策略前，需要进行大量的逻辑推演。虽然牺牲了部分时效性，但前文实验证明这种“慢思考”机制有效提升了策略的收敛度。


在经济成本维度，各模型表现出了截然不同的定价策略与资源消耗模式：

DeepSeek-R1 的极致性价比：尽管 DeepSeek-R1 的平均输出 Token 量较高（2,034 Tokens，包含思维链内容），但得益于其极低的 API 单价，其单 Pod 生成成本仅为 0.006 美元（约合人民币 0.04 元）。这意味着企业仅需极低的预算即可实现全量微服务的精细化防护，具备极高的规模化推广潜力。

Claude 的“全上下文”策略代价：Claude-Sonnet-4.5 的单 Pod 成本最高，达到 0.074 美元，是 DeepSeek 的 12 倍以上。数据分析显示，这主要是由于其平均输入 Token 高达 14,966 个。为了追求 100\% 的覆盖率，系统在调用 Claude 时加载了完整的代码仓库上下文而非摘要。这种高成本投入换取了最高的准确率，适合应用于对安全要求极高的核心支付类业务。

GPT-4o 的均衡选择：GPT-4o 以 0.012 美元的适中成本提供了最快的生成速度。其输入输出比例最为精简，表明该模型能够通过较短的 Prompt 高效理解任务意图，是平衡性能与预算的通用选择。

综上所述，工程实践中建议采用分级治理策略：对于绝大多数非核心微服务，采用 DeepSeek-R1 进行低成本的夜间批量计算；对于核心金融业务，采用 Claude-Sonnet-4.5 进行高精度覆盖；而对于应急响应场景，则优先使用 GPT-4o 进行快速阻断。

综合准确率、时效性与成本三个维度，本文提出如下工程选型建议：
\begin{itemize}
    \item 日常运维与冷启动：推荐使用 \textbf{DeepSeek-R1}。虽然耗时较长，但其 \$0.006/Pod 的低廉成本与 98.6\% 的高覆盖率，非常适合在夜间批量执行全量策略生成任务。
    \item 应急响应与扩容：推荐使用 \textbf{GPT-4o}。其分钟级的响应速度能迅速填补新上线服务的防护空白。
    \item 核心金融级审计：推荐使用 \textbf{Claude-Sonnet-4.5}。在不计成本追求 0 误报与 100\% 覆盖的核心支付场景（如 \texttt{epay}, \texttt{anthos-bank}）中，其全上下文推理能力是不可替代的。
\end{itemize}

subsection{模型证据链分析}
\label{subsec:evidence_analysis}

在零信任微隔离的工程落地中，策略的“可解释性（Explainability）”十分重要。运维人员通常面临“敢开通不敢阻断”的困境，根本原因在于缺乏足够的证据来证明“某条流量确实是不需要的”。

本节基于模型输出的证据链文件，重点对比了 GPT-4o、DeepSeek-R1 与 Claude-Sonnet-4.5 在策略生成过程中的证据溯源（Evidence Sourcing）能力。

\subsubsection{证据粒度分级评估}

通过对全量实验日志的审计，我们将模型的证据能力划分为三个层级：表层配置级、结构化溯源级与代码语义级。各模型的典型表现如表~\ref{tab:evidence_level} 所示。

\begin{table}[htbp]
\centering
\caption{多模型策略生成证据的质量与粒度分级对比}
\label{tab:evidence_level}
\resizebox{\textwidth}{!}{
\begin{tabular}{l p{3.0cm} p{7.5cm} c}
\toprule
模型 & 证据层级 & 典型证据模式 (Pattern) & 可信度评级 \\
\midrule
GPT-4o & \textbf{表层配置级} \newline (Surface) & 仅提取显式的环境变量键值对，缺乏上下文关联，无法解释隐式依赖。 & $\star\star$ \\
DeepSeek-R1 & \textbf{结构化溯源级} \newline (Structured) & 精确引用配置文件路径、JSON/YAML 结构片段，逻辑链路清晰，适合自动化验证。 & $\star\star\star\star$ \\
Claude-3.5 & \textbf{代码语义级} \newline (Semantic) & 深入代码实现细节，结合类名、库函数、架构模式（如“内存存储”）进行深度归因。 & $\star\star\star\star\star$ \\
\bottomrule
\end{tabular}
}
\end{table}

\subsubsection{典型案例：从“配置读取”到“意图理解”的跨越}

为了具体展示不同证据层级的差异，我们选取了 \texttt{Anthos Bank} 项目中的两个典型服务进行微观对比。

\textbf{1. 正向依赖证据对比：UserService 数据库连接}

在分析 \texttt{userservice} 对 \texttt{accounts-db} 的访问需求时，三个模型均生成了正确的允许规则，但其提供的证据链条（Evidence Chain）厚度截然不同：

\begin{itemize}
    \item \textbf{GPT-4o（配置复读）}：
    仅在 evidence 字段中列出了环境变量：
    \begin{quote}
    \texttt{"env: ACCOUNTS\_DB\_URI=postgresql://..."}
    \end{quote}
    这仅证明了“存在该配置”，但未证明“代码确实使用了该配置”。
    
    \item \textbf{DeepSeek-R1（配置溯源）}：
    不仅列出了环境变量，还引用了具体的配置文件片段，证明了配置的来源路径：
    \begin{quote}
    \texttt{"config\_filepath: \{\"container\_name\": \"userservice\", \"egress\_requirements\": ...\}"}
    \end{quote}
    这种结构化证据非常有利于下游的自动化校验工具（Verifier）进行快速索引。

    \item \textbf{Claude-3.5-Sonnet（代码确证）}：
    展现了惊人的代码级语义理解，它直接指出了使用该配置的**Java 类名**：
    \begin{quote}
    \texttt{"代码: UserDb类使用ACCOUNTS\_DB\_URI环境变量连接PostgreSQL数据库"}
    \end{quote}
    这一证据证明模型通过阅读源代码，确认了配置与业务逻辑的实质性绑定关系，构成了完整的证据闭环。
\end{itemize}

\textbf{2. 负向阻断证据对比：AdService 无依赖证明}

对于无需访问外部数据库的纯计算型服务（如 \texttt{adservice}），如何证明“它不需要访问任何数据库”是实施默认拒绝策略的难点。

\begin{itemize}
    \item \textbf{GPT-4o 与 DeepSeek-R1}：
    仅给出了消极的结论：“未发现网络依赖”或列出空的 Egress 列表。这在运维人员眼中可能被解读为“模型没找到”，而非“确实没有”。
    
    \item \textbf{Claude-3.5-Sonnet}：
    在 \texttt{security\_recommendations} 字段中提供了**教科书级的负向证据**：
    \begin{quote}
    \textit{“广告数据存储在内存中的 \textbf{ImmutableListMultimap}，无需外部数据库... 该容器仅提供入站 gRPC 服务，不主动发起出站连接”}
    \end{quote}
    Claude 不仅识别了 \texttt{ImmutableListMultimap} 这一具体的数据结构，还推断出了其“内存型存储（In-memory Storage）”的架构属性。这种基于实现原理的解释，彻底消除了“是否会有隐式数据库连接”的疑虑，为实施高强度的阻断策略提供了强有力的安全背书。
\end{itemize}

\subsubsection{分析总结}

实验结果表明，Claude-Sonnet-4.5 是目前唯一具备“代码级审计员”能力的模型**。它超越了简单的模式匹配（Pattern Matching），进入了语义理解（Semantic Understanding）的范畴。

在工程实践中，这种能力具有极高的价值：
\begin{enumerate}
    \item \textbf{消除误报焦虑}：通过指出具体的代码类（如 \texttt{UserDb}）或库函数（如 \texttt{StackExchange.Redis}），让运维人员确信策略的正确性。
    \item \textbf{支持激进防御}：通过识别架构模式（如“纯内存服务”），赋予安全团队在核心组件上实施“零出站（Zero Egress）”策略的底气。
\end{enumerate}

相比之下，DeepSeek-R1 的结构化证据虽然在语义深度上不及 Claude，但其标准化的 JSON 引用格式使其更适合作为自动化流水线（CI/CD Pipeline）中的中间件，用于快速生成合规性报告。



\section{本章小结}
\label{sec:chap5_summary}

本章通过在经典开源基础设施组件的异构 Kubernetes 集群上进行实验，全面验证了本文提出的零信任微隔离策略生成框架的有效性。实验结果表明，动静态协同分析引擎在标准场景下实现了 极高的基础策略生成准确率，且处理时延满足云原生环境的实时性需求。同时，大模型驱动的智能化模块在策略审计与正向生成任务中表现卓越，不仅实现了极高的逻辑错误识别率与极低的假阳性率，更成功解决了服务冷启动阶段的防护真空问题，验证了该方案在提升微隔离策略准确性与可解释性方面的工程价值。


\chapter{总结与展望}
\label{chap:conclusion_future}

\section{工作总结}
\label{sec:summary}

本文针对云原生架构下微服务集群的安全治理难题，深入探讨了零信任微隔离策略生成的理论支撑与工程实践。在微服务架构日益普及的背景下，其极致的动态性与多语言异构性，使得传统基于边界防御和被动流量学习的防御体系逐渐失效。本研究的核心价值在于，提出了一套融合“确定性程序分析”与“生成式语义推理”的内生安全防御体系，通过两套互补的技术方案，有效解决了现有研究中普遍存在的策略生成滞后、覆盖率不足以及缺乏可解释性等关键问题。

本文首先针对微服务基础通信关系的构建，提出了基于图结构的动静态协同分析方法。这一方案主要适用于以Java（如Spring Cloud生态）为代表的标准化微服务架构场景。相较于相关研究中主流的“被动流量学习”技术，本方法的显著优势在于其极高的执行效率与近乎零的边际成本——它能够在不消耗昂贵算力资源的前提下，快速完成集群的拓扑提取。通过将Kubernetes运行时的瞬时状态与静态字节码中的长效逻辑进行同构映射，该方法能够精准还原服务间的调用拓扑，为提供了高置信度的策略生成。然而，受限于静态分析技术的语言依赖性，该方法在面对非Java语言或高度动态的脚本语言环境时存在一定的适用性局限。

为了突破单一技术栈的限制并解决复杂异构场景下的语义理解难题，本文构建了基于大语言模型增强的策略生成与审计框架。这一方案作为动静态分析的有力补充，主要适用于多语言混合（如Go、Python、Node.js等）的复杂异构场景以及无流量冷启动环境。虽然大模型的引入带来了相对较高的算力成本与推理时延，但其展现了卓越的通用性与语义理解能力。它不仅能够跨越编程语言的障碍，深入理解代码层面的业务意图与隐式约束，还能解析非标协议与复杂的架构模式。其核心价值在于实现了从“语法匹配”到“语义理解”的跨越，不仅填补了传统静态工具在多语言支持上的空白，还能提供包含代码级证据的可解释性溯源，解决了零信任落地中运维人员因“不敢阻断”而导致的工程僵局。

综上所述，本文通过“动静态协同分析”与“大模型语义增强”的双轨驱动，构建了完整的零信任微隔离技术闭环。前者作为“低成本、高时效”的基础设施，负责在Java等标准场景下提供坚实的确定性策略；后者作为“高智能、全覆盖”的增强引擎，负责在多语言异构场景下注入深度的语义理解。两者优势互补，有效地将微隔离策略的生成模式从“基于流量观测的被动适应”转变为“基于代码意图的主动构建”，为云原生环境下的零信任安全落地提供了切实可行的理论依据与技术方案。

\section{未来展望}
\label{sec:future_work}

尽管本文在自动化策略生成领域取得了一定成果，但云原生安全防御的演进永无止境，未来的研究仍有广阔的探索空间。随着 eBPF 等内核技术的成熟与大模型逻辑推理能力的进一步提升，微隔离防护将从单纯的“流量管控”向“意图自治”方向深度迈进。未来的安全体系应当具备更深层次的协议洞察能力，能够穿越加密流量与复杂 RPC 框架，实现应用层语义的实时解构与风险感知。

策略的自愈能力将成为下一个研究重点。在持续集成与持续部署的流水线中，安全策略不应是静态的基线，而应是随代码变更而自动漂移的“流体”。探索如何利用大模型实时监听代码库的微小变动，并自动触发毫秒级的策略微调，将彻底解决安全配置滞后于业务迭代的顽疾。此外，跨云一致性与策略互操作性也是亟待解决的问题。在多云混合架构成为主流的趋势下，如何构建一套不依赖于特定网络插件的标准化策略语言，实现“一次意图提取，全球拓扑分发”，将具有极大的行业应用前景。

最后，大模型本身的性能开销与对抗性安全性亦不容忽视。在追求推理精度的同时，如何通过模型蒸馏与领域知识对齐，降低系统在生产环境中的资源占用，是工程化落地的关键。同时，利用人工智能技术对现有策略进行模拟攻防探测，构建基于“红队思维”的自适应加固机制，将进一步提升系统在零日攻击场景下的生存能力。我们相信，随着程序分析技术与人工智能的持续融合，云原生环境将真正实现安全与敏捷的深度平衡，构建起一个透明、智能且具备自我进化能力的零信任安全生态。